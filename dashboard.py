import streamlit as st
import os, json, sqlite3, io, urllib.parse
import pandas as pd
import numpy as np
import plotly.graph_objects as go 
from scipy.stats import skew, kurtosis
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
from datetime import datetime

# --- 0. é é¢åŸºæœ¬è¨­å®š ---
st.set_page_config(
    page_title="å…¨çƒè‚¡å¸‚ç‰¹å¾µå¼•æ“", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 1. å›ºå®šè®Šæ•¸å®šç¾© ---
# å¸‚å ´ä»£ç¢¼æ˜ å°„
MARKET_MAP = {
    "å°è‚¡ (TW)": "tw",
    "ç¾è‚¡ (US)": "us", 
    "é™¸è‚¡ (CN)": "cn",
    "æ¸¯è‚¡ (HK)": "hk",
    "æ—¥è‚¡ (JP)": "jp",
    "éŸ“è‚¡ (KR)": "kr"
}

# --- 2. è¼”åŠ©å‡½æ•¸ï¼šç²å–é…ç½®å€¼ ---
def get_config_value(key, default=None):
    """ç²å–é…ç½®å€¼ï¼Œå„ªå…ˆå¾ç’°å¢ƒè®Šæ•¸ï¼Œå…¶æ¬¡å¾ Streamlit Secrets"""
    # å…ˆå˜—è©¦ç’°å¢ƒè®Šæ•¸ (Render éƒ¨ç½²ç”¨)
    env_value = os.environ.get(key)
    if env_value:
        return env_value
    
    # å†å˜—è©¦ Streamlit Secrets (æœ¬åœ°é–‹ç™¼ç”¨)
    try:
        if key in st.secrets:
            return st.secrets[key]
    except Exception:
        # å¦‚æœåœ¨ Render ä¸Š st.secrets ä¸å¯ç”¨ï¼Œæœƒè·³åˆ°é€™è£¡
        pass
    
    return default

# --- 3. Google Drive æœå‹™åˆå§‹åŒ– ---
@st.cache_resource
def get_gdrive_service():
    """åˆå§‹åŒ– Google Drive æœå‹™ï¼ŒåŒæ™‚æ”¯æ´ç’°å¢ƒè®Šæ•¸å’Œ Streamlit Secrets"""
    # å˜—è©¦å¾ç’°å¢ƒè®Šæ•¸æˆ– Secrets ç²å–æœå‹™å¸³æˆ¶è³‡è¨Š
    service_account_json = get_config_value("GDRIVE_SERVICE_ACCOUNT")
    
    if not service_account_json:
        st.error("âŒ æ‰¾ä¸åˆ° GDRIVE_SERVICE_ACCOUNT é…ç½®")
        st.info("è«‹åœ¨ Render ç’°å¢ƒè®Šæ•¸æˆ– Streamlit Secrets ä¸­è¨­å®š GDRIVE_SERVICE_ACCOUNT")
        return None
    
    try:
        # è§£æ JSON (ç„¡è«–ä¾†è‡ªç’°å¢ƒè®Šæ•¸æˆ– Secrets)
        if isinstance(service_account_json, str):
            info = json.loads(service_account_json)
        else:
            info = service_account_json
        
        creds = service_account.Credentials.from_service_account_info(
            info, scopes=['https://www.googleapis.com/auth/drive.readonly']
        )
        return build('drive', 'v3', credentials=creds)
    except json.JSONDecodeError as e:
        st.error(f"âŒ GDRIVE_SERVICE_ACCOUNT JSON è§£æå¤±æ•—: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ æœå‹™åˆå§‹åŒ–å¤±æ•—: {e}")
        return None

def download_file(service, file_id, file_name):
    """ä¸‹è¼‰æª”æ¡ˆå¾ Google Drive"""
    request = service.files().get_media(fileId=file_id)
    fh = io.FileIO(file_name, 'wb')
    downloader = MediaIoBaseDownload(fh, request)
    done = False
    with st.spinner(f'ğŸš€ æ­£åœ¨åŒæ­¥ {file_name}...'):
        while done is False:
            _, done = downloader.next_chunk()
    return True

def get_database_stats(db_path, market_code):
    """ç²å–è³‡æ–™åº«çµ±è¨ˆè³‡è¨Š"""
    stats = {
        "è‚¡ç¥¨æ•¸é‡": 0,
        "æ•¸æ“šå¤©æ•¸": 0,
        "æœ€æ—©æ—¥æœŸ": None,
        "æœ€æ™šæ—¥æœŸ": None,
        "åˆ†æè¡¨ç­†æ•¸": 0,
        "æ¼²åœå¤©æ•¸": 0,
        "èˆˆæ«ƒå¼·å‹¢å¤©æ•¸": 0
    }
    
    if os.path.exists(db_path):
        try:
            conn = sqlite3.connect(db_path)
            
            # è‚¡ç¥¨æ•¸é‡
            query = "SELECT COUNT(DISTINCT symbol) FROM stock_prices"
            result = conn.execute(query).fetchone()
            stats["è‚¡ç¥¨æ•¸é‡"] = result[0] if result else 0
            
            # æ•¸æ“šå¤©æ•¸ç¯„åœ
            query = "SELECT MIN(date), MAX(date), COUNT(*) FROM stock_prices"
            result = conn.execute(query).fetchone()
            if result:
                stats["æœ€æ—©æ—¥æœŸ"] = result[0]
                stats["æœ€æ™šæ—¥æœŸ"] = result[1]
                stats["æ•¸æ“šå¤©æ•¸"] = result[2]
            
            # åˆ†æè¡¨çµ±è¨ˆ
            query = "SELECT COUNT(*) FROM stock_analysis"
            result = conn.execute(query).fetchone()
            stats["åˆ†æè¡¨ç­†æ•¸"] = result[0] if result else 0
            
            # æ¼²åœçµ±è¨ˆ (åƒ…é™éèˆˆæ«ƒ)
            query = """
            SELECT COUNT(*) FROM stock_analysis 
            WHERE is_limit_up = 1 AND market_detail != 'emerging'
            """
            result = conn.execute(query).fetchone()
            stats["æ¼²åœå¤©æ•¸"] = result[0] if result else 0
            
            # èˆˆæ«ƒå¼·å‹¢å¤©æ•¸ (æ¼²å¹…å¤§æ–¼10%)
            query = """
            SELECT COUNT(*) FROM stock_analysis 
            WHERE strength_value >= 10 AND market_detail = 'emerging'
            """
            result = conn.execute(query).fetchone()
            stats["èˆˆæ«ƒå¼·å‹¢å¤©æ•¸"] = result[0] if result else 0
            
            conn.close()
            
        except Exception as e:
            st.error(f"çµ±è¨ˆè³‡æ–™åº«æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    return stats

# --- 4. å´é‚Šæ¬„é…ç½® ---
st.sidebar.title("ğŸŒ å°èˆªé¸å–®")

# é é¢é¸æ“‡
page_options = {
    "ğŸ  é¦–é  - ç­–ç•¥ç¯©é¸": "home",
    "ğŸ“Š é€±Kåˆ†æ": "weekly",
    "ğŸ“ˆ æœˆKåˆ†æ": "monthly", 
    "ğŸ¯ æ¼²åœæ¿åˆ†æ": "limit_up",
    "ğŸ“‰ å¹´åº¦è²¢ç»åº¦åˆ†æ": "annual_contribution",
    "ğŸ” é™¤éŒ¯å·¥å…·": "debug"
}

selected_page = st.sidebar.radio("é¸æ“‡é é¢", list(page_options.keys()))

# å¸‚å ´é¸æ“‡ (å¤§éƒ¨åˆ†é é¢éƒ½éœ€è¦)
st.sidebar.header("ğŸ“Š å¸‚å ´é¸æ“‡")
selected_market_label = st.sidebar.selectbox("é¸æ“‡å¸‚å ´", list(MARKET_MAP.keys()))
market_code = MARKET_MAP[selected_market_label]
TARGET_DB = f"{market_code}_stock_warehouse.db"

# ä¸‹è¼‰è³‡æ–™åº«
service = get_gdrive_service()
db_stats = None

if service and st.sidebar.button("ğŸ”„ åŒæ­¥è³‡æ–™åº«", type="secondary"):
    with st.spinner("æ­£åœ¨å¾é›²ç«¯åŒæ­¥è³‡æ–™åº«..."):
        # ç²å–è³‡æ–™å¤¾ ID (å¾ç’°å¢ƒè®Šæ•¸æˆ– Secrets)
        folder_id = get_config_value("GDRIVE_FOLDER_ID", "")
        
        if folder_id:
            query = f"'{folder_id}' in parents and name = '{TARGET_DB}' and trashed = false"
            results = service.files().list(q=query, fields="files(id, name)").execute()
            files = results.get('files', [])
            if files: 
                download_file(service, files[0]['id'], TARGET_DB)
                st.sidebar.success("âœ… åŒæ­¥å®Œæˆ")
                st.rerun()  # é‡æ–°æ•´ç†é é¢ä»¥é¡¯ç¤ºæœ€æ–°æ•¸æ“š
        else:
            st.sidebar.warning("âš ï¸ æœªè¨­å®š GDRIVE_FOLDER_ID")

# é¡¯ç¤ºè³‡æ–™åº«çµ±è¨ˆ (å¦‚æœå­˜åœ¨)
if os.path.exists(TARGET_DB):
    db_stats = get_database_stats(TARGET_DB, market_code)
    st.sidebar.divider()
    st.sidebar.subheader("ğŸ“Š è³‡æ–™åº«çµ±è¨ˆ")
    
    col1, col2 = st.sidebar.columns(2)
    with col1:
        st.metric("è‚¡ç¥¨æ•¸é‡", f"{db_stats['è‚¡ç¥¨æ•¸é‡']:,}")
        st.metric("ç¸½å¤©æ•¸", f"{db_stats['æ•¸æ“šå¤©æ•¸']:,}")
    with col2:
        st.metric("åˆ†æç­†æ•¸", f"{db_stats['åˆ†æè¡¨ç­†æ•¸']:,}")
        if db_stats['æ¼²åœå¤©æ•¸'] > 0:
            st.metric("æ¼²åœå¤©æ•¸", f"{db_stats['æ¼²åœå¤©æ•¸']:,}")

# --- 5. ä¸»é é¢é‚è¼¯ ---
def render_home_page():
    """é¦–é  - ç­–ç•¥ç¯©é¸"""
    st.title("ğŸ  ç­–ç•¥ç¯©é¸ä¸­å¿ƒ")
    
    if db_stats:
        # é¡¯ç¤ºçµ±è¨ˆå¡ç‰‡
        st.subheader("ğŸ“ˆ å¸‚å ´æ•¸æ“šç¸½è¦½")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("è‚¡ç¥¨ç¸½æ•¸", f"{db_stats['è‚¡ç¥¨æ•¸é‡']:,}", "æ”¯è‚¡ç¥¨")
        with col2:
            st.metric("æ•¸æ“šæœŸé–“", 
                     f"{db_stats['æœ€æ—©æ—¥æœŸ']} è‡³ {db_stats['æœ€æ™šæ—¥æœŸ']}", 
                     f"{db_stats['æ•¸æ“šå¤©æ•¸']:,} å¤©")
        with col3:
            st.metric("åˆ†æè¨˜éŒ„", f"{db_stats['åˆ†æè¡¨ç­†æ•¸']:,}", "ç­†æŠ€è¡“åˆ†æ")
        with col4:
            if db_stats['æ¼²åœå¤©æ•¸'] > 0:
                st.metric("æ¼²åœå¤©æ•¸", f"{db_stats['æ¼²åœå¤©æ•¸']:,}", "å¤©")
            else:
                st.metric("èˆˆæ«ƒå¼·å‹¢", f"{db_stats['èˆˆæ«ƒå¼·å‹¢å¤©æ•¸']:,}", "å¤©")
    
    st.divider()
    
    # ç­–ç•¥ç¯©é¸æ¢ä»¶
    st.sidebar.header("ğŸ¯ ç­–ç•¥ç¯©é¸æ¢ä»¶")
    
    year = st.sidebar.selectbox("é¸æ“‡å¹´ä»½", [2024, 2025], index=1)
    month = st.sidebar.selectbox("é¸æ“‡æœˆä»½", list(range(1, 13)), index=0)
    
    # æŠ€è¡“æŒ‡æ¨™ç­–ç•¥
    strategy_type = st.sidebar.selectbox(
        "1. æŠ€è¡“æŒ‡æ¨™ç­–ç•¥", 
        ["ç„¡", "KD é»ƒé‡‘äº¤å‰", "MACD æŸ±ç‹€åœ–è½‰æ­£", "å‡ç·šå¤šé ­æ’åˆ—(MA20>MA60)"]
    )
    
    # èƒŒé›¢é¸å–®
    divergence_type = st.sidebar.selectbox(
        "2. ç–ŠåŠ èƒŒé›¢æ¢ä»¶",
        ["ä¸é™", "MACD åº•éƒ¨èƒŒé›¢", "KD åº•éƒ¨èƒŒé›¢", "é›™é‡èƒŒé›¢ (MACD+KD)"]
    )
    
    # è©•ä¼°æœŸé–“
    period_options = {
        "1-5 å¤© (æ¥µçŸ­ç·šå±•æœ›)": "1-5",
        "6-10 å¤© (æ³¢æ®µå•Ÿå‹•æœŸ)": "6-10",
        "11-20 å¤© (ä¸­æœŸè¶¨å‹¢é©—è­‰)": "11-20"
    }
    selected_period_label = st.sidebar.selectbox(
        "3. è©•ä¼°æœªä¾†å ±é…¬å€é–“", 
        list(period_options.keys())
    )
    reward_period = period_options[selected_period_label]
    
    # åŸ·è¡Œç­–ç•¥ç¯©é¸
    if os.path.exists(TARGET_DB):
        try:
            conn = sqlite3.connect(TARGET_DB)
            start_date = f"{year}-{month:02d}-01"
            end_date = f"{year}-{month:02d}-31"
            query = f"SELECT * FROM stock_analysis WHERE date BETWEEN '{start_date}' AND '{end_date}'"
            df = pd.read_sql(query, conn)
            conn.close()
            
            if not df.empty:
                # é¡¯ç¤ºç¯©é¸çµæœ
                st.subheader(f"ğŸ¯ {year}å¹´{month}æœˆ ç¬¦åˆè¨Šè™Ÿæ¨™çš„")
                
                # åŸºæœ¬ç¯©é¸é‚è¼¯
                if strategy_type != "ç„¡":
                    if strategy_type == "KD é»ƒé‡‘äº¤å‰":
                        df = df[df['kd_golden_cross'] == 1]
                    elif strategy_type == "MACD æŸ±ç‹€åœ–è½‰æ­£":
                        df = df[df['macd_histogram_turn_positive'] == 1]
                    elif strategy_type == "å‡ç·šå¤šé ­æ’åˆ—(MA20>MA60)":
                        df = df[df['ma20_ma60_cross'] == 1]
                
                # èƒŒé›¢æ¢ä»¶ç¯©é¸
                if divergence_type != "ä¸é™":
                    if divergence_type == "MACD åº•éƒ¨èƒŒé›¢":
                        df = df[df['macd_divergence'] == 1]
                    elif divergence_type == "KD åº•éƒ¨èƒŒé›¢":
                        df = df[df['kd_divergence'] == 1]
                    elif divergence_type == "é›™é‡èƒŒé›¢ (MACD+KD)":
                        df = df[(df['macd_divergence'] == 1) & (df['kd_divergence'] == 1)]
                
                # é¡¯ç¤ºçµæœ
                if not df.empty:
                    st.success(f"âœ… æ‰¾åˆ° {len(df)} å€‹ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨")
                    st.dataframe(df.head(50), use_container_width=True)
                    
                    # é¡¯ç¤ºçµ±è¨ˆåœ–è¡¨
                    if 'ytd_ret' in df.columns:
                        st.subheader("ğŸ“Š ä»Šå¹´ä»¥ä¾†å ±é…¬åˆ†å¸ƒ")
                        fig = go.Figure(data=[go.Histogram(x=df['ytd_ret'], nbinsx=30)])
                        fig.update_layout(title="YTD å ±é…¬åˆ†å¸ƒ", xaxis_title="å ±é…¬ç‡(%)", yaxis_title="è‚¡ç¥¨æ•¸é‡")
                        st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨")
                    
            else:
                st.info("ğŸ“­ è©²æ™‚æ®µå…§ç„¡è³‡æ–™ï¼Œè«‹æ›´æ›å¹´ä»½æˆ–æœˆä»½ã€‚")
                
        except Exception as e:
            st.error(f"âŒ æ•¸æ“šè®€å–å¤±æ•—: {e}")
    else:
        st.warning("âš ï¸ è«‹å…ˆé»æ“Šå´é‚Šæ¬„çš„ã€åŒæ­¥è³‡æ–™åº«ã€æŒ‰éˆ•ä¸‹è¼‰æ•¸æ“š")

def render_weekly_analysis():
    """é€±Kåˆ†æé é¢"""
    st.title("ğŸ“Š é€±Kåˆ†æ")
    
    if not os.path.exists(TARGET_DB):
        st.warning("âš ï¸ è«‹å…ˆåŒæ­¥è³‡æ–™åº«")
        return
    
    st.info("ğŸ—ï¸ é€±Kåˆ†æåŠŸèƒ½é–‹ç™¼ä¸­...")
    
    # é€±Kçµ±è¨ˆå¡ç‰‡
    if db_stats:
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("é€±Kç¸½æ•¸", "è¨ˆç®—ä¸­...", "é€±")
        with col2:
            st.metric("é€±å‡æ¼²å¹…", "è¨ˆç®—ä¸­...", "%")
        with col3:
            st.metric("é€±æ¼²åœæ•¸", "è¨ˆç®—ä¸­...", "æ¬¡")
    
    # é€±Kåœ–è¡¨ç¤ºä¾‹
    st.subheader("é€±Kèµ°å‹¢åœ–")
    st.line_chart(pd.DataFrame({
        'é€±æ•¸': list(range(1, 21)),
        'å¹³å‡æ¼²å¹…': np.random.randn(20).cumsum()
    }).set_index('é€±æ•¸'))

def render_monthly_analysis():
    """æœˆKåˆ†æé é¢"""
    st.title("ğŸ“ˆ æœˆKåˆ†æ")
    
    if not os.path.exists(TARGET_DB):
        st.warning("âš ï¸ è«‹å…ˆåŒæ­¥è³‡æ–™åº«")
        return
    
    st.info("ğŸ—ï¸ æœˆKåˆ†æåŠŸèƒ½é–‹ç™¼ä¸­...")
    
    # æœˆä»½é¸æ“‡
    months = st.multiselect("é¸æ“‡æœˆä»½ç¯„åœ", 
                          ["1æœˆ", "2æœˆ", "3æœˆ", "4æœˆ", "5æœˆ", "6æœˆ", 
                           "7æœˆ", "8æœˆ", "9æœˆ", "10æœˆ", "11æœˆ", "12æœˆ"],
                          default=["1æœˆ", "6æœˆ", "12æœˆ"])
    
    # æœˆKçµ±è¨ˆ
    st.subheader("æœˆKçµ±è¨ˆ")
    monthly_data = pd.DataFrame({
        'æœˆä»½': months,
        'å¹³å‡æ¼²å¹…': np.random.randn(len(months)) * 5 + 2,
        'æ¼²åœæ¬¡æ•¸': np.random.randint(5, 20, len(months))
    })
    st.dataframe(monthly_data, use_container_width=True)

def render_limit_up_analysis():
    """æ¼²åœæ¿åˆ†æé é¢"""
    st.title("ğŸ¯ æ¼²åœæ¿åˆ†æ")
    
    if not os.path.exists(TARGET_DB):
        st.warning("âš ï¸ è«‹å…ˆåŒæ­¥è³‡æ–™åº«")
        return
    
    try:
        conn = sqlite3.connect(TARGET_DB)
        
        # æ¼²åœçµ±è¨ˆ
        query = """
        SELECT 
            date,
            COUNT(*) as total_stocks,
            SUM(CASE WHEN is_limit_up = 1 THEN 1 ELSE 0 END) as limit_up_count,
            SUM(CASE WHEN is_limit_up = 1 THEN 1 ELSE 0 END) * 100.0 / COUNT(*) as limit_up_percentage
        FROM stock_analysis 
        WHERE market_detail != 'emerging'
        GROUP BY date
        ORDER BY date DESC
        LIMIT 100
        """
        
        limit_up_df = pd.read_sql(query, conn)
        
        if not limit_up_df.empty:
            # çµ±è¨ˆå¡ç‰‡
            st.subheader("ğŸ“ˆ æ¼²åœæ¿çµ±è¨ˆç¸½è¦½")
            
            col1, col2, col3, col4 = st.columns(4)
            total_days = len(limit_up_df)
            avg_limit_up = limit_up_df['limit_up_count'].mean()
            max_limit_up = limit_up_df['limit_up_count'].max()
            avg_percentage = limit_up_df['limit_up_percentage'].mean()
            
            with col1:
                st.metric("åˆ†æå¤©æ•¸", f"{total_days:,}", "å¤©")
            with col2:
                st.metric("æ—¥å‡æ¼²åœ", f"{avg_limit_up:.1f}", "æ”¯")
            with col3:
                st.metric("å–®æ—¥æœ€é«˜", f"{max_limit_up:,}", "æ”¯")
            with col4:
                st.metric("æ¼²åœæ¯”ç‡", f"{avg_percentage:.2f}", "%")
            
            # æ¼²åœè¶¨å‹¢åœ–
            st.subheader("ğŸ“Š æ¯æ—¥æ¼²åœå®¶æ•¸è¶¨å‹¢")
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=limit_up_df['date'], 
                y=limit_up_df['limit_up_count'],
                mode='lines+markers',
                name='æ¼²åœå®¶æ•¸',
                line=dict(color='red', width=2)
            ))
            fig.update_layout(
                title="æ¼²åœå®¶æ•¸è¶¨å‹¢åœ–",
                xaxis_title="æ—¥æœŸ",
                yaxis_title="æ¼²åœå®¶æ•¸",
                hovermode='x unified'
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # æ¼²åœé¡å‹åˆ†æ
            st.subheader("ğŸ” æ¼²åœé¡å‹åˆ†æ (4Uåˆ†æ)")
            query_4u = """
            SELECT 
                lu_type,
                COUNT(*) as count,
                AVG(CASE WHEN strength_rank LIKE 'RANK_%' THEN 1 ELSE 0 END) as strong_ratio,
                AVG(volume_ratio) as avg_volume_ratio,
                AVG(daily_change) as avg_daily_change
            FROM stock_analysis 
            WHERE is_limit_up = 1 AND lu_type IS NOT NULL
            GROUP BY lu_type
            ORDER BY count DESC
            """
            
            type_df = pd.read_sql(query_4u, conn)
            if not type_df.empty:
                st.dataframe(type_df, use_container_width=True)
                
                # 4Uåˆ†å¸ƒåœ–
                fig2 = go.Figure(data=[go.Pie(
                    labels=type_df['lu_type'],
                    values=type_df['count'],
                    hole=.3
                )])
                fig2.update_layout(title="æ¼²åœé¡å‹åˆ†å¸ƒ (4Uåˆ†æ)")
                st.plotly_chart(fig2, use_container_width=True)
        
        # é€£æ¿çµ±è¨ˆ
        st.subheader("ğŸ† é€£æ¿å¤©æ•¸çµ±è¨ˆ")
        query_streak = """
        SELECT 
            consecutive_limits,
            COUNT(*) as stock_count,
            AVG(daily_change) as avg_next_day_change,
            AVG(ytd_ret) as avg_ytd_ret
        FROM stock_analysis 
        WHERE consecutive_limits > 0
        GROUP BY consecutive_limits
        ORDER BY consecutive_limits
        """
        
        streak_df = pd.read_sql(query_streak, conn)
        if not streak_df.empty:
            st.dataframe(streak_df, use_container_width=True)
        
        conn.close()
        
    except Exception as e:
        st.error(f"âŒ åˆ†æå¤±æ•—: {e}")

def render_annual_contribution():
    """å¹´åº¦è²¢ç»åº¦åˆ†æ"""
    st.title("ğŸ“‰ å¹´åº¦è²¢ç»åº¦åˆ†æ")
    
    if not os.path.exists(TARGET_DB):
        st.warning("âš ï¸ è«‹å…ˆåŒæ­¥è³‡æ–™åº«")
        return
    
    try:
        conn = sqlite3.connect(TARGET_DB)
        
        # å¹´åº¦è²¢ç»åº¦çµ±è¨ˆ
        query = """
        SELECT 
            year,
            symbol,
            AVG(peak_high_ret) as avg_peak_return,
            AVG(strong_day_contribution) as avg_strong_contribution,
            SUM(CASE WHEN is_limit_up = 1 THEN 1 ELSE 0 END) as limit_up_days,
            SUM(CASE WHEN daily_change > 0.095 THEN 1 ELSE 0 END) as strong_up_days
        FROM stock_analysis 
        WHERE year IS NOT NULL
        GROUP BY year, symbol
        HAVING avg_peak_return IS NOT NULL
        ORDER BY year, avg_peak_return DESC
        """
        
        annual_df = pd.read_sql(query, conn)
        
        if not annual_df.empty:
            # å¹´åº¦é¸æ“‡
            years = sorted(annual_df['year'].unique())
            selected_year = st.selectbox("é¸æ“‡å¹´åº¦", years, index=len(years)-1)
            
            # å¹´åº¦çµ±è¨ˆ
            year_data = annual_df[annual_df['year'] == selected_year]
            
            st.subheader(f"ğŸ“Š {selected_year} å¹´åº¦è²¢ç»åº¦åˆ†æ")
            
            # é ‚ç´šè²¢ç»è‚¡ç¥¨
            st.subheader("ğŸ† å¹´åº¦è²¢ç»åº¦æ’è¡Œæ¦œ")
            top_contributors = year_data.nlargest(10, 'avg_peak_return')
            st.dataframe(top_contributors, use_container_width=True)
            
            # æ•£é»åœ–ï¼šè²¢ç»åº¦ vs æ¼²åœå¤©æ•¸
            st.subheader("ğŸ“ˆ è²¢ç»åº¦èˆ‡æ¼²åœå¤©æ•¸é—œä¿‚")
            fig = go.Figure(data=go.Scatter(
                x=year_data['limit_up_days'],
                y=year_data['avg_peak_return'],
                mode='markers',
                marker=dict(
                    size=year_data['strong_up_days'],
                    color=year_data['avg_strong_contribution'],
                    colorscale='Viridis',
                    showscale=True,
                    colorbar=dict(title="å¼·å‹¢æ—¥è²¢ç»åº¦%")
                ),
                text=year_data['symbol'],
                hovertemplate='<b>%{text}</b><br>' +
                            'æ¼²åœå¤©æ•¸: %{x}<br>' +
                            'å¹´åº¦å·”å³°: %{y:.1f}%<br>' +
                            'å¼·å‹¢æ—¥è²¢ç»: %{marker.color:.1f}%<br>'
            ))
            fig.update_layout(
                title=f"{selected_year}å¹´ è²¢ç»åº¦åˆ†æ",
                xaxis_title="æ¼²åœå¤©æ•¸",
                yaxis_title="å¹´åº¦å·”å³°å ±é…¬ç‡ (%)"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        conn.close()
        
    except Exception as e:
        st.error(f"âŒ åˆ†æå¤±æ•—: {e}")

def render_debug_tools():
    """é™¤éŒ¯å·¥å…·é é¢"""
    st.title("ğŸ” è³‡æ–™åº«é™¤éŒ¯å·¥å…·")
    
    # é¡¯ç¤ºç’°å¢ƒè³‡è¨Š
    st.subheader("ç’°å¢ƒè³‡è¨Š")
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ä½œæ¥­ç³»çµ±**:", os.name)
        st.write("**ç•¶å‰ç›®éŒ„**:", os.getcwd())
        st.write("**Python ç‰ˆæœ¬**:", os.sys.version)
    
    with col2:
        st.write("**è³‡æ–™åº«æª”æ¡ˆ**:")
        for market in MARKET_MAP.values():
            db_file = f"{market}_stock_warehouse.db"
            if os.path.exists(db_file):
                st.success(f"âœ… {db_file} - {os.path.getsize(db_file):,} bytes")
            else:
                st.error(f"âŒ {db_file} - ä¸å­˜åœ¨")
    
    # æª¢æŸ¥é…ç½®
    st.subheader("é…ç½®æª¢æŸ¥")
    gdrive_sa = get_config_value("GDRIVE_SERVICE_ACCOUNT")
    if gdrive_sa:
        st.success("âœ… GDRIVE_SERVICE_ACCOUNT å·²è¨­å®š")
        # é¡¯ç¤ºéƒ¨åˆ†è³‡è¨Š (ä¿è­·æ•æ„Ÿè³‡æ–™)
        if isinstance(gdrive_sa, str):
            try:
                sa_info = json.loads(gdrive_sa)
                st.write("**æœå‹™å¸³æˆ¶**:", sa_info.get("client_email", "æœªçŸ¥"))
            except:
                st.write("**æœå‹™å¸³æˆ¶**: JSON æ ¼å¼æ­£ç¢º")
    else:
        st.error("âŒ GDRIVE_SERVICE_ACCOUNT æœªè¨­å®š")
    
    folder_id = get_config_value("GDRIVE_FOLDER_ID")
    if folder_id:
        st.success(f"âœ… GDRIVE_FOLDER_ID å·²è¨­å®š: {folder_id}")
    else:
        st.warning("âš ï¸ GDRIVE_FOLDER_ID æœªè¨­å®š")
    
    # è³‡æ–™åº«æª¢æŸ¥
    if os.path.exists(TARGET_DB):
        st.subheader("è³‡æ–™åº«æª¢æŸ¥")
        try:
            conn = sqlite3.connect(TARGET_DB)
            cursor = conn.cursor()
            
            # æª¢æŸ¥è¡¨æ ¼
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            tables = cursor.fetchall()
            
            st.write("**è³‡æ–™åº«è¡¨æ ¼**:")
            for table in tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table[0]};")
                count = cursor.fetchone()[0]
                st.write(f"- {table[0]}: {count:,} ç­†è¨˜éŒ„")
            
            conn.close()
        except Exception as e:
            st.error(f"è³‡æ–™åº«æª¢æŸ¥å¤±æ•—: {e}")

# --- 6. é é¢è·¯ç”± ---
page_mapping = {
    "home": render_home_page,
    "weekly": render_weekly_analysis,
    "monthly": render_monthly_analysis,
    "limit_up": render_limit_up_analysis,
    "annual_contribution": render_annual_contribution,
    "debug": render_debug_tools
}

# æ ¹æ“šé¸æ“‡æ¸²æŸ“é é¢
selected_page_id = page_options[selected_page]
page_mapping[selected_page_id]()
