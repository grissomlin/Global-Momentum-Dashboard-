# -*- coding: utf-8 -*-
"""
downloader_kr.py
----------------
éŸ“åœ‹è‚¡å¸‚è³‡æ–™ä¸‹è¼‰å™¨ (èˆ‡ä¸»ç³»çµ±å…¼å®¹ç‰ˆ)

âœ” ä½¿ç”¨æœ¬åœ° CSV æ–‡ä»¶ç²å–è‚¡ç¥¨æ¸…å–® (krx_corp_list.csv)
âœ” æ”¯æŒå¢é‡ä¸‹è¼‰ (start_date, end_date åƒæ•¸)
âœ” èˆ‡ä¸»ç³»çµ±çš„ main.py å’Œ processor.py å…¼å®¹
âœ” ä¿ç•™é›²ç«¯åŒæ­¥åŠŸèƒ½
"""

import os, sys, time, sqlite3, csv, json, io
import pandas as pd
import yfinance as yf
from datetime import datetime, timedelta
from tqdm import tqdm
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload

# ========== é…ç½® ==========
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(BASE_DIR, "kr_stock_warehouse.db")
CSV_PATH = os.path.join(BASE_DIR, "krx_corp_list.csv")

# å¾ç’°å¢ƒè®Šæ•¸ç²å– Google Drive é…ç½®
import os
from dotenv import load_dotenv
load_dotenv()

GDRIVE_FOLDER_ID = os.environ.get('GDRIVE_FOLDER_ID')

def log(msg: str):
    print(f"{datetime.now().strftime('%H:%M:%S')}: {msg}", flush=True)

# ========== é›²ç«¯æœå‹™å‡½æ•¸ ==========
def get_drive_service():
    """ç²å– Google Drive æœå‹™å¯¦ä¾‹"""
    env_json = os.environ.get('GDRIVE_SERVICE_ACCOUNT')
    try:
        if env_json:
            info = json.loads(env_json)
            creds = service_account.Credentials.from_service_account_info(
                info, scopes=['https://www.googleapis.com/auth/drive'])
            return build('drive', 'v3', credentials=creds, cache_discovery=False)
        return None
    except Exception as e:
        log(f"âŒ Drive æœå‹™åˆå§‹åŒ–å¤±æ•—: {e}")
        return None

def download_db_from_drive(service, file_name):
    """å¾ Google Drive ä¸‹è¼‰è³‡æ–™åº«"""
    if not GDRIVE_FOLDER_ID or not service:
        return False
    
    query = f"name = '{file_name}' and '{GDRIVE_FOLDER_ID}' in parents and trashed = false"
    try:
        results = service.files().list(q=query, fields="files(id)").execute()
        items = results.get('files', [])
        if not items:
            return False
        
        file_id = items[0]['id']
        log(f"ğŸ“¡ å¾é›²ç«¯åŒæ­¥éŸ“åœ‹è³‡æ–™åº«: {file_name}")
        request = service.files().get_media(fileId=file_id)
        with io.FileIO(file_name, 'wb') as fh:
            downloader = MediaIoBaseDownload(fh, request, chunksize=5*1024*1024)
            done = False
            while not done:
                _, done = downloader.next_chunk()
        return True
    except Exception as e:
        log(f"âš ï¸ é›²ç«¯ä¸‹è¼‰å¤±æ•—: {e}")
        return False

def upload_db_to_drive(service, file_path):
    """ä¸Šå‚³è³‡æ–™åº«åˆ° Google Drive"""
    if not GDRIVE_FOLDER_ID or not service or not os.path.exists(file_path):
        return False
    
    file_name = os.path.basename(file_path)
    file_size = os.path.getsize(file_path)
    
    # æ ¹æ“šæ–‡ä»¶å¤§å°èª¿æ•´åˆ†ç‰‡å¤§å°
    chunk_size = 5 * 1024 * 1024
    if file_size > 100 * 1024 * 1024:
        chunk_size = 10 * 1024 * 1024
    
    try:
        media = MediaFileUpload(file_path, mimetype='application/x-sqlite3', 
                               resumable=True, chunksize=chunk_size)
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        query = f"name = '{file_name}' and '{GDRIVE_FOLDER_ID}' in parents and trashed = false"
        results = service.files().list(q=query, fields="files(id)").execute()
        items = results.get('files', [])
        
        if items:
            # æ›´æ–°ç¾æœ‰æ–‡ä»¶
            request = service.files().update(fileId=items[0]['id'], media_body=media, fields='id')
            log("ğŸ”„ æ›´æ–°é›²ç«¯éŸ“åœ‹è³‡æ–™åº«")
        else:
            # å‰µå»ºæ–°æ–‡ä»¶
            meta = {'name': file_name, 'parents': [GDRIVE_FOLDER_ID]}
            request = service.files().create(body=meta, media_body=media, fields='id')
            log("ğŸ†• å‰µå»ºé›²ç«¯éŸ“åœ‹è³‡æ–™åº«")
        
        response = None
        while response is None:
            status, response = request.next_chunk()
            if status:
                log(f"  ä¸Šå‚³é€²åº¦: {int(status.progress() * 100)}%")
        
        log("âœ… éŸ“åœ‹è³‡æ–™åº«ä¸Šå‚³æˆåŠŸ")
        return True
        
    except Exception as e:
        log(f"âŒ ä¸Šå‚³å¤±æ•—: {e}")
        return False

# ========== è³‡æ–™åº«åˆå§‹åŒ– ==========
def init_db():
    """åˆå§‹åŒ–è³‡æ–™åº«è¡¨æ ¼"""
    conn = sqlite3.connect(DB_PATH)
    try:
        # è‚¡åƒ¹è³‡æ–™è¡¨
        conn.execute('''CREATE TABLE IF NOT EXISTS stock_prices (
                            date TEXT, 
                            symbol TEXT, 
                            open REAL, 
                            high REAL, 
                            low REAL, 
                            close REAL, 
                            volume INTEGER,
                            PRIMARY KEY (date, symbol))''')
        
        # è‚¡ç¥¨è³‡è¨Šè¡¨ (å…¼å®¹ processor.py éœ€è¦çš„å­—æ®µ)
        conn.execute('''CREATE TABLE IF NOT EXISTS stock_info (
                            symbol TEXT PRIMARY KEY, 
                            name TEXT, 
                            sector TEXT, 
                            market TEXT,
                            market_detail TEXT,
                            updated_at TEXT)''')
        
        # å‰µå»ºç´¢å¼•
        conn.execute('''CREATE INDEX IF NOT EXISTS idx_symbol_date 
                       ON stock_prices (symbol, date)''')
        
    finally:
        conn.close()
    log("âœ… éŸ“åœ‹è³‡æ–™åº«åˆå§‹åŒ–å®Œæˆ")

# ========== è‚¡ç¥¨æ¸…å–®è™•ç† ==========
def get_kr_stock_list():
    """å¾ CSV æ–‡ä»¶ç²å–éŸ“åœ‹è‚¡ç¥¨æ¸…å–®"""
    log("ğŸ“¡ è®€å–éŸ“åœ‹è‚¡ç¥¨æ¸…å–®...")
    
    if not os.path.exists(CSV_PATH):
        log(f"âŒ æ‰¾ä¸åˆ°è‚¡ç¥¨æ¸…å–®æ–‡ä»¶: {CSV_PATH}")
        return []
    
    stocks = []
    conn = sqlite3.connect(DB_PATH)
    
    try:
        with open(CSV_PATH, 'r', encoding='utf-8-sig') as f:
            # è·³éå¯èƒ½çš„ BOM å­—å…ƒ
            if f.read(1) == '\ufeff':
                f.seek(1)
            else:
                f.seek(0)
            
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    # æå–è‚¡ç¥¨è³‡è¨Š
                    company_name = row.get('íšŒì‚¬ëª…', '').strip()
                    market = row.get('ì‹œì¥êµ¬ë¶„', '').strip()
                    code = row.get('ì¢…ëª©ì½”ë“œ', '').strip().zfill(6)
                    sector = row.get('ì—…ì¢…', '').strip()
                    region = row.get('ì§€ì—­', '').strip()
                    listing_date = row.get('ìƒì¥ì¼', '').strip()
                    
                    # æ±ºå®šå¸‚å ´å¾Œç¶´
                    if market == 'ìœ ê°€':
                        suffix = '.KS'  # KOSPI
                        market_detail = 'main'
                    elif market == 'ì½”ìŠ¤ë‹¥':
                        suffix = '.KQ'  # KOSDAQ
                        market_detail = 'kosdaq'
                    elif market == 'ì½”ë„¥ìŠ¤':
                        suffix = '.KN'  # KONEX
                        market_detail = 'konex'
                    else:
                        continue  # å¿½ç•¥å…¶ä»–å¸‚å ´
                    
                    symbol = f"{code}{suffix}"
                    
                    # å­˜å…¥ stock_info è¡¨
                    conn.execute("""
                        INSERT OR REPLACE INTO stock_info 
                        (symbol, name, sector, market, market_detail, updated_at) 
                        VALUES (?, ?, ?, ?, ?, ?)
                    """, (symbol, company_name, sector, market, market_detail, 
                          datetime.now().strftime("%Y-%m-%d")))
                    
                    stocks.append((symbol, company_name))
                    
                except Exception as e:
                    log(f"âš ï¸ è™•ç†è‚¡ç¥¨è¡Œæ™‚å‡ºéŒ¯: {e}")
                    continue
        
        conn.commit()
        log(f"âœ… è‚¡ç¥¨æ¸…å–®è¼‰å…¥å®Œæˆ: {len(stocks)} æª”")
        return stocks
        
    except Exception as e:
        log(f"âŒ è®€å– CSV å¤±æ•—: {e}")
        return []
    finally:
        conn.close()

# ========== å–®ä¸€è‚¡ç¥¨ä¸‹è¼‰ ==========
def download_one_stock(symbol, start_date, end_date):
    """ä¸‹è¼‰å–®ä¸€è‚¡ç¥¨æ­·å²æ•¸æ“š"""
    max_retries = 3
    
    for attempt in range(max_retries):
        try:
            # ä½¿ç”¨ yfinance ä¸‹è¼‰ï¼Œç¦ç”¨å¤šåŸ·è¡Œç·’é¿å…å•é¡Œ
            df = yf.download(
                symbol, 
                start=start_date, 
                end=end_date,
                progress=False,
                auto_adjust=True,
                threads=False,
                timeout=30
            )
            
            if df is None or df.empty:
                if attempt < max_retries - 1:
                    time.sleep(2)
                    continue
                return None
            
            # æ¸…ç†æ•¸æ“šæ ¼å¼
            if isinstance(df.columns, pd.MultiIndex):
                df.columns = df.columns.get_level_values(0)
            
            df.reset_index(inplace=True)
            df.columns = [col.lower() for col in df.columns]
            
            # æ¨™æº–åŒ–æ—¥æœŸæ ¼å¼
            date_col = 'date' if 'date' in df.columns else df.columns[0]
            df['date_str'] = pd.to_datetime(df[date_col]).dt.strftime('%Y-%m-%d')
            
            # é¸æ“‡éœ€è¦çš„æ¬„ä½
            required_cols = ['date_str', 'open', 'high', 'low', 'close', 'volume']
            available_cols = [col for col in required_cols if col in df.columns]
            
            if 'date_str' not in available_cols:
                return None
            
            df_final = df[available_cols].copy()
            df_final.columns = ['date', 'open', 'high', 'low', 'close', 'volume']
            df_final['symbol'] = symbol
            
            return df_final
            
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(3)
                continue
            log(f"âš ï¸ ä¸‹è¼‰å¤±æ•— {symbol}: {e}")
            return None

# ========== ä¸»ä¸‹è¼‰å‡½æ•¸ ==========
def run_sync(start_date=None, end_date=None):
    """
    éŸ“åœ‹è‚¡å¸‚åŒæ­¥ä¸»å‡½æ•¸
    
    åƒæ•¸:
        start_date: é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: çµæŸæ—¥æœŸ (YYYY-MM-DD)
    """
    start_time = time.time()
    
    # è¨­ç½®æ—¥æœŸç¯„åœ
    if not start_date:
        start_date = "2023-01-01"
    if not end_date:
        end_date = datetime.now().strftime("%Y-%m-%d")
    
    log(f"ğŸš€ å•Ÿå‹•éŸ“åœ‹è‚¡å¸‚åŒæ­¥ | æœŸé–“: {start_date} ~ {end_date}")
    
    # åˆå§‹åŒ–è³‡æ–™åº«
    init_db()
    
    # é›²ç«¯åŒæ­¥
    service = get_drive_service()
    if service:
        download_db_from_drive(service, "kr_stock_warehouse.db")
    
    # ç²å–è‚¡ç¥¨æ¸…å–®
    stocks = get_kr_stock_list()
    if not stocks:
        log("âŒ æ²’æœ‰å¯ä¸‹è¼‰çš„è‚¡ç¥¨")
        return {"success": 0, "total": 0, "has_changed": False}
    
    log(f"ğŸ“Š é–‹å§‹ä¸‹è¼‰ {len(stocks)} æª”éŸ“åœ‹è‚¡ç¥¨")
    
    # é€£æ¥è³‡æ–™åº«
    conn = sqlite3.connect(DB_PATH, timeout=60)
    success_count = 0
    
    # é€²åº¦æ¢
    pbar = tqdm(stocks, desc="éŸ“åœ‹ä¸‹è¼‰", unit="æª”")
    for symbol, name in pbar:
        pbar.set_postfix({"è‚¡ç¥¨": name[:10]})
        
        df = download_one_stock(symbol, start_date, end_date)
        
        if df is not None and not df.empty:
            try:
                # å­˜å…¥è³‡æ–™åº«
                df.to_sql(
                    'stock_prices', 
                    conn, 
                    if_exists='append', 
                    index=False,
                    method=lambda table, conn, keys, data_iter: 
                    conn.executemany(
                        f"INSERT OR REPLACE INTO {table.name} ({', '.join(keys)}) VALUES ({', '.join(['?']*len(keys))})", 
                        data_iter
                    )
                )
                success_count += 1
            except Exception as e:
                log(f"âš ï¸ å­˜å…¥è³‡æ–™åº«å¤±æ•— {symbol}: {e}")
        
        # æ§åˆ¶ä¸‹è¼‰é€Ÿåº¦
        time.sleep(0.1)
    
    conn.commit()
    
    # åŸ·è¡Œè³‡æ–™åº«å„ªåŒ–
    log("ğŸ§¹ å„ªåŒ–è³‡æ–™åº«...")
    conn.execute("VACUUM")
    conn.close()
    
    # ä¸Šå‚³åˆ°é›²ç«¯
    if service and success_count > 0:
        upload_db_to_drive(service, DB_PATH)
    
    # è¨ˆç®—åŸ·è¡Œæ™‚é–“
    duration = (time.time() - start_time) / 60
    
    log(f"""
âœ… éŸ“åœ‹è‚¡å¸‚åŒæ­¥å®Œæˆï¼
ğŸ“Š çµ±è¨ˆ:
   - æˆåŠŸä¸‹è¼‰: {success_count}/{len(stocks)} æª”
   - è³‡æ–™æœŸé–“: {start_date} ~ {end_date}
   - åŸ·è¡Œæ™‚é–“: {duration:.1f} åˆ†é˜
    """)
    
    return {
        "success": success_count, 
        "total": len(stocks), 
        "has_changed": success_count > 0
    }

# ========== å‘½ä»¤è¡Œç›´æ¥åŸ·è¡Œ ==========
if __name__ == "__main__":
    # è§£æå‘½ä»¤è¡Œåƒæ•¸
    start_date = None
    end_date = None
    
    if len(sys.argv) > 1:
        for arg in sys.argv[1:]:
            if arg.startswith("--start="):
                start_date = arg.split("=")[1]
            elif arg.startswith("--end="):
                end_date = arg.split("=")[1]
    
    run_sync(start_date, end_date)
