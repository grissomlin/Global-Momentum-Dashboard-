# -*- coding: utf-8 -*-
"""
downloader_kr.py
----------------
éŸ“åœ‹è‚¡å¸‚è³‡æ–™ä¸‹è¼‰å™¨ (èˆ‡ä¸»ç³»çµ±å…¼å®¹ç‰ˆ)

âœ” å„ªå…ˆå˜—è©¦å¾ KRX KIND ä¸‹è¼‰å…¬å¸æ¸…å–®ï¼ˆå¤±æ•—æ‰ fallback æœ¬åœ° CSVï¼‰
âœ” æ”¯æŒå¢é‡ä¸‹è¼‰ (start_date, end_date åƒæ•¸)
âœ” èˆ‡ main.py / processor.py å…¼å®¹ï¼ˆstock_prices + stock_infoï¼‰
âœ” ä¿ç•™é›²ç«¯åŒæ­¥åŠŸèƒ½ï¼ˆä½†æœƒé¿å…ã€Œä¸‹è¼‰èˆŠ DB æ²’è¡¨ã€é€ æˆ stock_info ä¸å­˜åœ¨ï¼‰
"""

import os
import sys
import time
import sqlite3
import csv
import json
import io
from datetime import datetime

import pandas as pd
import yfinance as yf
import requests
from tqdm import tqdm
from dotenv import load_dotenv

from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload


# ========== é…ç½® ==========
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(BASE_DIR, "kr_stock_warehouse.db")
CSV_PATH = os.path.join(BASE_DIR, "krx_corp_list.csv")

# KRX corp list ä¸‹è¼‰ç¶²å€ï¼ˆä½ æä¾›çš„ï¼‰
KRX_CORP_LIST_URL = "http://kind.krx.co.kr/corpgeneral/corpList.do?method=download&searchType=13"
KRX_CORP_LIST_REFERER = "http://kind.krx.co.kr/corpgeneral/corpList.do"

# Env
load_dotenv()
GDRIVE_FOLDER_ID = os.environ.get("GDRIVE_FOLDER_ID")


def log(msg: str):
    print(f"{datetime.now().strftime('%H:%M:%S')}: {msg}", flush=True)


# ========== é›²ç«¯æœå‹™å‡½æ•¸ ==========
def get_drive_service():
    """ç²å– Google Drive æœå‹™å¯¦ä¾‹"""
    env_json = os.environ.get("GDRIVE_SERVICE_ACCOUNT")
    try:
        if env_json:
            info = json.loads(env_json)
            creds = service_account.Credentials.from_service_account_info(
                info, scopes=["https://www.googleapis.com/auth/drive"]
            )
            return build("drive", "v3", credentials=creds, cache_discovery=False)
        return None
    except Exception as e:
        log(f"âŒ Drive æœå‹™åˆå§‹åŒ–å¤±æ•—: {e}")
        return None


def download_db_from_drive(service, file_name: str, local_path: str):
    """å¾ Google Drive ä¸‹è¼‰è³‡æ–™åº«åˆ°æŒ‡å®šè·¯å¾‘"""
    if not GDRIVE_FOLDER_ID or not service:
        return False

    query = f"name = '{file_name}' and '{GDRIVE_FOLDER_ID}' in parents and trashed = false"
    try:
        results = service.files().list(q=query, fields="files(id)").execute()
        items = results.get("files", [])
        if not items:
            log(f"â„¹ï¸ é›²ç«¯æ²’æœ‰ {file_name}ï¼ˆå°‡ä½¿ç”¨æœ¬åœ°æ–°å»º/æ—¢æœ‰ DBï¼‰")
            return False

        file_id = items[0]["id"]
        log(f"ğŸ“¡ å¾é›²ç«¯åŒæ­¥éŸ“åœ‹è³‡æ–™åº«: {file_name} -> {local_path}")

        request = service.files().get_media(fileId=file_id)
        os.makedirs(os.path.dirname(local_path), exist_ok=True)

        with io.FileIO(local_path, "wb") as fh:
            downloader = MediaIoBaseDownload(fh, request, chunksize=5 * 1024 * 1024)
            done = False
            while not done:
                _, done = downloader.next_chunk()

        log("âœ… é›²ç«¯ä¸‹è¼‰å®Œæˆ")
        return True

    except Exception as e:
        log(f"âš ï¸ é›²ç«¯ä¸‹è¼‰å¤±æ•—: {e}")
        return False


def upload_db_to_drive(service, file_path: str):
    """ä¸Šå‚³è³‡æ–™åº«åˆ° Google Drive"""
    if not GDRIVE_FOLDER_ID or not service or not os.path.exists(file_path):
        return False

    file_name = os.path.basename(file_path)
    file_size = os.path.getsize(file_path)

    chunk_size = 5 * 1024 * 1024
    if file_size > 100 * 1024 * 1024:
        chunk_size = 10 * 1024 * 1024

    try:
        media = MediaFileUpload(
            file_path, mimetype="application/x-sqlite3", resumable=True, chunksize=chunk_size
        )

        query = f"name = '{file_name}' and '{GDRIVE_FOLDER_ID}' in parents and trashed = false"
        results = service.files().list(q=query, fields="files(id)").execute()
        items = results.get("files", [])

        if items:
            request = service.files().update(fileId=items[0]["id"], media_body=media, fields="id")
            log("ğŸ”„ æ›´æ–°é›²ç«¯éŸ“åœ‹è³‡æ–™åº«")
        else:
            meta = {"name": file_name, "parents": [GDRIVE_FOLDER_ID]}
            request = service.files().create(body=meta, media_body=media, fields="id")
            log("ğŸ†• å‰µå»ºé›²ç«¯éŸ“åœ‹è³‡æ–™åº«")

        response = None
        while response is None:
            status, response = request.next_chunk()
            if status:
                log(f"  ä¸Šå‚³é€²åº¦: {int(status.progress() * 100)}%")

        log("âœ… éŸ“åœ‹è³‡æ–™åº«ä¸Šå‚³æˆåŠŸ")
        return True

    except Exception as e:
        log(f"âŒ ä¸Šå‚³å¤±æ•—: {e}")
        return False


# ========== DB schema ==========
def init_db():
    """åˆå§‹åŒ–è³‡æ–™åº«è¡¨æ ¼ï¼ˆä¸€å®šè¦èƒ½è£œé½Š stock_infoï¼‰"""
    conn = sqlite3.connect(DB_PATH)
    try:
        # stock_pricesï¼ˆèˆ‡ processor.py æŸ¥è©¢å…¼å®¹ï¼‰
        conn.execute(
            """CREATE TABLE IF NOT EXISTS stock_prices (
                date TEXT,
                symbol TEXT,
                open REAL,
                high REAL,
                low REAL,
                close REAL,
                volume INTEGER,
                PRIMARY KEY (date, symbol)
            )"""
        )

        # stock_infoï¼ˆprocessor éœ€è¦ market/sector/market_detailï¼‰
        conn.execute(
            """CREATE TABLE IF NOT EXISTS stock_info (
                symbol TEXT PRIMARY KEY,
                name TEXT,
                sector TEXT,
                market TEXT,
                market_detail TEXT,
                updated_at TEXT
            )"""
        )

        # index
        conn.execute(
            """CREATE INDEX IF NOT EXISTS idx_symbol_date
               ON stock_prices (symbol, date)"""
        )
    finally:
        conn.close()

    log("âœ… éŸ“åœ‹è³‡æ–™åº«åˆå§‹åŒ–å®Œæˆï¼ˆå« stock_info/stock_pricesï¼‰")


# ========== KRX corp listï¼šå…ˆæŠ“ URLï¼Œå¤±æ•—æ‰ç”¨æœ¬åœ° ==========
def try_download_krx_corp_list_csv(save_path: str = CSV_PATH) -> bool:
    """
    å˜—è©¦å¾ KRX KIND ä¸‹è¼‰å…¬å¸æ¸…å–®ä¸¦å­˜æˆ CSVï¼ˆUTF-8-SIGï¼‰
    æˆåŠŸå› Trueï¼›å¤±æ•—å› Falseï¼ˆå¾ŒçºŒå¯ fallback æœ¬åœ°æª”ï¼‰
    """
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/119.0.0.0 Safari/537.36"
        ),
        "Referer": KRX_CORP_LIST_REFERER,
    }

    log("ğŸ“¡ å˜—è©¦å¾ KRX KIND ä¸‹è¼‰å…¬å¸æ¸…å–®ï¼ˆè‹¥è¢«æ“‹æœƒ fallback æœ¬åœ° CSVï¼‰")

    try:
        resp = requests.get(KRX_CORP_LIST_URL, headers=headers, timeout=30)
        resp.raise_for_status()

        # KIND é€™å€‹ endpoint é€šå¸¸å›å‚³ HTML table
        dfs = pd.read_html(io.BytesIO(resp.content))
        if not dfs:
            log("âš ï¸ å·²å–å¾—å›æ‡‰ï¼Œä½†æ‰¾ä¸åˆ°è¡¨æ ¼ï¼ˆread_html è§£æä¸åˆ°ï¼‰")
            return False

        df = dfs[0]
        if df is None or df.empty:
            log("âš ï¸ è¡¨æ ¼ç‚ºç©ºï¼ˆå¯èƒ½è¢«å°å‘/é˜»æ“‹/å…§å®¹è®Šæ›´ï¼‰")
            return False

        # å­˜æˆ csv
        df.to_csv(save_path, index=False, encoding="utf-8-sig")
        log(f"âœ… KRX å…¬å¸æ¸…å–®ä¸‹è¼‰æˆåŠŸï¼Œå·²å­˜æˆ: {save_path}")
        return True

    except Exception as e:
        log(f"âš ï¸ KRX ä¸‹è¼‰å¤±æ•—ï¼š{e}")
        return False


# ========== è‚¡ç¥¨æ¸…å–®è™•ç† ==========
def get_kr_stock_list():
    """
    å¾ CSV æ–‡ä»¶ç²å–éŸ“åœ‹è‚¡ç¥¨æ¸…å–®ï¼Œä¸¦åŒæ­¥å¯«å…¥ stock_infoã€‚
    - market å›ºå®šå¯« 'KR'
    - market_detail å¯« 'KOSPI' / 'KOSDAQ' / 'KONEX'ï¼ˆè®“ processor åˆ¤æ–·æ›´ç©©ï¼‰
    """
    log("ğŸ“¡ è®€å–éŸ“åœ‹è‚¡ç¥¨æ¸…å–®...")

    # 1) è‹¥æœ¬åœ° CSV ä¸å­˜åœ¨ï¼Œå…ˆå˜—è©¦æŠ“ KRX
    if not os.path.exists(CSV_PATH):
        ok = try_download_krx_corp_list_csv(CSV_PATH)
        if not ok and not os.path.exists(CSV_PATH):
            log(f"âŒ æ‰¾ä¸åˆ°è‚¡ç¥¨æ¸…å–®æ–‡ä»¶ä¸”ç„¡æ³•å¾ç¶²è·¯å–å¾—: {CSV_PATH}")
            return []

    stocks = []
    conn = sqlite3.connect(DB_PATH)

    try:
        with open(CSV_PATH, "r", encoding="utf-8-sig") as f:
            # è™•ç† BOM
            first = f.read(1)
            if first != "\ufeff":
                f.seek(0)

            reader = csv.DictReader(f)
            for row in reader:
                try:
                    company_name = (row.get("íšŒì‚¬ëª…", "") or "").strip()
                    market_kor = (row.get("ì‹œì¥êµ¬ë¶„", "") or "").strip()
                    code = (row.get("ì¢…ëª©ì½”ë“œ", "") or "").strip().zfill(6)
                    sector = (row.get("ì—…ì¢…", "") or "").strip()

                    if not company_name or not code:
                        continue

                    # å¸‚å ´å°æ‡‰
                    if market_kor == "ìœ ê°€":
                        suffix = ".KS"
                        market_detail = "KOSPI"
                    elif market_kor == "ì½”ìŠ¤ë‹¥":
                        suffix = ".KQ"
                        market_detail = "KOSDAQ"
                    elif market_kor == "ì½”ë„¥ìŠ¤":
                        suffix = ".KN"
                        market_detail = "KONEX"
                    else:
                        continue

                    symbol = f"{code}{suffix}"

                    conn.execute(
                        """
                        INSERT OR REPLACE INTO stock_info
                        (symbol, name, sector, market, market_detail, updated_at)
                        VALUES (?, ?, ?, ?, ?, ?)
                        """,
                        (
                            symbol,
                            company_name,
                            sector,
                            "KR",
                            market_detail,
                            datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        ),
                    )

                    stocks.append((symbol, company_name))

                except Exception as e:
                    log(f"âš ï¸ è™•ç†è‚¡ç¥¨è¡Œæ™‚å‡ºéŒ¯: {e}")
                    continue

        conn.commit()
        log(f"âœ… è‚¡ç¥¨æ¸…å–®è¼‰å…¥å®Œæˆ: {len(stocks)} æª”")
        return stocks

    except Exception as e:
        log(f"âŒ è®€å– CSV å¤±æ•—: {e}")
        return []
    finally:
        conn.close()


# ========== å–®ä¸€è‚¡ç¥¨ä¸‹è¼‰ ==========
def download_one_stock(symbol: str, start_date: str, end_date: str):
    """ä¸‹è¼‰å–®ä¸€è‚¡ç¥¨æ­·å²æ•¸æ“š"""
    max_retries = 3

    for attempt in range(max_retries):
        try:
            df = yf.download(
                symbol,
                start=start_date,
                end=end_date,
                progress=False,
                auto_adjust=True,
                threads=False,
                timeout=30,
            )

            if df is None or df.empty:
                if attempt < max_retries - 1:
                    time.sleep(2)
                    continue
                return None

            if isinstance(df.columns, pd.MultiIndex):
                df.columns = df.columns.get_level_values(0)

            df.reset_index(inplace=True)
            df.columns = [str(c).lower() for c in df.columns]

            date_col = "date" if "date" in df.columns else df.columns[0]
            df["date"] = pd.to_datetime(df[date_col]).dt.strftime("%Y-%m-%d")

            # ç¢ºä¿æ¬„ä½å­˜åœ¨
            for col in ["open", "high", "low", "close", "volume"]:
                if col not in df.columns:
                    df[col] = None

            df_final = df[["date", "open", "high", "low", "close", "volume"]].copy()
            df_final["symbol"] = symbol
            return df_final

        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(3)
                continue
            log(f"âš ï¸ ä¸‹è¼‰å¤±æ•— {symbol}: {e}")
            return None


# ========== ä¸»ä¸‹è¼‰å‡½æ•¸ ==========
def run_sync(start_date=None, end_date=None):
    """
    éŸ“åœ‹è‚¡å¸‚åŒæ­¥ä¸»å‡½æ•¸

    åƒæ•¸:
        start_date: é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: çµæŸæ—¥æœŸ (YYYY-MM-DD)
    """
    start_time = time.time()

    if not start_date:
        start_date = "2023-01-01"
    if not end_date:
        end_date = datetime.now().strftime("%Y-%m-%d")

    log(f"ğŸš€ å•Ÿå‹•éŸ“åœ‹è‚¡å¸‚åŒæ­¥ | æœŸé–“: {start_date} ~ {end_date}")

    # 1) é›²ç«¯åŒæ­¥ï¼šå…ˆä¸‹è¼‰èˆŠ DBï¼ˆå¦‚æœæœ‰ï¼‰
    service = get_drive_service()
    if service:
        download_db_from_drive(service, "kr_stock_warehouse.db", local_path=DB_PATH)

    # âœ… 2) é—œéµï¼šä¸‹è¼‰å¾Œå†è£œ schemaï¼ˆèˆŠ DB æ²’ stock_info ä¹Ÿèƒ½è£œï¼‰
    init_db()

    # 3) è‚¡ç¥¨æ¸…å–®ï¼ˆå…ˆæŠ“ URLï¼Œä¸è¡Œæ‰ç”¨æœ¬åœ°ï¼‰
    stocks = get_kr_stock_list()
    if not stocks:
        log("âŒ æ²’æœ‰å¯ä¸‹è¼‰çš„è‚¡ç¥¨ï¼ˆcorp list ç©ºæˆ–æŠ“å–å¤±æ•—ï¼‰")
        return {"success": 0, "total": 0, "has_changed": False}

    log(f"ğŸ“Š é–‹å§‹ä¸‹è¼‰ {len(stocks)} æª”éŸ“åœ‹è‚¡ç¥¨")

    conn = sqlite3.connect(DB_PATH, timeout=60)
    success_count = 0

    pbar = tqdm(stocks, desc="éŸ“åœ‹ä¸‹è¼‰", unit="æª”")
    for symbol, name in pbar:
        pbar.set_postfix({"è‚¡ç¥¨": name[:10]})

        df = download_one_stock(symbol, start_date, end_date)

        if df is not None and not df.empty:
            try:
                df.to_sql(
                    "stock_prices",
                    conn,
                    if_exists="append",
                    index=False,
                    method=lambda table, _conn, keys, data_iter: _conn.executemany(
                        f"INSERT OR REPLACE INTO {table.name} ({', '.join(keys)}) "
                        f"VALUES ({', '.join(['?']*len(keys))})",
                        data_iter,
                    ),
                )
                success_count += 1
            except Exception as e:
                log(f"âš ï¸ å­˜å…¥è³‡æ–™åº«å¤±æ•— {symbol}: {e}")

        time.sleep(0.1)

    conn.commit()

    log("ğŸ§¹ å„ªåŒ–è³‡æ–™åº«...")
    try:
        conn.execute("VACUUM")
    except Exception as e:
        log(f"âš ï¸ VACUUM å¤±æ•—ï¼ˆå¯å¿½ç•¥ï¼‰: {e}")
    conn.close()

    # 4) ä¸Šå‚³åˆ°é›²ç«¯
    if service and success_count > 0:
        upload_db_to_drive(service, DB_PATH)

    duration = (time.time() - start_time) / 60

    log(
        f"""
âœ… éŸ“åœ‹è‚¡å¸‚åŒæ­¥å®Œæˆï¼
ğŸ“Š çµ±è¨ˆ:
   - æˆåŠŸä¸‹è¼‰: {success_count}/{len(stocks)} æª”
   - è³‡æ–™æœŸé–“: {start_date} ~ {end_date}
   - åŸ·è¡Œæ™‚é–“: {duration:.1f} åˆ†é˜
"""
    )

    return {"success": success_count, "total": len(stocks), "has_changed": success_count > 0}


if __name__ == "__main__":
    start_date = None
    end_date = None

    if len(sys.argv) > 1:
        for arg in sys.argv[1:]:
            if arg.startswith("--start="):
                start_date = arg.split("=", 1)[1]
            elif arg.startswith("--end="):
                end_date = arg.split("=", 1)[1]

    run_sync(start_date, end_date)
