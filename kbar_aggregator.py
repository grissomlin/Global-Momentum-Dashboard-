# -*- coding: utf-8 -*-
"""
kbar_aggregator.py
------------------
æŠŠæ—¥K stock_prices èšåˆæˆï¼š
- kbar_weekly  (å‘¨K)
- kbar_monthly (æœˆK)
- kbar_yearly  (å¹´K + å¹´å…§æœ€é«˜é» peak_date/peak_high)

âœ… åªä¾è³´ SQLite + pandas
âœ… ä¸æ”¹å‹•åŸå§‹ stock_prices
âœ… å°é½Šå„€è¡¨æ¿éœ€æ±‚ï¼šé€±/æœˆK å¯å°åˆ°å¹´Kçš„ peak_dateï¼ˆå¾ŒçºŒ event_engine åšè²¢ç»åº¦æ›´ä¹¾æ·¨ï¼‰

DB ä¾è³´è¡¨ï¼š
- stock_prices(symbol,date,open,high,low,close,volume)
- stock_info(symbol, market, market_detail, ...)  (å¯ç„¡ï¼›æ²’æœ‰ä¹Ÿèƒ½è·‘)

ç”¢å‡ºè¡¨ï¼š
- kbar_weekly
- kbar_monthly
- kbar_yearly

ä½¿ç”¨æ–¹å¼ï¼š
1) åœ¨ main.py ä¸‹è¼‰å®Œæˆå¾Œå‘¼å«ï¼š
   from kbar_aggregator import build_kbars
   build_kbars(db_file)

2) CLIï¼š
   python kbar_aggregator.py tw_stock_warehouse.db
"""

import os
import sqlite3
import warnings
from dataclasses import dataclass
from typing import Optional, Tuple

import numpy as np
import pandas as pd

warnings.filterwarnings("ignore", category=FutureWarning)


# --------------------------
# Utilities
# --------------------------
def log(msg: str):
    print(f"{pd.Timestamp.now():%H:%M:%S} | {msg}", flush=True)


def _safe_to_datetime(s: pd.Series) -> pd.Series:
    dt = pd.to_datetime(s, errors="coerce")
    # yfinance å¯èƒ½æœ‰ tzï¼Œçµ±ä¸€å»æ‰
    try:
        return dt.dt.tz_localize(None)
    except Exception:
        return dt


def _ensure_numeric(df: pd.DataFrame, cols):
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df


def _read_stock_prices(conn: sqlite3.Connection) -> pd.DataFrame:
    df = pd.read_sql(
        """
        SELECT symbol, date, open, high, low, close, volume
        FROM stock_prices
        """,
        conn,
    )
    if df.empty:
        return df

    df["date"] = _safe_to_datetime(df["date"])
    df = df.dropna(subset=["symbol", "date"]).copy()
    df = _ensure_numeric(df, ["open", "high", "low", "close", "volume"])
    df["symbol"] = df["symbol"].astype(str)
    df = df.sort_values(["symbol", "date"])
    return df


def _read_stock_info(conn: sqlite3.Connection) -> pd.DataFrame:
    # æŸäº› DB å¯èƒ½æ²’æœ‰ stock_info æˆ–æ²’æœ‰ market_detail
    try:
        df = pd.read_sql("SELECT * FROM stock_info", conn)
        if df.empty:
            return df
        df["symbol"] = df["symbol"].astype(str)
        for col in ["market", "market_detail", "sector", "name"]:
            if col not in df.columns:
                df[col] = None
        return df[["symbol", "market", "market_detail", "sector", "name"]].copy()
    except Exception:
        return pd.DataFrame(columns=["symbol", "market", "market_detail", "sector", "name"])


def _attach_info(df: pd.DataFrame, info: pd.DataFrame) -> pd.DataFrame:
    if df.empty or info.empty:
        # ç¢ºä¿æ¬„ä½å­˜åœ¨
        for col in ["market", "market_detail", "sector", "name"]:
            if col not in df.columns:
                df[col] = None
        return df
    return df.merge(info, on="symbol", how="left")


def _ohlcv_agg(group: pd.DataFrame) -> pd.Series:
    """å°æŸå€‹ period çš„æ—¥Kåš OHLCV èšåˆï¼ˆå‡è¨­ group å·²æŒ‰ date æ’åºï¼‰"""
    open_ = group["open"].iloc[0]
    close_ = group["close"].iloc[-1]
    high_ = group["high"].max()
    low_ = group["low"].min()
    vol_ = group["volume"].sum(min_count=1)

    return pd.Series(
        {
            "open": open_,
            "high": high_,
            "low": low_,
            "close": close_,
            "volume": vol_,
            "start_date": group["date"].iloc[0],
            "end_date": group["date"].iloc[-1],
            "n_bars": int(len(group)),
        }
    )


def _add_prev_ret(df: pd.DataFrame, key_cols: Tuple[str, ...], close_col="close") -> pd.DataFrame:
    """åŠ ä¸Š prev_close / ret / logretï¼ˆæŒ‰ key_cols çš„ç¬¬ä¸€æ¬„é€šå¸¸æ˜¯ symbol åˆ†çµ„ï¼‰"""
    df = df.sort_values(list(key_cols)).copy()
    sym_col = key_cols[0]
    df["prev_close"] = df.groupby(sym_col)[close_col].shift(1)
    df["ret"] = (df[close_col] / df["prev_close"]) - 1
    df["logret"] = np.log(df[close_col] / df["prev_close"])
    df.loc[df["prev_close"].isna(), ["ret", "logret"]] = np.nan
    return df


# --------------------------
# Core builder
# --------------------------
@dataclass
class KbarBuildResult:
    weekly_rows: int
    monthly_rows: int
    yearly_rows: int


def build_kbars(db_path: str) -> KbarBuildResult:
    """
    è®€å– stock_prices -> ç”¢ç”Ÿ kbar_weekly / kbar_monthly / kbar_yearly
    """
    if not os.path.exists(db_path):
        raise FileNotFoundError(f"DB not found: {db_path}")

    conn = sqlite3.connect(db_path, timeout=120)
    try:
        log(f"ğŸ“¥ è®€å–æ—¥K: {db_path}")
        df = _read_stock_prices(conn)
        if df.empty:
            log("âŒ stock_prices ç‚ºç©ºï¼Œè·³é kbar èšåˆ")
            return KbarBuildResult(0, 0, 0)

        info = _read_stock_info(conn)
        df = _attach_info(df, info)

        # ==========================
        # Weekly
        # ==========================
        log("ğŸ§± å»ºç«‹ kbar_weekly ...")
        d = df.copy()
        # ä»¥ã€Œé€±ä¸€ã€ä½œç‚º week_startï¼ˆå¸¸è¦‹å®šç¾©ï¼›ä½ å„€è¡¨æ¿ä¹Ÿå®¹æ˜“å°é½Šï¼‰
        d["week_start"] = d["date"].dt.to_period("W-MON").apply(lambda p: p.start_time)
        d = d.sort_values(["symbol", "date"])

        wk = (
            d.groupby(["symbol", "week_start"], as_index=False, sort=False)
            .apply(lambda g: _ohlcv_agg(g.sort_values("date")))
            .reset_index(drop=True)
        )
        # è£œ infoï¼ˆæ¯æª”å›ºå®šï¼‰
        wk = wk.merge(
            d.groupby("symbol")[["market", "market_detail", "sector", "name"]].first().reset_index(),
            on="symbol",
            how="left",
        )

        wk["week_start"] = pd.to_datetime(wk["week_start"]).dt.strftime("%Y-%m-%d")
        wk["start_date"] = pd.to_datetime(wk["start_date"]).dt.strftime("%Y-%m-%d")
        wk["end_date"] = pd.to_datetime(wk["end_date"]).dt.strftime("%Y-%m-%d")

        wk = _add_prev_ret(wk, ("symbol", "week_start"), close_col="close")
        wk["period"] = "W"

        # ==========================
        # Monthly
        # ==========================
        log("ğŸ§± å»ºç«‹ kbar_monthly ...")
        d2 = df.copy()
        d2["month_start"] = d2["date"].dt.to_period("M").dt.start_time
        d2 = d2.sort_values(["symbol", "date"])

        mo = (
            d2.groupby(["symbol", "month_start"], as_index=False, sort=False)
            .apply(lambda g: _ohlcv_agg(g.sort_values("date")))
            .reset_index(drop=True)
        )
        mo = mo.merge(
            d2.groupby("symbol")[["market", "market_detail", "sector", "name"]].first().reset_index(),
            on="symbol",
            how="left",
        )

        mo["month_start"] = pd.to_datetime(mo["month_start"]).dt.strftime("%Y-%m-%d")
        mo["start_date"] = pd.to_datetime(mo["start_date"]).dt.strftime("%Y-%m-%d")
        mo["end_date"] = pd.to_datetime(mo["end_date"]).dt.strftime("%Y-%m-%d")

        mo = _add_prev_ret(mo, ("symbol", "month_start"), close_col="close")
        mo["period"] = "M"

        # ==========================
        # Yearly + Peak
        # ==========================
        log("ğŸ§± å»ºç«‹ kbar_yearly (å«å¹´å…§æœ€é«˜é» peak_date) ...")
        d3 = df.copy()
        d3["year"] = d3["date"].dt.year.astype(int)
        d3 = d3.sort_values(["symbol", "date"])

        # å¹´K OHLCV
        yr = (
            d3.groupby(["symbol", "year"], as_index=False, sort=False)
            .apply(lambda g: _ohlcv_agg(g.sort_values("date")))
            .reset_index(drop=True)
        )

        # å¹´å…§æœ€é«˜é»ï¼ˆç”¨ highï¼‰
        # æ‰¾æ¯å€‹ symbol-year çš„æœ€å¤§ high çš„é‚£å¤©ï¼ˆè‹¥æœ‰åŒé«˜ï¼Œå–æœ€æ—©å‡ºç¾ï¼‰
        peak_idx = d3.groupby(["symbol", "year"])["high"].idxmax()
        peak_df = d3.loc[peak_idx, ["symbol", "year", "date", "high"]].copy()
        peak_df = peak_df.rename(columns={"date": "peak_date", "high": "peak_high"})

        # è‹¥ high å…¨ NaNï¼Œidxmax æœƒçˆ†ï¼›åšä¿è­·
        if peak_df.empty:
            yr["peak_date"] = None
            yr["peak_high"] = np.nan
        else:
            yr = yr.merge(peak_df, on=["symbol", "year"], how="left")

        # è£œ info
        yr = yr.merge(
            d3.groupby("symbol")[["market", "market_detail", "sector", "name"]].first().reset_index(),
            on="symbol",
            how="left",
        )

        # å¹´Ké¡å¤–æŒ‡æ¨™ï¼šå¹´å ±é…¬ã€peak_ret
        yr = yr.sort_values(["symbol", "year"])
        yr["prev_close"] = yr.groupby("symbol")["close"].shift(1)
        yr["year_ret"] = (yr["close"] / yr["prev_close"]) - 1
        yr["year_logret"] = np.log(yr["close"] / yr["prev_close"])
        yr.loc[yr["prev_close"].isna(), ["year_ret", "year_logret"]] = np.nan

        # å¹´å…§ peak ç›¸å°å¹´åˆ open çš„ peak_retï¼ˆç™¾åˆ†æ¯”ï¼‰
        yr["peak_ret"] = np.where(
            (yr["open"].notna()) & (yr["open"] > 0) & (yr["peak_high"].notna()),
            (yr["peak_high"] / yr["open"] - 1) * 100.0,
            np.nan,
        )

        # è½‰å­—ä¸²
        yr["peak_date"] = pd.to_datetime(yr["peak_date"], errors="coerce").dt.strftime("%Y-%m-%d")
        yr["start_date"] = pd.to_datetime(yr["start_date"]).dt.strftime("%Y-%m-%d")
        yr["end_date"] = pd.to_datetime(yr["end_date"]).dt.strftime("%Y-%m-%d")
        yr["period"] = "Y"

        # ==========================
        # Write back to DB
        # ==========================
        log("ğŸ§¾ å¯«å›è³‡æ–™åº«ï¼ˆreplaceï¼‰: kbar_weekly / kbar_monthly / kbar_yearly")

        conn.execute("DROP TABLE IF EXISTS kbar_weekly")
        conn.execute("DROP TABLE IF EXISTS kbar_monthly")
        conn.execute("DROP TABLE IF EXISTS kbar_yearly")

        wk.to_sql("kbar_weekly", conn, if_exists="replace", index=False)
        mo.to_sql("kbar_monthly", conn, if_exists="replace", index=False)
        yr.to_sql("kbar_yearly", conn, if_exists="replace", index=False)

        # Indexesï¼ˆæŸ¥è©¢é€Ÿåº¦æœƒå·®å¾ˆå¤šï¼‰
        conn.execute("CREATE INDEX IF NOT EXISTS idx_wk_symbol_week ON kbar_weekly(symbol, week_start)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_mo_symbol_month ON kbar_monthly(symbol, month_start)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_yr_symbol_year ON kbar_yearly(symbol, year)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_yr_peak_date ON kbar_yearly(peak_date)")
        conn.commit()

        # å°å„ªåŒ–
        log("ğŸ§¹ VACUUM ...")
        conn.execute("VACUUM")
        conn.commit()

        log(
            f"âœ… å®Œæˆ kbars | weekly={len(wk):,} monthly={len(mo):,} yearly={len(yr):,}"
        )
        return KbarBuildResult(len(wk), len(mo), len(yr))

    finally:
        conn.close()


# --------------------------
# CLI
# --------------------------
if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("Usage: python kbar_aggregator.py <db_file>")
        print("Example: python kbar_aggregator.py tw_stock_warehouse.db")
        raise SystemExit(1)

    build_kbars(sys.argv[1])
