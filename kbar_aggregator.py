# kbar_aggregator.py
# -*- coding: utf-8 -*-
"""
kbar_aggregator.py
------------------
å¾ SQLite(stock_prices) æ—¥K â†’ æ¸…æ´— â†’ èšåˆç”¢ç”Ÿ é€±K / æœˆK / å¹´Kï¼ˆå¯«å›åŒä¸€å€‹ DBï¼‰

âœ… ç›®æ¨™ï¼ˆæ”¯æ´ä½ çš„å„€è¡¨æ¿/ç ”ç©¶ï¼‰ï¼š
- ç”¢å‡º kbar_weekly / kbar_monthly / kbar_yearly ä¸‰å¼µè¡¨
- é€±/æœˆ/å¹´Kã€ŒåŒæºä¸€è‡´ã€ï¼šå…¨éƒ¨ç”±æ—¥Kèšåˆï¼ˆé¿å… yfinance 1wk å®šç¾©ä¸ä¸€è‡´ï¼‰
- å…§å»ºã€Œç•°å¸¸å ±é…¬æ¸…æ´—ã€ï¼šåƒè€ƒä½ è²¼çš„ pingpong æ¦‚å¿µ + limit sanity check
- é¡å¤–æä¾› year_peak_date / year_peak_highï¼šè®“ä½ èƒ½å¿«é€Ÿç®—
  ã€Œå¹´Ké«˜é»å‰æœ‰å¹¾æ ¹æ¼²åœã€ã€ã€Œé€±/æœˆå°å¹´Ké«˜é»è²¢ç»åº¦ã€ç­‰

ğŸ“Œ ä¾è³´ï¼š
- pandas, numpyï¼ˆéƒ½åœ¨ä½ çš„ç’°å¢ƒä¸­ï¼‰
- SQLite è¡¨ï¼š
  - stock_prices(symbol,date,open,high,low,close,volume)
  - stock_info(symbol,market,market_detail,sector,name...)  (å¯é¸ï¼Œä½†å»ºè­°æœ‰)

âš ï¸ æ³¨æ„ï¼š
- é€™æ”¯è…³æœ¬ä¸ä¾è³´ yfinanceï¼Œä¸æœƒé¡å¤–æŠ“è³‡æ–™
- è‹¥ä½  downloader å·²ä½¿ç”¨ auto_adjust=Trueï¼Œclose å·²æ¥è¿‘é‚„åŸåƒ¹ï¼Œé€™è£¡çš„æ¸…æ´—æœƒæ›´å¯é 

ç”¨æ³•ï¼š
    python kbar_aggregator.py tw_stock_warehouse.db
æˆ–åœ¨ç¨‹å¼è£¡å‘¼å«ï¼š
    from kbar_aggregator import build_kbars
    build_kbars("tw_stock_warehouse.db")

"""

import sys
import sqlite3
import warnings
from dataclasses import dataclass
from typing import Optional, Dict, Tuple

import numpy as np
import pandas as pd

warnings.filterwarnings("ignore", category=FutureWarning)


# =============================================================================
# å¯é¸ï¼šæ¥ market_rulesï¼ˆè‹¥å­˜åœ¨å°±ç”¨å®ƒçš„ limit/tick è¦å‰‡åšæ›´ç²¾æº–æ¸…æ´—ï¼‰
# =============================================================================
try:
    import market_rules  # ä½ çš„è¦å‰‡æª”ï¼ˆè‹¥å·²å®Œæˆï¼‰
    HAS_MARKET_RULES = True
except Exception:
    market_rules = None
    HAS_MARKET_RULES = False


# =============================================================================
# è¨­å®š
# =============================================================================
PINGPONG_THRESHOLD = 0.40     # ä½ è²¼çš„ï¼šé€£çºŒå…©æ—¥ abs(ret)>0.4 ä¸”åå‘ â†’ ç•°å¸¸
LIMIT_SANITY_MULT = 1.50      # æœ‰æ¼²è·Œå¹…é™åˆ¶å¸‚å ´ï¼šabs(ret) > limit*1.5 è¦–ç‚ºç•°å¸¸
MIN_DAYS_PER_SYMBOL = 40      # å¤ªçŸ­çš„ä¸åš
SQLITE_TIMEOUT = 120


@dataclass
class LimitRule:
    kind: str                 # 'pct' / 'none'
    up_pct: Optional[float]   # 0.10 / 0.20 / None


def _fallback_limit_rule(market: confirm str, market_detail: str, symbol: str) -> LimitRule:
    """
    è‹¥ market_rules ä¸å­˜åœ¨æ™‚çš„ä¿åº•åˆ¤æ–·ï¼š
    - TW: listed/otc 10%, emerging none
    - CN: 300/301/688 20% else 10%
    - JP: none (ä½ ä¹‹å¾Œç”¨ market_rules è£œç²¾æº–å€¤å¹…)
    """
    m = (market or "").upper().strip()
    md = (market_detail or "").lower().strip()
    sym = (symbol or "").upper().strip()

    # TW
    if m in ["TW", "TSE", "GTSM"] or sym.endswith(".TW") or sym.endswith(".TWO"):
        if md == "emerging":
            return LimitRule(kind="none", up_pct=None)
        return LimitRule(kind="pct", up_pct=0.10)

    # CN
    if m in ["SSE", "SZSE", "CN", "CHINA"] or sym.endswith(".SS") or sym.endswith(".SZ"):
        code = "".join([c for c in sym if c.isdigit()])
        if code.startswith(("300", "301", "688")):
            return LimitRule(kind="pct", up_pct=0.20)
        return LimitRule(kind="pct", up_pct=0.10)

    # JP
    if m in ["JP", "JPX", "TSE"] or sym.endswith(".T"):
        return LimitRule(kind="none", up_pct=None)

    return LimitRule(kind="none", up_pct=None)


def _get_limit_rule(market: str, market_detail: str, symbol: str) -> LimitRule:
    """
    ç›¡é‡ç”¨ market_rules.get_rule()ï¼Œå¦å‰‡ fallbackã€‚
    åªæ‹¿ã€Œæ˜¯å¦ pct limitã€èˆ‡ã€Œä¸Šé™ã€ç”¨æ–¼ sanity checkã€‚
    """
    if HAS_MARKET_RULES and hasattr(market_rules, "get_rule"):
        try:
            r = market_rules.get_rule(market=market, market_detail=market_detail, symbol=symbol)
            kind = r.get("limit_kind", "none")
            up = r.get("limit_up_pct", None)
            if kind == "pct" and isinstance(up, (int, float)):
                return LimitRule(kind="pct", up_pct=float(up))
            return LimitRule(kind="none", up_pct=None)
        except Exception:
            pass
    return _fallback_limit_rule(market, market_detail, symbol)


# =============================================================================
# æ¸…æ´—ï¼špingpong + limit sanity + åŸºç¤ä¿®è£œ
# =============================================================================
def _clean_daily(df: pd.DataFrame, limit_rule: LimitRule) -> pd.DataFrame:
    """
    df: å–®ä¸€ symbol çš„æ—¥Kï¼Œéœ€åŒ…å« date/open/high/low/close/volume
    å›å‚³æ¸…æ´—å¾Œ dfï¼ˆä»ä¿æŒæ—¥é »ï¼‰ï¼Œä¸¦æ–°å¢ clean_ret
    """

    if df.empty:
        return df

    df = df.sort_values("date").reset_index(drop=True).copy()

    # åŸºç¤ï¼šåƒ¹é‡ç„¡æ•ˆ
    for c in ["open", "high", "low", "close"]:
        df.loc[df[c].astype(float) <= 0, c] = np.nan

    # ä¿®è£œ closeï¼ˆå› ç‚º ret ä¾è³´ closeï¼‰
    df["close"] = df["close"].astype(float).ffill()

    # ç”¨ close ç®—å ±é…¬
    df["clean_ret"] = df["close"].pct_change().astype(float)

    # (1) limit sanity checkï¼ˆæœ‰æ¼²è·Œå¹…é™åˆ¶å¸‚å ´ï¼‰
    if limit_rule.kind == "pct" and limit_rule.up_pct is not None:
        max_abs = float(limit_rule.up_pct) * LIMIT_SANITY_MULT
        bad = df["clean_ret"].abs() > max_abs
        # é€™äº›æ—¥å­è¦–ç‚ºç•°å¸¸ï¼šæŠŠ OHLC å…¨è¨­ NaNï¼Œå†ç”¨ close ffill è®“èšåˆä¸ç‚¸
        if bad.any():
            for c in ["open", "high", "low", "close"]:
                df.loc[bad, c] = np.nan
            df["close"] = df["close"].ffill()
            df["clean_ret"] = df["close"].pct_change().astype(float)

    # (2) pingpong filterï¼ˆä½ è²¼çš„ç²¾ç¥ï¼‰
    # è‹¥ i èˆ‡ i+1 é€£çºŒå…©æ—¥ abs(ret)>threshold ä¸” ret æ–¹å‘ç›¸å â†’ i, i+1 æ¨™è¨˜ç•°å¸¸
    r = df["clean_ret"].values
    mask = np.zeros(len(df), dtype=bool)
    for i in range(1, len(df) - 1):
        prev = r[i]
        nxt = r[i + 1]
        if np.isfinite(prev) and np.isfinite(nxt):
            if (abs(prev) > PINGPONG_THRESHOLD) and (abs(nxt) > PINGPONG_THRESHOLD) and (prev * nxt < 0):
                mask[i] = True
                mask[i + 1] = True

    if mask.any():
        for c in ["open", "high", "low", "close"]:
            df.loc[mask, c] = np.nan
        df["close"] = df["close"].ffill()
        df["clean_ret"] = df["close"].pct_change().astype(float)

    # é‡æ–°è£œ open/high/lowï¼ˆä¿å®ˆï¼šç”¨ close è¿‘ä¼¼è£œæ´ï¼Œç¢ºä¿èšåˆä¸ä¸­æ–·ï¼‰
    # ä½ è‹¥æ›´æƒ³åš´æ ¼ï¼Œå¯ä»¥æ”¹æˆï¼šåª ffill closeï¼Œä¸è£œ open/high/lowï¼Œä½†èšåˆå¯èƒ½ç¼ºè³‡æ–™
    df["open"] = df["open"].astype(float)
    df["high"] = df["high"].astype(float)
    df["low"] = df["low"].astype(float)

    df["open"] = df["open"].fillna(df["close"])
    df["high"] = df["high"].fillna(df[["open", "close"]].max(axis=1))
    df["low"] = df["low"].fillna(df[["open", "close"]].min(axis=1))

    # volume
    if "volume" in df.columns:
        df["volume"] = pd.to_numeric(df["volume"], errors="coerce").fillna(0).astype(float)
    else:
        df["volume"] = 0.0

    return df


# =============================================================================
# èšåˆï¼šç”±æ—¥Kç”Ÿæˆ é€±/æœˆ/å¹´
# =============================================================================
def _agg_ohlcv(g: pd.DataFrame) -> pd.Series:
    """å°å–®ä¸€ period çš„ OHLCV èšåˆ"""
    if g.empty:
        return pd.Series({"open": np.nan, "high": np.nan, "low": np.nan, "close": np.nan, "volume": 0.0})

    return pd.Series(
        {
            "open": float(g["open"].iloc[0]),
            "high": float(np.nanmax(g["high"].values)),
            "low": float(np.nanmin(g["low"].values)),
            "close": float(g["close"].iloc[-1]),
            "volume": float(np.nansum(g["volume"].values)),
        }
    )


def _build_weekly(df: pd.DataFrame) -> pd.DataFrame:
    """
    é€±Kï¼šä»¥ ISO week åšé€±æœŸéµï¼ˆè·¨å¹´é€±æœƒæ­¸åˆ° ISO yearï¼‰
    period_endï¼šé€±æœ€å¾Œä¸€å€‹äº¤æ˜“æ—¥ï¼ˆå¯¦éš›å­˜åœ¨çš„æ—¥Kæœ€å¾Œä¸€å¤©ï¼‰
    """
    x = df.copy()
    iso = x["date"].dt.isocalendar()
    x["iso_year"] = iso["year"].astype(int)
    x["iso_week"] = iso["week"].astype(int)
    x["period_key"] = x["iso_year"].astype(str) + "-W" + x["iso_week"].astype(str).str.zfill(2)

    out = (
        x.groupby("period_key", sort=True)
        .apply(_agg_ohlcv)
        .reset_index()
        .rename(columns={"period_key": "week_id"})
    )

    # start/end date
    se = x.groupby("period_key")["date"].agg(["min", "max"]).reset_index()
    se.columns = ["week_id", "period_start", "period_end"]
    out = out.merge(se, on="week_id", how="left")

    # year/week
    out["year"] = out["week_id"].str.slice(0, 4).astype(int)
    out["week"] = out["week_id"].str.split("-W").str[1].astype(int)

    return out[["week_id", "year", "week", "period_start", "period_end", "open", "high", "low", "close", "volume"]]


def _build_monthly(df: pd.DataFrame) -> pd.DataFrame:
    x = df.copy()
    x["year"] = x["date"].dt.year.astype(int)
    x["month"] = x["date"].dt.month.astype(int)
    x["month_id"] = x["year"].astype(str) + "-" + x["month"].astype(str).str.zfill(2)

    out = x.groupby("month_id", sort=True).apply(_agg_ohlcv).reset_index()
    se = x.groupby("month_id")["date"].agg(["min", "max"]).reset_index()
    se.columns = ["month_id", "period_start", "period_end"]
    out = out.merge(se, on="month_id", how="left")

    out["year"] = out["month_id"].str.slice(0, 4).astype(int)
    out["month"] = out["month_id"].str.slice(5, 7).astype(int)

    return out[["month_id", "year", "month", "period_start", "period_end", "open", "high", "low", "close", "volume"]]


def _build_yearly(df: pd.DataFrame) -> pd.DataFrame:
    x = df.copy()
    x["year"] = x["date"].dt.year.astype(int)
    x["year_id"] = x["year"].astype(str)

    out = x.groupby("year_id", sort=True).apply(_agg_ohlcv).reset_index()
    se = x.groupby("year_id")["date"].agg(["min", "max"]).reset_index()
    se.columns = ["year_id", "period_start", "period_end"]
    out = out.merge(se, on="year_id", how="left")

    out["year"] = out["year_id"].astype(int)

    # å¹´å…§é«˜é»ï¼ˆç”¨ highï¼‰
    peak = x.groupby("year_id").apply(lambda g: pd.Series({
        "year_peak_date": g.loc[g["high"].astype(float).idxmax(), "date"] if len(g) else pd.NaT,
        "year_peak_high": float(np.nanmax(g["high"].astype(float).values)) if len(g) else np.nan
    })).reset_index().rename(columns={"year_id": "year_id"})

    out = out.merge(peak, left_on="year_id", right_on="year_id", how="left")
    return out[["year_id", "year", "period_start", "period_end", "open", "high", "low", "close", "volume", "year_peak_date", "year_peak_high"]]


# =============================================================================
# DB IO
# =============================================================================
def _ensure_indexes(conn: sqlite3.Connection):
    # æ—¥Kç´¢å¼•ï¼ˆå¦‚æœæ²’æœ‰ï¼‰
    try:
        conn.execute("CREATE INDEX IF NOT EXISTS idx_prices_symbol_date ON stock_prices(symbol, date)")
    except Exception:
        pass


def _write_table(conn: sqlite3.Connection, name: str, df: pd.DataFrame):
    conn.execute(f"DROP TABLE IF EXISTS {name}")
    df.to_sql(name, conn, if_exists="replace", index=False)

    # å¸¸ç”¨ç´¢å¼•
    try:
        if name == "kbar_weekly":
            conn.execute("CREATE INDEX IF NOT EXISTS idx_kbar_weekly_symbol_end ON kbar_weekly(symbol, period_end)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_kbar_weekly_symbol_week ON kbar_weekly(symbol, week_id)")
        elif name == "kbar_monthly":
            conn.execute("CREATE INDEX IF NOT EXISTS idx_kbar_monthly_symbol_end ON kbar_monthly(symbol, period_end)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_kbar_monthly_symbol_month ON kbar_monthly(symbol, month_id)")
        elif name == "kbar_yearly":
            conn.execute("CREATE INDEX IF NOT EXISTS idx_kbar_yearly_symbol_year ON kbar_yearly(symbol, year)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_kbar_yearly_symbol_end ON kbar_yearly(symbol, period_end)")
    except Exception:
        pass


# =============================================================================
# ä¸»å‡½æ•¸
# =============================================================================
def build_kbars(db_path: str, symbols: Optional[list] = None) -> Dict[str, int]:
    """
    è®€ stock_prices â†’ æ¸…æ´— â†’ èšåˆ â†’ å¯«å› kbar_weekly/monthly/yearly
    å›å‚³çµ±è¨ˆ dict
    """

    conn = sqlite3.connect(db_path, timeout=SQLITE_TIMEOUT)
    try:
        _ensure_indexes(conn)

        # è®€ stock_prices + stock_infoï¼ˆmarketåˆ¤å®šç”¨ï¼‰
        query = """
        SELECT p.symbol, p.date, p.open, p.high, p.low, p.close, p.volume,
               i.market, i.market_detail
        FROM stock_prices p
        LEFT JOIN stock_info i ON p.symbol = i.symbol
        """
        df = pd.read_sql(query, conn)

        if df.empty:
            print("âŒ stock_prices ç„¡è³‡æ–™")
            return {"symbols": 0, "weekly_rows": 0, "monthly_rows": 0, "yearly_rows": 0}

        df["date"] = pd.to_datetime(df["date"], errors="coerce")
        df = df.dropna(subset=["date"]).sort_values(["symbol", "date"]).reset_index(drop=True)

        if symbols:
            sset = set(symbols)
            df = df[df["symbol"].isin(sset)].copy()
            if df.empty:
                print("âŒ æŒ‡å®š symbols åœ¨ DB æ‰¾ä¸åˆ°è³‡æ–™")
                return {"symbols": 0, "weekly_rows": 0, "monthly_rows": 0, "yearly_rows": 0}

        wk_list, mo_list, yr_list = [], [], []
        symbol_count = 0

        for sym, g in df.groupby("symbol", sort=False):
            g = g.sort_values("date").reset_index(drop=True)
            if len(g) < MIN_DAYS_PER_SYMBOL:
                continue

            market = g["market"].iloc[0] if "market" in g.columns else ""
            market_detail = g["market_detail"].iloc[0] if "market_detail" in g.columns else ""

            rule = _get_limit_rule(market, market_detail, sym)

            gd = _clean_daily(g, rule)
            if gd.empty or gd["close"].isna().all():
                continue

            # èšåˆ
            w = _build_weekly(gd)
            w.insert(0, "symbol", sym)
            m = _build_monthly(gd)
            m.insert(0, "symbol", sym)
            y = _build_yearly(gd)
            y.insert(0, "symbol", sym)

            wk_list.append(w)
            mo_list.append(m)
            yr_list.append(y)

            symbol_count += 1

        if symbol_count == 0:
            print("âŒ æ²’æœ‰è¶³å¤ è³‡æ–™å¯èšåˆï¼ˆå¯èƒ½éƒ½ä¸è¶³ MIN_DAYS_PER_SYMBOLï¼‰")
            return {"symbols": 0, "weekly_rows": 0, "monthly_rows": 0, "yearly_rows": 0}

        df_wk = pd.concat(wk_list, ignore_index=True)
        df_mo = pd.concat(mo_list, ignore_index=True)
        df_yr = pd.concat(yr_list, ignore_index=True)

        # æ—¥æœŸæ¬„ä½è½‰å­—ä¸²ï¼ˆSQLiteç©©ï¼‰
        for col in ["period_start", "period_end"]:
            df_wk[col] = pd.to_datetime(df_wk[col]).dt.strftime("%Y-%m-%d")
            df_mo[col] = pd.to_datetime(df_mo[col]).dt.strftime("%Y-%m-%d")
            df_yr[col] = pd.to_datetime(df_yr[col]).dt.strftime("%Y-%m-%d")

        df_yr["year_peak_date"] = pd.to_datetime(df_yr["year_peak_date"], errors="coerce").dt.strftime("%Y-%m-%d")

        # å¯«å›
        _write_table(conn, "kbar_weekly", df_wk)
        _write_table(conn, "kbar_monthly", df_mo)
        _write_table(conn, "kbar_yearly", df_yr)

        conn.commit()

        print("\nâœ… kbar èšåˆå®Œæˆï¼ˆç”±æ—¥Kèšåˆï¼Œå·²æ¸…æ´—ï¼‰")
        print(f"ğŸ“Œ symbols: {symbol_count}")
        print(f"ğŸ“Œ kbar_weekly rows:  {len(df_wk):,}")
        print(f"ğŸ“Œ kbar_monthly rows: {len(df_mo):,}")
        print(f"ğŸ“Œ kbar_yearly rows:  {len(df_yr):,}")

        return {
            "symbols": int(symbol_count),
            "weekly_rows": int(len(df_wk)),
            "monthly_rows": int(len(df_mo)),
            "yearly_rows": int(len(df_yr)),
        }

    finally:
        conn.close()


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python kbar_aggregator.py <db_path> [symbol1 symbol2 ...]")
        sys.exit(1)

    db = sys.argv[1]
    syms = sys.argv[2:] if len(sys.argv) > 2 else None
    build_kbars(db, symbols=syms)
