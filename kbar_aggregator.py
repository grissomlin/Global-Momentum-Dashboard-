# kbar_aggregator.py
# -*- coding: utf-8 -*-
"""
kbar_aggregator.py
------------------
å¾æ—¥Kï¼ˆstock_analysis æˆ– stock_pricesï¼‰èšåˆé€±K/æœˆK/å¹´Kï¼š

è¼¸å‡ºè¡¨ï¼š
- kbar_weekly : symbol, year, week_id, period_start, period_end, open, high, low, close, volume
- kbar_monthly: symbol, year, month_id, period_start, period_end, open, high, low, close, volume
- kbar_yearly : symbol, year, period_start, period_end, open, high, low, close, volume,
                year_peak_date, year_peak_high

âœ… ç‰¹é»ï¼ˆåŠ æ³•ï¼Œä¸æœƒç ´å£ä½ ç¾æœ‰åŠŸèƒ½ï¼‰
- ä½¿ç”¨ã€Œclean_closeã€åšèšåˆï¼šä¿ç•™åŸ closeï¼Œä¸æ”¹ stock_analysis
- å…§å»ºç•°å¸¸å ±é…¬æ¸…æ´—ï¼ˆå¯é—œï¼‰
  1) è¶…é™å€¼å¹³æ»‘ï¼šè‹¥å¸‚å ´æœ‰æ¼²è·Œå¹…é™åˆ¶ï¼ˆTW/CN/JP å¯ç”¨ market_rulesï¼‰ï¼Œabs(daily_ret) > limit*1.5 è¦–ç‚ºç•°å¸¸
  2) pingpongï¼šé€£çºŒå…©æ—¥ |ret| > 0.40 ä¸”æ–¹å‘ç›¸åï¼Œè¦–ç‚ºç•°å¸¸éœ‡ç›ªï¼ˆæ¸›è³‡/ä½µè³¼/è³‡æ–™éŒ¯ï¼‰
- å¯å„ªå…ˆè®€ stock_analysisï¼ˆæœ‰ prev_close / market ç­‰ï¼‰ï¼Œæ²’æœ‰å†é€€å› stock_prices

ç”¨æ³•ï¼š
    python kbar_aggregator.py tw_stock_warehouse.db
æˆ–ï¼š
    from kbar_aggregator import build_kbar_tables
    build_kbar_tables("tw_stock_warehouse.db")

ä¾è³´ï¼ˆå¯é¸ï¼‰ï¼š
- market_rules.pyï¼ˆè‹¥å­˜åœ¨ï¼Œæœƒç”¨å®ƒæ‹¿ limit_up_pct / tick ç­‰ï¼›ä¸å­˜åœ¨å°± fallbackï¼‰
"""

import sys
import sqlite3
import numpy as np
import pandas as pd
from typing import Optional, Dict

SQLITE_TIMEOUT = 120

# -------------------------
# optional market_rules
# -------------------------
try:
    import market_rules
    HAS_MARKET_RULES = True
except Exception:
    market_rules = None
    HAS_MARKET_RULES = False


def _fallback_limit_up_pct(market: str, market_detail: str, symbol: str) -> Optional[float]:
    """fallbackï¼šåªåšå¸¸è¦‹ TW=10%ã€CN=10/20ã€JP=None"""
    m = (market or "").upper().strip()
    sym = (symbol or "").upper().strip()
    md = (market_detail or "").lower().strip()

    if m in ["TW", "TSE", "GTSM"] or sym.endswith(".TW") or sym.endswith(".TWO"):
        if md == "emerging":
            return None
        return 0.10

    if m in ["CN", "SSE", "SZSE", "CHINA"] or sym.endswith(".SS") or sym.endswith(".SZ"):
        code = "".join([c for c in sym if c.isdigit()])
        if code.startswith(("300", "301", "688")):
            return 0.20
        return 0.10

    if m in ["JP", "JPX", "TSE"] or sym.endswith(".T"):
        return None

    return None


def _get_limit_up_pct(market: str, market_detail: str, symbol: str) -> Optional[float]:
    if HAS_MARKET_RULES and hasattr(market_rules, "get_rule"):
        try:
            rule = market_rules.get_rule(market=market, market_detail=market_detail, symbol=symbol)
            v = rule.get("limit_up_pct", None)
            if isinstance(v, (int, float)):
                return float(v)
            return None
        except Exception:
            return _fallback_limit_up_pct(market, market_detail, symbol)
    return _fallback_limit_up_pct(market, market_detail, symbol)


# -------------------------
# anomaly cleaning (ADD-ON)
# -------------------------
def _apply_anomaly_cleaning(
    g: pd.DataFrame,
    limit_up_pct: Optional[float],
    enable_pingpong: bool = True,
    pingpong_threshold: float = 0.40,
    enable_overlimit_smoothing: bool = True,
) -> pd.DataFrame:
    """
    ä»¥ã€Œclean_closeã€ç”Ÿæˆä¹¾æ·¨åƒ¹æ ¼åºåˆ—ï¼Œç”¨æ–¼èšåˆï¼Œä¸ç ´å£åŸ closeã€‚

    ç­–ç•¥ï¼ˆä¸ drop rowï¼Œé¿å…ç ´å£é€±/æœˆåˆ‡æ®µï¼‰ï¼š
    - overlimitï¼šæŠŠ OHLC è¨­ NaN -> ä»¥ close ffill -> å…¶é¤˜ç”¨ close è£œ
    - pingpongï¼šæŠŠ (i, i+1) å…©å¤© OHLC è¨­ NaN -> ffill
    """
    g = g.sort_values("date").copy()

    # clean_ohlc åˆå§‹ = åŸå§‹
    for c in ["open", "high", "low", "close"]:
        g[f"clean_{c}"] = pd.to_numeric(g[c], errors="coerce")

    # å…ˆç®— daily_retï¼ˆç”¨ closeï¼‰
    g["clean_ret"] = g["clean_close"].pct_change()

    # 1) overlimit smoothing
    if enable_overlimit_smoothing and isinstance(limit_up_pct, (int, float)) and limit_up_pct > 0:
        max_allowed = float(limit_up_pct) * 1.5
        mask_over = g["clean_ret"].abs() > max_allowed
        if mask_over.any():
            for c in ["clean_open", "clean_high", "clean_low", "clean_close"]:
                g.loc[mask_over, c] = np.nan

    # 2) pingpong
    if enable_pingpong:
        r = g["clean_ret"].values
        mask_pp = np.zeros(len(g), dtype=bool)
        for i in range(0, len(g) - 2):
            a = r[i + 0]
            b = r[i + 1]
            if np.isfinite(a) and np.isfinite(b):
                if abs(a) > pingpong_threshold and abs(b) > pingpong_threshold and (a * b) < 0:
                    mask_pp[i] = True
                    mask_pp[i + 1] = True
        if mask_pp.any():
            for c in ["clean_open", "clean_high", "clean_low", "clean_close"]:
                g.loc[mask_pp, c] = np.nan

    # ffill clean_closeï¼ˆæ ¸å¿ƒï¼‰
    g["clean_close"] = g["clean_close"].ffill()

    # å…¶é¤˜ OHLC è‹¥ NaNï¼Œç”¨ clean_close è£œï¼ˆä¿å®ˆï¼‰
    for c in ["clean_open", "clean_high", "clean_low"]:
        g[c] = g[c].fillna(g["clean_close"])

    # high/low é‚è¼¯ä¿®æ­£
    g["clean_high"] = np.maximum.reduce([g["clean_high"], g["clean_open"], g["clean_close"]])
    g["clean_low"] = np.minimum.reduce([g["clean_low"], g["clean_open"], g["clean_close"]])

    return g


# -------------------------
# aggregation helpers
# -------------------------
def _agg_period(g: pd.DataFrame) -> Dict[str, float]:
    """
    gï¼šè©² period çš„æ—¥Kï¼ˆå·²å« clean_*ï¼‰
    å›å‚³ period OHLCVï¼ˆç”¨ clean_OHLC + åŸ volumeï¼‰
    """
    if g.empty:
        return dict(open=np.nan, high=np.nan, low=np.nan, close=np.nan, volume=0.0)

    open_ = float(g["clean_open"].iloc[0]) if np.isfinite(g["clean_open"].iloc[0]) else np.nan
    close_ = float(g["clean_close"].iloc[-1]) if np.isfinite(g["clean_close"].iloc[-1]) else np.nan
    high_ = float(np.nanmax(g["clean_high"].values)) if np.isfinite(np.nanmax(g["clean_high"].values)) else np.nan
    low_ = float(np.nanmin(g["clean_low"].values)) if np.isfinite(np.nanmin(g["clean_low"].values)) else np.nan
    vol_ = float(np.nansum(pd.to_numeric(g["volume"], errors="coerce").fillna(0).values))
    return dict(open=open_, high=high_, low=low_, close=close_, volume=vol_)


def build_kbar_tables(
    db_path: str,
    source_table_prefer: str = "stock_analysis",
    enable_anomaly_cleaning: bool = True,
    enable_pingpong: bool = True,
    pingpong_threshold: float = 0.40,
    enable_overlimit_smoothing: bool = True,
) -> Dict[str, int]:
    conn = sqlite3.connect(db_path, timeout=SQLITE_TIMEOUT)

    try:
        existing = set(pd.read_sql("SELECT name FROM sqlite_master WHERE type='table'", conn)["name"].tolist())

        # é¸ä¾†æº
        source = None
        if source_table_prefer in existing:
            source = source_table_prefer
        elif "stock_prices" in existing:
            source = "stock_prices"
        else:
            raise RuntimeError("æ‰¾ä¸åˆ° stock_analysis æˆ– stock_pricesï¼Œè«‹å…ˆè·‘ downloader + processor")

        # è®€è³‡æ–™ï¼ˆè‹¥æ˜¯ stock_prices å¯èƒ½æ²’æœ‰ market / market_detailï¼Œç›¡é‡ join stock_infoï¼‰
        if source == "stock_analysis":
            df = pd.read_sql(
                """
                SELECT symbol, date, open, high, low, close, volume,
                       market, market_detail
                FROM stock_analysis
                """,
                conn,
            )
        else:
            if "stock_info" in existing:
                df = pd.read_sql(
                    """
                    SELECT p.symbol, p.date, p.open, p.high, p.low, p.close, p.volume,
                           i.market, i.market_detail
                    FROM stock_prices p
                    LEFT JOIN stock_info i ON p.symbol = i.symbol
                    """,
                    conn,
                )
            else:
                df = pd.read_sql(
                    "SELECT symbol, date, open, high, low, close, volume FROM stock_prices",
                    conn,
                )
                df["market"] = ""
                df["market_detail"] = ""

        if df.empty:
            print("âŒ ç„¡æ—¥Kè³‡æ–™")
            return {"weekly": 0, "monthly": 0, "yearly": 0}

        df["date"] = pd.to_datetime(df["date"], errors="coerce")
        df = df.dropna(subset=["date"]).sort_values(["symbol", "date"]).reset_index(drop=True)

        weekly_rows = []
        monthly_rows = []
        yearly_rows = []

        for sym, g in df.groupby("symbol", sort=False):
            g = g.sort_values("date").copy()
            if len(g) < 10:
                continue

            market = g["market"].iloc[0] if "market" in g.columns else ""
            market_detail = g["market_detail"].iloc[0] if "market_detail" in g.columns else ""
            limit_up_pct = _get_limit_up_pct(market, market_detail, sym)

            # ç•°å¸¸æ¸…æ´—ï¼ˆç”¢ç”Ÿ clean_*ï¼‰
            if enable_anomaly_cleaning:
                g = _apply_anomaly_cleaning(
                    g,
                    limit_up_pct=limit_up_pct,
                    enable_pingpong=enable_pingpong,
                    pingpong_threshold=pingpong_threshold,
                    enable_overlimit_smoothing=enable_overlimit_smoothing,
                )
            else:
                for c in ["open", "high", "low", "close"]:
                    g[f"clean_{c}"] = pd.to_numeric(g[c], errors="coerce")

            g["year"] = g["date"].dt.year.astype(int)

            # ========== weekly ==========
            # é€±å®šç¾©ï¼šMon~Sunï¼ˆpandas 'W-SUN'ï¼‰
            # period_end = è©²é€±é€±æ—¥ï¼Œperiod_start = é€±ä¸€
            g["week_end"] = g["date"].dt.to_period("W-SUN").dt.end_time.dt.normalize()
            wk_groups = g.groupby(["year", "week_end"], sort=False)

            for (yr, week_end), wg in wk_groups:
                if wg.empty:
                    continue
                week_end = pd.Timestamp(week_end).normalize()
                week_start = (week_end - pd.Timedelta(days=6)).normalize()
                ohlcv = _agg_period(wg)
                # week_id ç”¨ ISO year-weekï¼ˆä»¥ week_end è¨ˆï¼‰
                iso = week_end.isocalendar()
                week_id = f"{int(iso.year)}-W{int(iso.week):02d}"
                weekly_rows.append(
                    {
                        "symbol": sym,
                        "year": int(yr),
                        "week_id": week_id,
                        "period_start": week_start.strftime("%Y-%m-%d"),
                        "period_end": week_end.strftime("%Y-%m-%d"),
                        **ohlcv,
                    }
                )

            # ========== monthly ==========
            g["month_end"] = g["date"].dt.to_period("M").dt.end_time.dt.normalize()
            mo_groups = g.groupby(["year", "month_end"], sort=False)

            for (yr, month_end), mg in mo_groups:
                if mg.empty:
                    continue
                month_end = pd.Timestamp(month_end).normalize()
                month_start = pd.Timestamp(month_end.replace(day=1)).normalize()
                ohlcv = _agg_period(mg)
                month_id = month_start.strftime("%Y-%m")
                monthly_rows.append(
                    {
                        "symbol": sym,
                        "year": int(yr),
                        "month_id": month_id,
                        "period_start": month_start.strftime("%Y-%m-%d"),
                        "period_end": month_end.strftime("%Y-%m-%d"),
                        **ohlcv,
                    }
                )

            # ========== yearly ==========
            yr_groups = g.groupby("year", sort=False)
            for yr, yg in yr_groups:
                if yg.empty:
                    continue
                period_start = pd.Timestamp(f"{int(yr)}-01-01")
                period_end = pd.Timestamp(f"{int(yr)}-12-31")
                # å¯¦éš›ä»¥è©²å¹´è³‡æ–™ min/max date ç•¶ period_start/endï¼ˆæ›´åˆç†ï¼‰
                period_start = pd.Timestamp(yg["date"].min()).normalize()
                period_end = pd.Timestamp(yg["date"].max()).normalize()

                ohlcv = _agg_period(yg)

                # å¹´é«˜é»ï¼šç”¨ clean_high æ‰¾ peak date
                idx = yg["clean_high"].astype(float).idxmax()
                year_peak_date = None
                year_peak_high = np.nan
                if pd.notna(idx) and idx in yg.index:
                    year_peak_date = pd.Timestamp(yg.loc[idx, "date"]).normalize()
                    year_peak_high = float(yg.loc[idx, "clean_high"]) if np.isfinite(yg.loc[idx, "clean_high"]) else np.nan

                yearly_rows.append(
                    {
                        "symbol": sym,
                        "year": int(yr),
                        "period_start": period_start.strftime("%Y-%m-%d"),
                        "period_end": period_end.strftime("%Y-%m-%d"),
                        **ohlcv,
                        "year_peak_date": year_peak_date.strftime("%Y-%m-%d") if year_peak_date is not None else None,
                        "year_peak_high": year_peak_high,
                    }
                )

        wk_df = pd.DataFrame(weekly_rows)
        mo_df = pd.DataFrame(monthly_rows)
        yr_df = pd.DataFrame(yearly_rows)

        # å¯«å›ï¼ˆé‡å»ºï¼‰
        conn.execute("DROP TABLE IF EXISTS kbar_weekly")
        conn.execute("DROP TABLE IF EXISTS kbar_monthly")
        conn.execute("DROP TABLE IF EXISTS kbar_yearly")

        wk_df.to_sql("kbar_weekly", conn, if_exists="replace", index=False)
        mo_df.to_sql("kbar_monthly", conn, if_exists="replace", index=False)
        yr_df.to_sql("kbar_yearly", conn, if_exists="replace", index=False)

        # ç´¢å¼•
        try:
            conn.execute("CREATE INDEX IF NOT EXISTS idx_kbar_w_sym_year ON kbar_weekly(symbol, year)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_kbar_m_sym_year ON kbar_monthly(symbol, year)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_kbar_y_sym_year ON kbar_yearly(symbol, year)")
        except Exception:
            pass

        conn.commit()

        print("\nâœ… kbar_aggregator å®Œæˆï¼ˆå·²ç”¢ç”Ÿé€±/æœˆ/å¹´ Kï¼‰")
        print(f"ğŸ“Œ kbar_weekly: {len(wk_df):,} rows")
        print(f"ğŸ“Œ kbar_monthly: {len(mo_df):,} rows")
        print(f"ğŸ“Œ kbar_yearly: {len(yr_df):,} rows")
        print(f"ğŸ“Œ ç•°å¸¸æ¸…æ´—: {'ON' if enable_anomaly_cleaning else 'OFF'} (pingpong={enable_pingpong}, thr={pingpong_threshold})")

        return {"weekly": int(len(wk_df)), "monthly": int(len(mo_df)), "yearly": int(len(yr_df))}

    finally:
        conn.close()


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python kbar_aggregator.py <db_path>")
        sys.exit(1)

    build_kbar_tables(sys.argv[1])
