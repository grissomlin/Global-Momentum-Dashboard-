# -*- coding: utf-8 -*-
"""
kbar_aggregator.py
------------------
å°‡æ—¥K(stock_prices) èšåˆæˆ

âœ… kbar_weekly   (é€±K)
âœ… kbar_monthly  (æœˆK)
âœ… kbar_yearly   (å¹´K, å« peak_date / peak_high / peak_high_ret)

è¨­è¨ˆç›®æ¨™ï¼š
- èˆ‡ä½ çš„ DB schema ç›¸å®¹ï¼šstock_prices(symbol,date,open,high,low,close,volume)
- èƒ½ç”¨æ–¼å¾ŒçºŒã€Œå°é½Šå¹´Kæœ€é«˜é»ã€çš„è²¢ç»åº¦ç ”ç©¶ï¼ˆpeak_date æ˜¯é—œéµï¼‰
- å¯ç›´æ¥åœ¨ main.py / pipeline å‘¼å«ï¼šbuild_kbars(db_path)

æ³¨æ„ï¼š
- é€™è£¡ä½¿ç”¨ã€Œè‡ªç„¶é€±ã€W-MONï¼ˆé€±ä¸€é–‹å§‹ï¼Œé€±æ—¥çµæŸï¼‰ä½ å¯ä»¥æ”¹æˆ W-FRI ç­‰
- æœˆKï¼šæ¯æœˆè‡ªç„¶æœˆ
- å¹´Kï¼šæ¯å¹´è‡ªç„¶å¹´
"""

import sqlite3
from datetime import datetime
import pandas as pd


# ======================
# å·¥å…·
# ======================
def log(msg: str):
    print(f"{pd.Timestamp.now():%H:%M:%S}: {msg}", flush=True)


def _ensure_tables(conn: sqlite3.Connection):
    """å»ºç«‹ kbar_* è¡¨ï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰ï¼Œä¸¦å»ºç«‹ç´¢å¼•"""
    conn.execute(
        """
        CREATE TABLE IF NOT EXISTS kbar_weekly (
            symbol TEXT,
            week_start TEXT,
            week_end TEXT,
            open REAL,
            high REAL,
            low REAL,
            close REAL,
            volume INTEGER,
            prev_close REAL,
            ret_pct REAL,
            logret REAL,
            PRIMARY KEY (symbol, week_start)
        )
        """
    )
    conn.execute(
        """
        CREATE TABLE IF NOT EXISTS kbar_monthly (
            symbol TEXT,
            month TEXT,           -- YYYY-MM
            period_start TEXT,
            period_end TEXT,
            open REAL,
            high REAL,
            low REAL,
            close REAL,
            volume INTEGER,
            prev_close REAL,
            ret_pct REAL,
            logret REAL,
            PRIMARY KEY (symbol, month)
        )
        """
    )
    conn.execute(
        """
        CREATE TABLE IF NOT EXISTS kbar_yearly (
            symbol TEXT,
            year INTEGER,
            period_start TEXT,
            period_end TEXT,
            open REAL,
            high REAL,
            low REAL,
            close REAL,
            volume INTEGER,

            peak_date TEXT,       -- å¹´å…§æœ€é«˜åƒ¹ç•¶æ—¥æ—¥æœŸ
            peak_high REAL,       -- å¹´å…§æœ€é«˜åƒ¹
            peak_high_ret REAL,   -- (peak_high / year_open - 1) * 100

            prev_close REAL,
            ret_pct REAL,
            logret REAL,

            PRIMARY KEY (symbol, year)
        )
        """
    )

    conn.execute("CREATE INDEX IF NOT EXISTS idx_kbar_w_symbol ON kbar_weekly(symbol)")
    conn.execute("CREATE INDEX IF NOT EXISTS idx_kbar_m_symbol ON kbar_monthly(symbol)")
    conn.execute("CREATE INDEX IF NOT EXISTS idx_kbar_y_symbol ON kbar_yearly(symbol)")


def _read_stock_prices(conn: sqlite3.Connection) -> pd.DataFrame:
    """è®€å– stock_prices + åŸºæœ¬æ¸…æ´—"""
    df = pd.read_sql(
        """
        SELECT symbol, date, open, high, low, close, volume
        FROM stock_prices
        """,
        conn,
    )
    if df.empty:
        return df

    df["date"] = pd.to_datetime(df["date"])
    df = df.sort_values(["symbol", "date"])
    # åŸºæœ¬é˜²å‘†ï¼šç¼ºæ¬„ä½è£œ 0
    if "volume" in df.columns:
        df["volume"] = pd.to_numeric(df["volume"], errors="coerce").fillna(0).astype("int64")
    for c in ["open", "high", "low", "close"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")
    return df


def _calc_prev_ret_log(df: pd.DataFrame, key_cols):
    """
    çµ¦å®š dfï¼ˆå·²ç¶“æ˜¯é€±/æœˆ/å¹´èšåˆçµæœï¼‰ï¼Œä¾ key_colsï¼ˆsymbol + period keyï¼‰æ’åºå¾Œ
    åŠ ä¸Š prev_close / ret_pct / logret
    """
    df = df.sort_values(["symbol"] + key_cols)

    df["prev_close"] = df.groupby("symbol")["close"].shift(1)

    df["ret_pct"] = None
    mask = df["prev_close"].notna() & (df["prev_close"] > 0) & df["close"].notna()
    df.loc[mask, "ret_pct"] = (df.loc[mask, "close"] / df.loc[mask, "prev_close"] - 1.0) * 100.0

    df["logret"] = None
    mask2 = df["prev_close"].notna() & (df["prev_close"] > 0) & df["close"].notna() & (df["close"] > 0)
    df.loc[mask2, "logret"] = (df.loc[mask2, "close"] / df.loc[mask2, "prev_close"]).map(
        lambda x: None if pd.isna(x) else float(pd.np.log(x))  # type: ignore
    )
    return df


# ======================
# èšåˆï¼šé€±K
# ======================
def _build_weekly(df_daily: pd.DataFrame) -> pd.DataFrame:
    """
    é€±Kï¼šW-MONï¼ˆé€±ä¸€ç‚ºé€±æœŸèµ·é»ï¼‰
    é€±å€é–“ï¼šweek_start / week_end
    """
    if df_daily.empty:
        return df_daily

    d = df_daily.copy()
    # week_startï¼šé€±ä¸€
    d["week_start"] = d["date"].dt.to_period("W-MON").apply(lambda p: p.start_time)
    d["week_end"] = d["week_start"] + pd.Timedelta(days=6)

    g = d.groupby(["symbol", "week_start"], as_index=False)

    out = g.agg(
        week_end=("week_end", "max"),
        open=("open", "first"),
        high=("high", "max"),
        low=("low", "min"),
        close=("close", "last"),
        volume=("volume", "sum"),
    )

    # å­—ä¸²åŒ–
    out["week_start"] = pd.to_datetime(out["week_start"]).dt.strftime("%Y-%m-%d")
    out["week_end"] = pd.to_datetime(out["week_end"]).dt.strftime("%Y-%m-%d")

    # prev_close / ret / logretï¼ˆä¾ week_start æ’ï¼‰
    out = out.sort_values(["symbol", "week_start"])
    out["prev_close"] = out.groupby("symbol")["close"].shift(1)

    mask = out["prev_close"].notna() & (out["prev_close"] > 0) & out["close"].notna()
    out["ret_pct"] = None
    out.loc[mask, "ret_pct"] = (out.loc[mask, "close"] / out.loc[mask, "prev_close"] - 1.0) * 100.0

    out["logret"] = None
    mask2 = out["prev_close"].notna() & (out["prev_close"] > 0) & out["close"].notna() & (out["close"] > 0)
    out.loc[mask2, "logret"] = (out.loc[mask2, "close"] / out.loc[mask2, "prev_close"]).map(
        lambda x: None if pd.isna(x) else float(pd.np.log(x))  # type: ignore
    )

    return out


# ======================
# èšåˆï¼šæœˆK
# ======================
def _build_monthly(df_daily: pd.DataFrame) -> pd.DataFrame:
    if df_daily.empty:
        return df_daily

    d = df_daily.copy()
    d["month"] = d["date"].dt.to_period("M").astype(str)  # YYYY-MM
    d["period_start"] = d["date"].dt.to_period("M").apply(lambda p: p.start_time)
    d["period_end"] = d["date"].dt.to_period("M").apply(lambda p: p.end_time)

    g = d.groupby(["symbol", "month"], as_index=False)

    out = g.agg(
        period_start=("period_start", "min"),
        period_end=("period_end", "max"),
        open=("open", "first"),
        high=("high", "max"),
        low=("low", "min"),
        close=("close", "last"),
        volume=("volume", "sum"),
    )

    out["period_start"] = pd.to_datetime(out["period_start"]).dt.strftime("%Y-%m-%d")
    out["period_end"] = pd.to_datetime(out["period_end"]).dt.strftime("%Y-%m-%d")

    out = out.sort_values(["symbol", "month"])
    out["prev_close"] = out.groupby("symbol")["close"].shift(1)

    mask = out["prev_close"].notna() & (out["prev_close"] > 0) & out["close"].notna()
    out["ret_pct"] = None
    out.loc[mask, "ret_pct"] = (out.loc[mask, "close"] / out.loc[mask, "prev_close"] - 1.0) * 100.0

    out["logret"] = None
    mask2 = out["prev_close"].notna() & (out["prev_close"] > 0) & out["close"].notna() & (out["close"] > 0)
    out.loc[mask2, "logret"] = (out.loc[mask2, "close"] / out.loc[mask2, "prev_close"]).map(
        lambda x: None if pd.isna(x) else float(pd.np.log(x))  # type: ignore
    )

    return out


# ======================
# èšåˆï¼šå¹´Kï¼ˆå« peak_dateï¼‰
# ======================
def _build_yearly(df_daily: pd.DataFrame) -> pd.DataFrame:
    if df_daily.empty:
        return df_daily

    d = df_daily.copy()
    d["year"] = d["date"].dt.year
    d["period_start"] = d["date"].dt.to_period("Y").apply(lambda p: p.start_time)
    d["period_end"] = d["date"].dt.to_period("Y").apply(lambda p: p.end_time)

    # å…ˆåšå¹´K OHLCV
    g = d.groupby(["symbol", "year"], as_index=False)
    y = g.agg(
        period_start=("period_start", "min"),
        period_end=("period_end", "max"),
        open=("open", "first"),
        high=("high", "max"),
        low=("low", "min"),
        close=("close", "last"),
        volume=("volume", "sum"),
    )

    y["period_start"] = pd.to_datetime(y["period_start"]).dt.strftime("%Y-%m-%d")
    y["period_end"] = pd.to_datetime(y["period_end"]).dt.strftime("%Y-%m-%d")

    # peak_date / peak_highï¼šç”±æ—¥Kæ‰¾å¹´å…§æœ€é«˜ high çš„é‚£ä¸€å¤©
    # åšæ³•ï¼šå…ˆæ‰¾æ¯å€‹ (symbol, year) çš„ max_highï¼Œå†å›è²¼ç¬¬ä¸€å€‹å‘½ä¸­çš„æ—¥æœŸ
    d_valid = d.dropna(subset=["high"]).copy()
    max_high = (
        d_valid.groupby(["symbol", "year"], as_index=False)["high"]
        .max()
        .rename(columns={"high": "peak_high"})
    )

    d2 = d_valid.merge(max_high, on=["symbol", "year"], how="left")
    d2 = d2[d2["high"] == d2["peak_high"]].sort_values(["symbol", "year", "date"])
    peak = d2.groupby(["symbol", "year"], as_index=False).first()[["symbol", "year", "date", "peak_high"]]
    peak = peak.rename(columns={"date": "peak_date"})
    peak["peak_date"] = pd.to_datetime(peak["peak_date"]).dt.strftime("%Y-%m-%d")

    y = y.merge(peak, on=["symbol", "year"], how="left")

    # peak_high_ret = (peak_high / year_open - 1) * 100
    y["peak_high_ret"] = None
    maskp = y["open"].notna() & (y["open"] > 0) & y["peak_high"].notna()
    y.loc[maskp, "peak_high_ret"] = (y.loc[maskp, "peak_high"] / y.loc[maskp, "open"] - 1.0) * 100.0

    # prev_close / ret / logretï¼ˆä¾ year æ’ï¼‰
    y = y.sort_values(["symbol", "year"])
    y["prev_close"] = y.groupby("symbol")["close"].shift(1)

    mask = y["prev_close"].notna() & (y["prev_close"] > 0) & y["close"].notna()
    y["ret_pct"] = None
    y.loc[mask, "ret_pct"] = (y.loc[mask, "close"] / y.loc[mask, "prev_close"] - 1.0) * 100.0

    y["logret"] = None
    mask2 = y["prev_close"].notna() & (y["prev_close"] > 0) & y["close"].notna() & (y["close"] > 0)
    y.loc[mask2, "logret"] = (y.loc[mask2, "close"] / y.loc[mask2, "prev_close"]).map(
        lambda x: None if pd.isna(x) else float(pd.np.log(x))  # type: ignore
    )

    return y


# ======================
# å¯«å…¥ DBï¼ˆreplace or upsertï¼‰
# ======================
def _write_table(conn: sqlite3.Connection, df: pd.DataFrame, table_name: str, pk_cols: list):
    """
    ä»¥ INSERT OR REPLACE å¯«å…¥ï¼Œé¿å…é‡è¤‡
    """
    if df.empty:
        return

    cols = list(df.columns)
    placeholders = ", ".join(["?"] * len(cols))
    col_list = ", ".join(cols)

    sql = f"INSERT OR REPLACE INTO {table_name} ({col_list}) VALUES ({placeholders})"
    data = df[cols].where(pd.notna(df[cols]), None).values.tolist()
    conn.executemany(sql, data)


# ======================
# å°å¤– API
# ======================
def build_kbars(db_path: str, rebuild: bool = True) -> dict:
    """
    å…¥å£ï¼šå¾ stock_prices å»ºç«‹ kbar_weekly/monthly/yearly

    rebuild=Trueï¼šæœƒå…ˆ DROP èˆŠè¡¨å†é‡å»ºï¼ˆæœ€ä¹¾æ·¨ï¼‰
    rebuild=Falseï¼šä¿ç•™è¡¨çµæ§‹ï¼Œåªåš INSERT OR REPLACE æ›´æ–°ï¼ˆè¼ƒå¿«ï¼‰
    """
    t0 = time.time() if "time" in globals() else None  # é˜²å‘†

    log(f"ğŸ§± é–‹å§‹å»ºç«‹ KBar èšåˆè¡¨: {db_path}")

    conn = sqlite3.connect(db_path)
    try:
        if rebuild:
            conn.execute("DROP TABLE IF EXISTS kbar_weekly")
            conn.execute("DROP TABLE IF EXISTS kbar_monthly")
            conn.execute("DROP TABLE IF EXISTS kbar_yearly")
            conn.commit()

        _ensure_tables(conn)

        df_daily = _read_stock_prices(conn)
        if df_daily.empty:
            log("âš ï¸ stock_prices æ²’è³‡æ–™ï¼Œè·³é kbar èšåˆ")
            return {"ok": False, "weekly": 0, "monthly": 0, "yearly": 0}

        log(f"ğŸ“¥ è®€å–æ—¥Kå®Œæˆ: {len(df_daily):,} ç­† | symbols={df_daily['symbol'].nunique():,}")

        # Build
        log("ğŸ§© ç”Ÿæˆé€±K...")
        w = _build_weekly(df_daily)
        log(f"âœ… é€±Kå®Œæˆ: {len(w):,}")

        log("ğŸ§© ç”ŸæˆæœˆK...")
        m = _build_monthly(df_daily)
        log(f"âœ… æœˆKå®Œæˆ: {len(m):,}")

        log("ğŸ§© ç”Ÿæˆå¹´Kï¼ˆå« peak_dateï¼‰...")
        y = _build_yearly(df_daily)
        log(f"âœ… å¹´Kå®Œæˆ: {len(y):,}")

        # Write
        log("ğŸ’¾ å¯«å…¥è³‡æ–™åº«...")
        _write_table(conn, w, "kbar_weekly", ["symbol", "week_start"])
        _write_table(conn, m, "kbar_monthly", ["symbol", "month"])
        _write_table(conn, y, "kbar_yearly", ["symbol", "year"])
        conn.commit()

        # ç´¢å¼•èˆ‡çµ±è¨ˆ
        weekly_cnt = conn.execute("SELECT COUNT(*) FROM kbar_weekly").fetchone()[0]
        monthly_cnt = conn.execute("SELECT COUNT(*) FROM kbar_monthly").fetchone()[0]
        yearly_cnt = conn.execute("SELECT COUNT(*) FROM kbar_yearly").fetchone()[0]

        log(f"ğŸ“Š KBar èšåˆå®Œæˆ | weekly={weekly_cnt:,} monthly={monthly_cnt:,} yearly={yearly_cnt:,}")

        return {"ok": True, "weekly": weekly_cnt, "monthly": monthly_cnt, "yearly": yearly_cnt}

    finally:
        conn.close()


# ======================
# CLI
# ======================
if __name__ == "__main__":
    import sys
    import time as _time

    if len(sys.argv) < 2:
        print("ç”¨æ³•: python kbar_aggregator.py <db_path> [--no-rebuild]")
        raise SystemExit(1)

    db_path = sys.argv[1]
    rebuild = True
    if len(sys.argv) >= 3 and sys.argv[2] == "--no-rebuild":
        rebuild = False

    t0 = _time.time()
    res = build_kbars(db_path, rebuild=rebuild)
    print(res)
    print(f"è€—æ™‚: {_time.time()-t0:.1f} ç§’")
