-*- coding: utf-8 -*-
import os, sys, sqlite3, json, time, socket, io
import pandas as pd
from datetime import datetime, timedelta
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload
from dotenv import load_dotenv

ğŸ’¡ 1. è¼‰å…¥ç’°å¢ƒè®Šæ•¸èˆ‡ç’°å¢ƒè¨­å®š
load_dotenv()
socket.setdefaulttimeout(600)

ğŸ’¡ 2. å¼·åˆ¶æ—¥æœŸé™åˆ¶ (ä¾éœ€æ±‚é–å®š)
FORCE_START_DATE = "2024-01-01"
FORCE_END_DATE = "2025-12-31"

GDRIVE_FOLDER_ID = os.environ.get('GDRIVE_FOLDER_ID')

ğŸ’¡ 3. å°å…¥ç‰¹å¾µåŠ å·¥æ¨¡çµ„ (ä¿ç•™ processor)
try:
from processor import process_market_data
except ImportError:
print("âš ï¸ ç³»çµ±æç¤ºï¼šæ‰¾ä¸åˆ° processor.py")
process_market_data = None

ğŸ’¡ 5. å‹•æ…‹å°å…¥ä¸‹è¼‰å™¨æ¨¡çµ„
def load_downloader(module_name):
"""å‹•æ…‹è¼‰å…¥ä¸‹è¼‰å™¨æ¨¡çµ„ï¼ŒåŒ…å«éŒ¯èª¤è™•ç†"""
try:
module = import(module_name)

text
    # æª¢æŸ¥æ¨¡çµ„æ˜¯å¦æœ‰å¿…è¦çš„ run_sync å‡½æ•¸
    if hasattr(module, 'run_sync'):
        return module
    else:
        print(f"âš ï¸ {module_name} æ¨¡çµ„ç¼ºå°‘ run_sync å‡½æ•¸")
        return None
except ImportError as e:
    print(f"âš ï¸ ç„¡æ³•è¼‰å…¥ {module_name} æ¨¡çµ„: {e}")
    return None
except Exception as e:
    print(f"âš ï¸ è¼‰å…¥ {module_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    return None
è¼‰å…¥æ‰€æœ‰ä¸‹è¼‰å™¨
downloader_tw = load_downloader('downloader_tw')
downloader_us = load_downloader('downloader_us')
downloader_cn = load_downloader('downloader_cn')
downloader_hk = load_downloader('downloader_hk')
downloader_jp = load_downloader('downloader_jp')
downloader_kr = load_downloader('downloader_kr')

å»ºç«‹å¸‚å ´æ˜ å°„
module_map = {
'tw': downloader_tw,
'us': downloader_us,
'cn': downloader_cn,
'hk': downloader_hk,
'jp': downloader_jp,
'kr': downloader_kr
}

========== ğŸ’¡ è¼”åŠ©å‡½å¼ ==========
def get_db_last_date(db_path):
"""å–å¾—è³‡æ–™åº«æœ€å¾Œæ›´æ–°æ—¥æœŸ"""
if not os.path.exists(db_path):
return None
try:
conn = sqlite3.connect(db_path)
res = conn.execute("SELECT MAX(date) FROM stock_prices").fetchone()
conn.close()
return res[0] if res[0] else None
except Exception:
return None

def check_market_requirements(market):
"""æª¢æŸ¥å¸‚å ´ç‰¹å®šéœ€æ±‚"""
if market == 'kr':
# æª¢æŸ¥éŸ“åœ‹å¸‚å ´éœ€è¦çš„ CSV æ–‡ä»¶
csv_files = ['krx_corp_list.csv']
missing_files = []

text
    for csv_file in csv_files:
        if not os.path.exists(csv_file):
            missing_files.append(csv_file)
    
    if missing_files:
        print(f"âŒ éŸ“åœ‹å¸‚å ´éœ€è¦ä»¥ä¸‹æ–‡ä»¶: {', '.join(missing_files)}")
        print(f"   è«‹å°‡æ–‡ä»¶æ”¾ç½®æ–¼ç•¶å‰ç›®éŒ„: {os.getcwd()}")
        return False
    
    print(f"âœ… æ‰¾åˆ°éŸ“åœ‹è‚¡ç¥¨æ¸…å–®æ–‡ä»¶: {csv_files[0]}")

return True
def get_market_display_name(market_code):
"""å–å¾—å¸‚å ´é¡¯ç¤ºåç¨±"""
market_names = {
'tw': 'å°ç£',
'us': 'ç¾åœ‹',
'cn': 'ä¸­åœ‹',
'hk': 'é¦™æ¸¯',
'jp': 'æ—¥æœ¬',
'kr': 'éŸ“åœ‹'
}
return market_names.get(market_code, market_code.upper())

========== â˜ï¸ Google Drive æœå‹™å‡½å¼ ==========
def get_drive_service():
"""å–å¾— Google Drive æœå‹™"""
env_json = os.environ.get('GDRIVE_SERVICE_ACCOUNT')
try:
if env_json:
info = json.loads(env_json)
creds = service_account.Credentials.from_service_account_info(
info, scopes=['https://www.googleapis.com/auth/drive'])
return build('drive', 'v3', credentials=creds, cache_discovery=False)
else:
print("âš ï¸ æœªæ‰¾åˆ° GDRIVE_SERVICE_ACCOUNT ç’°å¢ƒè®Šæ•¸ï¼Œè·³éé›²ç«¯åŒæ­¥")
return None
except Exception as e:
print(f"âŒ Drive æœå‹™åˆå§‹åŒ–å¤±æ•—: {e}")
return None

def download_db_from_drive(service, file_name):
"""å¾ Google Drive ä¸‹è¼‰è³‡æ–™åº«"""
if not GDRIVE_FOLDER_ID:
print("âš ï¸ æœªè¨­å®š GDRIVE_FOLDER_IDï¼Œè·³éé›²ç«¯ä¸‹è¼‰")
return False

text
query = f"name = '{file_name}' and '{GDRIVE_FOLDER_ID}' in parents and trashed = false"
try:
    results = service.files().list(q=query, fields="files(id)").execute()
    items = results.get('files', [])
    if not items: 
        print(f"â„¹ï¸ é›²ç«¯ç„¡ {file_name} æª”æ¡ˆï¼Œå°‡å‰µå»ºæ–°æª”")
        return False
    
    file_id = items[0]['id']
    print(f"ğŸ“¡ å¾é›²ç«¯åŒæ­¥: {file_name}")
    request = service.files().get_media(fileId=file_id)
    
    with io.FileIO(file_name, 'wb') as fh:
        downloader = MediaIoBaseDownload(fh, request, chunksize=5*1024*1024)
        done = False
        while not done: 
            _, done = downloader.next_chunk()
    
    print(f"âœ… é›²ç«¯ä¸‹è¼‰å®Œæˆ: {file_name}")
    return True
except Exception as e:
    print(f"âš ï¸ é›²ç«¯ä¸‹è¼‰å¤±æ•— {file_name}: {e}")
    return False
def upload_db_to_drive(service, file_path, max_retries=3):
"""ä¸Šå‚³è³‡æ–™åº«åˆ° Google Drive"""
if not GDRIVE_FOLDER_ID or not os.path.exists(file_path):
return False

text
file_name = os.path.basename(file_path)
file_size = os.path.getsize(file_path)
chunk_size = 5 * 1024 * 1024

if file_size > 100 * 1024 * 1024: 
    chunk_size = 10 * 1024 * 1024

for attempt in range(max_retries):
    try:
        media = MediaFileUpload(file_path, mimetype='application/x-sqlite3', 
                               resumable=True, chunksize=chunk_size)
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        query = f"name = '{file_name}' and '{GDRIVE_FOLDER_ID}' in parents and trashed = false"
        results = service.files().list(q=query, fields="files(id)").execute()
        items = results.get('files', [])
        
        if items:
            print(f"ğŸ”„ æ›´æ–°é›²ç«¯æª”æ¡ˆ (ç¬¬ {attempt+1} æ¬¡é‡è©¦)")
            request = service.files().update(fileId=items[0]['id'], media_body=media, fields='id')
        else:
            print(f"ğŸ†• å‰µå»ºé›²ç«¯æª”æ¡ˆ (ç¬¬ {attempt+1} æ¬¡é‡è©¦)")
            meta = {'name': file_name, 'parents': [GDRIVE_FOLDER_ID]}
            request = service.files().create(body=meta, media_body=media, fields='id')
        
        response = None
        while response is None:
            status, response = request.next_chunk()
            if status: 
                print(f"  ä¸Šå‚³é€²åº¦: {int(status.progress() * 100)}%")
        
        print(f"âœ… {file_name} ä¸Šå‚³æˆåŠŸ!")
        return True
        
    except Exception as e:
        error_msg = str(e)
        print(f"âš ï¸ ä¸Šå‚³å¤±æ•— {file_name}: {error_msg}")
        
        if "SSL" in error_msg or "EOF" in error_msg:
            time.sleep(5 * (attempt + 1))
            # é‡æ–°å»ºç«‹æœå‹™
            service = get_drive_service()
            if not service:
                print("âŒ ç„¡æ³•é‡æ–°å»ºç«‹ Drive æœå‹™")
                return False
        else:
            time.sleep(2 * (attempt + 1))

print(f"âŒ {file_name} ä¸Šå‚³å¤±æ•—ï¼Œå·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸")
return False
def optimize_database(db_file):
"""å„ªåŒ–è³‡æ–™åº«"""
try:
conn = sqlite3.connect(db_file)

text
    # æª¢æŸ¥è¡¨çµæ§‹
    cursor = conn.cursor()
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
    tables = cursor.fetchall()
    
    print(f"ğŸ”§ å„ªåŒ–è³‡æ–™åº«: {db_file}")
    print(f"   ç™¼ç¾ {len(tables)} å€‹è¡¨æ ¼")
    
    # åŸ·è¡Œ VACUUM
    conn.execute("VACUUM")
    conn.close()
    
    print(f"âœ… è³‡æ–™åº«å„ªåŒ–å®Œæˆ: {db_file}")
    return True
    
except Exception as e:
    print(f"âŒ è³‡æ–™åº«å„ªåŒ–å¤±æ•— {db_file}: {e}")
    return False
========== ğŸ å¸‚å ´è™•ç†å‡½å¼ ==========
def process_market(market_code, service):
"""è™•ç†å–®ä¸€å¸‚å ´çš„ä¸‹è¼‰èˆ‡è™•ç†æµç¨‹"""
print(f"\n{'='*50}")
print(f"ğŸš€ é–‹å§‹è™•ç†: {get_market_display_name(market_code)}å¸‚å ´ ({market_code.upper()})")
print(f"{'='*50}")

text
# æª¢æŸ¥ä¸‹è¼‰å™¨æ¨¡çµ„
downloader_module = module_map.get(market_code)
if not downloader_module:
    print(f"âŒ {get_market_display_name(market_code)}å¸‚å ´ä¸‹è¼‰å™¨æœªè¼‰å…¥ï¼Œè·³é")
    return False

# æª¢æŸ¥å¸‚å ´ç‰¹å®šéœ€æ±‚
if not check_market_requirements(market_code):
    return False

# è¨­å®šè³‡æ–™åº«æª”æ¡ˆåç¨±
db_file = f"{market_code}_stock_warehouse.db"

# å¾é›²ç«¯ä¸‹è¼‰ç¾æœ‰è³‡æ–™åº«
if service:
    download_db_from_drive(service, db_file)

# è¨ˆç®—å¢é‡ä¸‹è¼‰æ—¥æœŸ
last_date = get_db_last_date(db_file)
actual_start = FORCE_START_DATE

if last_date:
    try:
        last_date_dt = pd.to_datetime(last_date)
        next_day = last_date_dt + timedelta(days=1)
        actual_start = next_day.strftime("%Y-%m-%d")
        print(f"ğŸ“… æœ€å¾Œæ›´æ–°æ—¥æœŸ: {last_date}ï¼Œå¢é‡ä¸‹è¼‰å¾: {actual_start}")
    except Exception:
        print(f"âš ï¸ ç„¡æ³•è§£ææœ€å¾Œæ›´æ–°æ—¥æœŸï¼Œå¾é ­ä¸‹è¼‰")

# æª¢æŸ¥æ˜¯å¦éœ€è¦ä¸‹è¼‰
if actual_start and actual_start <= FORCE_END_DATE:
    print(f"ğŸ“¡ åŒæ­¥å€é–“: {actual_start} ~ {FORCE_END_DATE}")
    
    # åŸ·è¡Œä¸‹è¼‰
    try:
        download_start_time = time.time()
        
        # åŸ·è¡Œä¸‹è¼‰å™¨
        result = downloader_module.run_sync(
            start_date=actual_start, 
            end_date=FORCE_END_DATE
        )
        
        download_duration = time.time() - download_start_time
        
        if result and result.get('success', 0) > 0:
            success_count = result.get('success', 0)
            total_count = result.get('total', 0)
            
            print(f"âœ… {get_market_display_name(market_code)}ä¸‹è¼‰å®Œæˆ")
            print(f"   æˆåŠŸ: {success_count}/{total_count}")
            print(f"   è€—æ™‚: {download_duration:.1f}ç§’")
            
            # åŸ·è¡Œç‰¹å¾µè™•ç†
            if process_market_data:
                print(f"ğŸ”§ é–‹å§‹ç‰¹å¾µè™•ç†...")
                process_start_time = time.time()
                
                try:
                    process_market_data(db_file)
                    process_duration = time.time() - process_start_time
                    print(f"âœ… ç‰¹å¾µè™•ç†å®Œæˆï¼Œè€—æ™‚: {process_duration:.1f}ç§’")
                except Exception as e:
                    print(f"âŒ ç‰¹å¾µè™•ç†å¤±æ•—: {e}")
            else:
                print(f"âš ï¸ è·³éç‰¹å¾µè™•ç† (æœªè¼‰å…¥ processor)")
            
            # å„ªåŒ–ä¸¦ä¸Šå‚³åˆ°é›²ç«¯
            if service:
                print(f"â˜ï¸ é–‹å§‹é›²ç«¯åŒæ­¥...")
                upload_start_time = time.time()
                
                # å…ˆå„ªåŒ–è³‡æ–™åº«
                if optimize_database(db_file):
                    # ä¸Šå‚³åˆ°é›²ç«¯
                    if upload_db_to_drive(service, db_file):
                        upload_duration = time.time() - upload_start_time
                        print(f"âœ… é›²ç«¯åŒæ­¥å®Œæˆï¼Œè€—æ™‚: {upload_duration:.1f}ç§’")
                    else:
                        print(f"âš ï¸ é›²ç«¯åŒæ­¥å¤±æ•—")
                else:
                    print(f"âš ï¸ è·³éé›²ç«¯åŒæ­¥ (è³‡æ–™åº«å„ªåŒ–å¤±æ•—)")
            
            return True
        else:
            print(f"âš ï¸ {get_market_display_name(market_code)}ä¸‹è¼‰æœªæˆåŠŸ")
            if result:
                print(f"   æˆåŠŸ: {result.get('success', 0)}/{result.get('total', 0)}")
            return False
            
    except Exception as e:
        print(f"âŒ {get_market_display_name(market_code)}ä¸‹è¼‰éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return False
else:
    print(f"â­ï¸ ç„¡éœ€æ›´æ–°ï¼Œæœ€å¾Œæ—¥æœŸ: {last_date}")
    return True
========== ğŸ ä¸»ç¨‹å¼ ==========
def main():
"""ä¸»ç¨‹å¼å…¥å£"""
print("ğŸŒ å…¨çƒè‚¡ç¥¨æ•¸æ“šåŒæ­¥ç³»çµ±")
print("="*50)

text
# è§£æå‘½ä»¤è¡Œåƒæ•¸
target_market = sys.argv[1].lower() if len(sys.argv) > 1 else 'all'

# é¡¯ç¤ºç³»çµ±è³‡è¨Š
print(f"ğŸ“… å¼·åˆ¶æ—¥æœŸç¯„åœ: {FORCE_START_DATE} ~ {FORCE_END_DATE}")
print(f"ğŸ¯ ç›®æ¨™å¸‚å ´: {get_market_display_name(target_market) if target_market != 'all' else 'å…¨éƒ¨å¸‚å ´'}")

# åˆå§‹åŒ–é›²ç«¯æœå‹™
service = get_drive_service()
if service and GDRIVE_FOLDER_ID:
    print("â˜ï¸ é›²ç«¯åŒæ­¥: å•Ÿç”¨")
else:
    print("â˜ï¸ é›²ç«¯åŒæ­¥: åœç”¨")

# ç¢ºå®šè¦åŸ·è¡Œçš„å¸‚å ´
if target_market == 'all':
    markets_to_run = list(module_map.keys())
elif target_market in module_map:
    markets_to_run = [target_market]
else:
    print(f"âŒ æœªçŸ¥çš„å¸‚å ´ä»£ç¢¼: {target_market}")
    print(f"   å¯ç”¨çš„å¸‚å ´: {', '.join([f'{k}({get_market_display_name(k)})' for k in module_map.keys()])}")
    return

print(f"ğŸ“Š å°‡è™•ç† {len(markets_to_run)} å€‹å¸‚å ´")

# é–‹å§‹è™•ç†
start_time = time.time()
successful_markets = []
failed_markets = []

for market_code in markets_to_run:
    market_start_time = time.time()
    
    if process_market(market_code, service):
        successful_markets.append(market_code)
    else:
        failed_markets.append(market_code)
    
    market_duration = time.time() - market_start_time
    print(f"â±ï¸  {get_market_display_name(market_code)}è™•ç†æ™‚é–“: {market_duration:.1f}ç§’\n")

# ç¸½çµå ±å‘Š
total_duration = time.time() - start_time

print("="*50)
print("ğŸ“Š è™•ç†ç¸½çµå ±å‘Š")
print("="*50)

if successful_markets:
    print(f"âœ… æˆåŠŸè™•ç†: {len(successful_markets)} å€‹å¸‚å ´")
    for market in successful_markets:
        print(f"   - {get_market_display_name(market)}")

if failed_markets:
    print(f"âŒ è™•ç†å¤±æ•—: {len(failed_markets)} å€‹å¸‚å ´")
    for market in failed_markets:
        print(f"   - {get_market_display_name(market)}")

print(f"\nâ±ï¸  ç¸½è™•ç†æ™‚é–“: {total_duration:.1f}ç§’ ({total_duration/60:.1f}åˆ†é˜)")
print(f"âœ… åŒæ­¥å®Œæˆ!")
if name == "main":
main()
