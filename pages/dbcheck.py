# pages/dbcheck.py
# -*- coding: utf-8 -*-
import os
import sqlite3
import pandas as pd
import streamlit as st
from datetime import datetime

# -----------------------------
# Helpers
# -----------------------------
def list_db_files(search_dirs):
    out = []
    for d in search_dirs:
        if d and os.path.isdir(d):
            for fn in os.listdir(d):
                if fn.lower().endswith(".db"):
                    out.append(os.path.join(d, fn))
    # å»é‡ + æ’åº
    out = sorted(list(dict.fromkeys(out)))
    return out

def get_tables(conn):
    q = "SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%' ORDER BY name"
    return [r[0] for r in conn.execute(q).fetchall()]

def get_columns(conn, table):
    # PRAGMA table_info returns: cid, name, type, notnull, dflt_value, pk
    rows = conn.execute(f"PRAGMA table_info({table})").fetchall()
    return [{"name": r[1], "type": r[2], "notnull": r[3], "pk": r[5]} for r in rows]

def get_count(conn, table):
    return conn.execute(f"SELECT COUNT(*) FROM {table}").fetchone()[0]

def read_head(conn, table, n):
    return pd.read_sql(f"SELECT * FROM {table} LIMIT {int(n)}", conn)

def make_ai_prompt(table, cols, sample_df):
    col_lines = "\n".join([f"- {c['name']} ({c['type']})" for c in cols])
    sample_csv = sample_df.to_csv(index=False)
    return f"""ä½ æ˜¯ä¸€ä½è³‡æ–™å·¥ç¨‹/é‡åŒ–ç ”ç©¶åŠ©ç†ã€‚è«‹å”åŠ©æˆ‘ç†è§£ SQLite è³‡æ–™è¡¨çš„æ¬„ä½å®šç¾©èˆ‡ç”¨é€”ï¼Œä¸¦æª¢æŸ¥æ˜¯å¦æœ‰ç¼ºæ¬„ã€å‹åˆ¥ä¸ä¸€è‡´æˆ–å¯ç–‘è³‡æ–™å“è³ªå•é¡Œã€‚

ã€Tableã€‘{table}

ã€Schemaã€‘
{col_lines}

ã€Top rows (CSV)ã€‘
{sample_csv}

è«‹è¼¸å‡ºï¼š
1) ä½ å°æ¯å€‹æ¬„ä½çš„ç”¨é€”æ¨æ¸¬ï¼ˆä¸­è‹±æ–‡ï¼‰
2) ä½ è¦ºå¾—æœ€å¯èƒ½éœ€è¦è£œå……/ä¿®æ­£çš„æ¬„ä½èˆ‡ç†ç”±
3) å»ºè­°æˆ‘å¾ŒçºŒç”¨å“ªäº› SQL/æŸ¥è©¢å»é©—è­‰è³‡æ–™å“è³ª
"""

# -----------------------------
# UI
# -----------------------------
st.set_page_config(page_title="DB Check", layout="wide")
st.title("ğŸ§ª DB Checkï¼ˆè³‡æ–™åº«è®€å– + Schema + Sample + æ¬„ä½å­—å…¸ + AI Promptï¼‰")
st.caption("ç”¨é€”ï¼šç¢ºèª SQLite DB å¯æ­£å¸¸è®€å–ã€å¿«é€Ÿçœ‹åˆ°æ¯å€‹ table çš„æ¬„ä½èˆ‡å‰ N ç­†ï¼Œä¸¦ç”Ÿæˆå¯ç›´æ¥è²¼å»å• AI çš„ promptã€‚")

# æœå°‹ db çš„ç›®éŒ„ï¼šå°ˆæ¡ˆæ ¹ç›®éŒ„ + /tmpï¼ˆRender/GHA å¸¸ç”¨ï¼‰
search_dirs = [os.getcwd(), "/tmp"]
db_files = list_db_files(search_dirs)

with st.expander("ğŸ” ç’°å¢ƒè³‡è¨Š / DB æƒæ", expanded=False):
    st.write("ç•¶å‰ç›®éŒ„:", os.getcwd())
    st.write("å¯æƒæç›®éŒ„:", search_dirs)
    if db_files:
        for p in db_files:
            st.write(f"âœ… {os.path.basename(p)} - {os.path.getsize(p):,} bytes - {p}")
    else:
        st.warning("æ‰¾ä¸åˆ°ä»»ä½• .db æª”æ¡ˆã€‚è«‹å…ˆåŒæ­¥ DB æˆ–ç¢ºèª DB è½åœ°è·¯å¾‘ã€‚")

if not db_files:
    st.stop()

# é è¨­æŒ‘ tw_stock_warehouse.dbï¼ˆå¦‚æœå­˜åœ¨ï¼‰
default_idx = 0
for i, p in enumerate(db_files):
    if os.path.basename(p) == "tw_stock_warehouse.db":
        default_idx = i
        break

db_path = st.selectbox(
    "SQLite DB è·¯å¾‘ï¼ˆè‡ªå‹•æƒæï¼‰",
    db_files,
    index=default_idx,
)

# å…¨ç«™å…±ç”¨ï¼šå¯«å…¥ session_state
st.session_state["db_path"] = db_path
st.session_state["db_name"] = os.path.basename(db_path)

n_head = st.number_input("æ¯è¡¨é¡¯ç¤ºå‰ N ç­†", min_value=1, max_value=200, value=10, step=1)

# æ¬„ä½å­—å…¸ï¼ˆä½ å¯ä»¥æ…¢æ…¢æ“´å……ï¼‰
# key: (table, column) -> {"zh": "...", "en": "...", "note": "..."}
COLUMN_DICT = {
    ("stock_prices", "symbol"): {"zh": "è‚¡ç¥¨ä»£è™Ÿ", "en": "Symbol/Ticker"},
    ("stock_prices", "date"): {"zh": "äº¤æ˜“æ—¥æœŸ", "en": "Trading date"},
    ("stock_prices", "open"): {"zh": "é–‹ç›¤åƒ¹", "en": "Open price"},
    ("stock_prices", "high"): {"zh": "æœ€é«˜åƒ¹", "en": "High price"},
    ("stock_prices", "low"): {"zh": "æœ€ä½åƒ¹", "en": "Low price"},
    ("stock_prices", "close"): {"zh": "æ”¶ç›¤åƒ¹", "en": "Close price"},
    ("stock_prices", "volume"): {"zh": "æˆäº¤é‡", "en": "Volume"},
    ("stock_info", "market"): {"zh": "å¸‚å ´ä»£ç¢¼", "en": "Market code"},
    ("stock_info", "sector"): {"zh": "ç”¢æ¥­åˆ¥", "en": "Sector"},
    ("stock_analysis", "is_limit_up"): {"zh": "æ˜¯å¦æ¼²åœ(æ”¶ç›¤)", "en": "Is limit-up at close"},
    ("stock_analysis", "lu_type"): {"zh": "æ¼²åœå‹æ…‹", "en": "Limit-up pattern type"},
    ("stock_analysis", "consecutive_limits"): {"zh": "é€£æ¿å¤©æ•¸", "en": "Consecutive limit-up days"},
    ("stock_analysis", "strength_rank"): {"zh": "å¼·åº¦åˆ†ç®±æ¨™ç±¤", "en": "Strength rank bin label"},
    ("stock_analysis", "strength_value"): {"zh": "å¼·åº¦æ•¸å€¼åŒ–", "en": "Strength numeric value"},
}

# è®€ DB
conn = sqlite3.connect(db_path, timeout=60)

try:
    tables = get_tables(conn)
    if not tables:
        st.warning("DB å…§æ²’æœ‰ä»»ä½• tableã€‚")
        st.stop()

    st.subheader("ğŸ“š Tables")
    cols = st.columns([2, 1, 1, 4])
    with cols[0]:
        table = st.selectbox("é¸æ“‡ Table", tables, index=0)
    with cols[1]:
        show_schema = st.toggle("é¡¯ç¤ºæ¬„ä½", value=True)
    with cols[2]:
        show_dict = st.toggle("é¡¯ç¤ºå­—å…¸", value=True)
    with cols[3]:
        st.info("æç¤ºï¼šä½ ä¹Ÿå¯ä»¥ç”¨é€™é ç”Ÿæˆ promptï¼Œç›´æ¥è²¼å»å• AI åšè³‡æ–™å“è³ªæª¢æŸ¥ / æ¬„ä½ç”¨é€”æ¨æ¸¬ã€‚")

    # åŸºæœ¬è³‡è¨Š
    total = get_count(conn, table)
    st.write(f"**{table}** | rows: **{total:,}**")

    # Schema
    cols_meta = get_columns(conn, table)
    if show_schema:
        schema_df = pd.DataFrame(cols_meta)
        st.markdown("### ğŸ§± Schema")
        st.dataframe(schema_df, use_container_width=True)

    # Sample rows
    st.markdown("### ğŸ”Ÿ Sample (Top N rows)")
    sample_df = read_head(conn, table, n_head)
    st.dataframe(sample_df, use_container_width=True)

    # Dictionary
    if show_dict:
        st.markdown("### ğŸ“– æ¬„ä½å­—å…¸ï¼ˆä¸­è‹±æ–‡ï¼‰")
        dict_rows = []
        for c in cols_meta:
            key = (table, c["name"])
            d = COLUMN_DICT.get(key, {})
            dict_rows.append({
                "column": c["name"],
                "type": c["type"],
                "zh": d.get("zh", ""),
                "en": d.get("en", ""),
                "note": d.get("note", ""),
            })
        dict_df = pd.DataFrame(dict_rows)
        st.dataframe(dict_df, use_container_width=True)

        st.caption("âœ… é€™ä»½å­—å…¸ä½ å¯ä»¥é€æ­¥è£œé½Šï¼ˆæ–°å¢åˆ° COLUMN_DICTï¼‰ã€‚")

    # AI Prompt
    st.markdown("### ğŸ¤– ä¸€éµç”Ÿæˆã€Œå¯è²¼å»å• AIã€çš„ Prompt")
    prompt = make_ai_prompt(table, cols_meta, sample_df)
    st.text_area("Promptï¼ˆå¯ç›´æ¥è¤‡è£½ï¼‰", prompt, height=260)

finally:
    conn.close()
