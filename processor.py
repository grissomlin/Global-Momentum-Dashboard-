# -*- coding: utf-8 -*-
import sqlite3
import pandas as pd
import numpy as np

def process_market_data(db_path):
    conn = sqlite3.connect(db_path)
    # 1. è®€å–æ•¸æ“š (å»ºè­° JOIN stock_info å–å¾—å¸‚å ´é¡å‹ä»¥ç²¾ç¢ºåˆ¤æ–·æ¼²åœé™åˆ¶)
    query = """
    SELECT p.*, i.market 
    FROM stock_prices p
    LEFT JOIN stock_info i ON p.symbol = i.symbol
    """
    df = pd.read_sql(query, conn)
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values(['symbol', 'date'])

    processed_list = []
    
    # 2. åˆ†çµ„è¨ˆç®—æŒ‡æ¨™
    for symbol, group in df.groupby('symbol'):
        group = group.copy().sort_values('date')
        
        # --- ğŸŸ¢ ç¬¬ä¸€æ­¥ï¼šè³‡æ–™æ¸…æ´— (Data Cleaning) ---
        # ä¿ç•™åŸæœ‰çš„ç•°å¸¸å€¼è™•ç†ï¼Œé¿å…éŒ¯èª¤åƒ¹æ ¼å¹²æ“¾æ¼²åœåˆ¤æ–·
        group['daily_change'] = group['close'].pct_change()
        group.loc[abs(group['daily_change']) > 0.6, 'close'] = np.nan
        group['close'] = group['close'].ffill() 
        
        if len(group) < 60: continue 

        # åŸºç¤è¨ˆç®—æº–å‚™
        group['prev_close'] = group['close'].shift(1)
        group['avg_vol_20'] = group['volume'].rolling(window=20).mean()
        group['year'] = group['date'].dt.year

        # --- ğŸ”´ ç¬¬äºŒæ­¥ï¼šæ¼²åœåµæ¸¬èˆ‡ LU_Type4 åˆ†é¡ ---
        # å°ç£å¸‚å ´é‚è¼¯ï¼š10% é™åˆ¶ (è‹¥ç‚ºèˆˆæ«ƒå‰‡ä¸è¨ˆç®—æ¼²åœ)
        is_tw_limit = (group['market'] != 'èˆˆæ«ƒ') & (group['market'] != 'ETF') # ç°¡æ˜“éæ¿¾
        group['is_limit_up'] = ((group['close'] >= (group['prev_close'] * 1.0945)) & is_tw_limit).astype(int)
        
        # åˆ†é¡ï¼šä¸€å­—æ¿(NO_VOLUME_LOCK)ã€è·³ç©ºé–(GAP_UP)ã€çˆ†é‡é–(HIGH_VOLUME_LOCK)ã€çˆ›æ¿(FLOATING)
        conditions = [
            (group['is_limit_up'] == 1) & (group['open'] == group['close']) & (group['high'] == group['low']),
            (group['is_limit_up'] == 1) & (group['open'] > group['prev_close'] * 1.05),
            (group['is_limit_up'] == 1) & (group['volume'] > group['avg_vol_20'] * 2),
            (group['is_limit_up'] == 1)
        ]
        choices = ['NO_VOLUME_LOCK', 'GAP_UP', 'HIGH_VOLUME_LOCK', 'FLOATING']
        group['lu_type'] = np.select(conditions, choices, default=None)

        # é€£æ¿è¨ˆæ•¸
        streak = group['is_limit_up'].groupby((group['is_limit_up'] != group['is_limit_up'].shift()).cumsum()).cumsum()
        group['consecutive_limits'] = np.where(group['is_limit_up'] == 1, streak, 0)

        # éš”æ—¥æ²–ç©ºé–“ (éš”æ—¥é–‹ç›¤/æœ€é«˜æ¼²å¹…)
        group['next_open_ret'] = ((group['open'].shift(-1) / group['close']) - 1) * 100
        group['next_high_ret'] = ((group['high'].shift(-1) / group['close']) - 1) * 100

        # --- ğŸŸ£ ç¬¬ä¸‰æ­¥ï¼šå¹´åº¦å·”å³°è²¢ç»åº¦è¨ˆç®— ---
        def calc_peak_metrics(df_year):
            if len(df_year) == 0: return df_year
            # æ‰¾åˆ°è©²å¹´æœ€é«˜åƒ¹æ—¥æœŸ (ç¬¬ä¸€æ¬¡åˆ°é”æœ€é«˜é»)
            peak_idx = df_year['high'].idxmax()
            peak_date = df_year.loc[peak_idx, 'date']
            peak_high = df_year.loc[peak_idx, 'high']
            year_open = df_year.iloc[0]['open']
            
            # ç¸½å·”å³° Log å ±é…¬
            total_peak_log = np.log(peak_high / year_open)
            
            # æœ€é«˜é»ä¹‹å‰çš„æ•¸æ“š
            mask_before = df_year['date'] <= peak_date
            # è¨ˆç®—æœ€é«˜é»å‰ã€Œæ¼²åœæ—¥ã€çš„ Log è²¢ç»
            # Log å ±é…¬å…·æœ‰ç›¸åŠ æ€§ï¼šln(A/B) = ln(A) - ln(B)
            lu_logs = np.log(df_year['close'] / df_year['prev_close'])
            lu_contribution = lu_logs[(df_year['is_limit_up'] == 1) & mask_before].sum()
            
            df_year['peak_date'] = peak_date
            df_year['peak_high_ret'] = ((peak_high - year_open) / year_open * 100)
            df_year['lu_peak_contribution'] = (lu_contribution / total_peak_log * 100) if total_peak_log > 0 else 0
            return df_year

        group = group.groupby('year', group_keys=False).apply(calc_peak_metrics)

        # --- ğŸ”µ ç¬¬å››æ­¥ï¼šåŸæœ‰æŠ€è¡“æŒ‡æ¨™ (MA, MACD, KD) ---
        group['ma20'] = group['close'].rolling(window=20).mean()
        group['ma60'] = group['close'].rolling(window=60).mean()
        group['ma20_slope'] = (group['ma20'].diff(3) / 3).round(4)
        
        ema12 = group['close'].ewm(span=12, adjust=False).mean()
        ema26 = group['close'].ewm(span=26, adjust=False).mean()
        group['macd'] = (ema12 - ema26)
        group['macds'] = group['macd'].ewm(span=9, adjust=False).mean()
        group['macdh'] = (group['macd'] - group['macds'])
        
        # å¹´åº¦ YTD å ±é…¬ (å¯¦æ¸¬æ”¶ç›¤)
        group['year_start_price'] = group.groupby('year')['close'].transform('first')
        group['ytd_ret'] = ((group['close'] - group['year_start_price']) / group['year_start_price'] * 100).round(2)

        # æœªä¾†å ±é…¬å€é–“ (1-20æ—¥)
        windows = {'1-5': (1, 5), '6-10': (6, 10), '11-20': (11, 20)}
        for label, (s, e) in windows.items():
            f_high = group['high'].shift(-s).rolling(window=(e-s+1)).max()
            group[f'up_{label}'] = ((f_high / group['close'] - 1) * 100).round(2)
            f_low = group['low'].shift(-s).rolling(window=(e-s+1)).min()
            group[f'down_{label}'] = ((f_low / group['close'] - 1) * 100).round(2)

        processed_list.append(group)

    # 3. å¯«å›è³‡æ–™åº«
    df_final = pd.concat(processed_list)
    df_final.to_sql('stock_analysis', conn, if_exists='replace', index=False)
    conn.execute("CREATE INDEX IF NOT EXISTS idx_analysis ON stock_analysis (symbol, date)")
    conn.close()
    print(f"âœ… ç‰¹å¾µå·¥ç¨‹å®Œæˆï¼åŒ…å«ï¼šè³‡æ–™æ¸…æ´—ã€æ¼²åœåˆ†é¡ã€éš”æ—¥æ²–èˆ‡å·”å³°è²¢ç»åº¦åˆ†æã€‚")

if __name__ == "__main__":
    process_market_data("tw_stock_warehouse.db")
