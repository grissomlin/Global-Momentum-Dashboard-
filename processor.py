# -*- coding: utf-8 -*-
import sqlite3
import pandas as pd
import numpy as np
from datetime import datetime
import warnings

# å¿½ç•¥ç‰¹å®šè­¦å‘Š
warnings.filterwarnings('ignore', category=FutureWarning)

def process_market_data(db_path):
    conn = sqlite3.connect(db_path)
    
    # 1. è®€å–æ•¸æ“šä¸¦é—œè¯ stock_info å–å¾—å¸‚å ´èˆ‡ç”¢æ¥­åˆ¥
    query = """
    SELECT p.*, i.market, i.sector, i.market_detail
    FROM stock_prices p
    LEFT JOIN stock_info i ON p.symbol = i.symbol
    """
    df = pd.read_sql(query, conn)
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values(['symbol', 'date'])

    # æª¢æŸ¥æ˜¯å¦æœ‰æ•¸æ“š
    if df.empty:
        print("âŒ æ²’æœ‰æ‰¾åˆ°è‚¡ç¥¨æ•¸æ“š")
        conn.close()
        return

    processed_list = []
    
    # å®šç¾©å¸‚å ´åˆ†é¡å‡½æ•¸
    def is_unrestricted_market(market_detail):
        """åˆ¤æ–·æ˜¯å¦ç‚ºç„¡æ¼²è·Œå¹…é™åˆ¶çš„å¸‚å ´"""
        if pd.isna(market_detail):
            return False
        unrestricted_markets = ['emerging', 'managed', 'strategic']  # èˆˆæ«ƒã€ç®¡ç†è‚¡ç¥¨ã€æˆ°ç•¥æ–°æ¿
        return market_detail in unrestricted_markets
    
    # 2. åˆ†çµ„è¨ˆç®—
    for symbol, group in df.groupby('symbol'):
        group = group.copy().sort_values('date')
        
        # è·³éæ•¸æ“šå¤ªå°‘çš„è‚¡ç¥¨
        if len(group) < 40: 
            continue
        
        # ç²å–å¸‚å ´ä¿¡æ¯
        market_detail = group['market_detail'].iloc[0] if not group['market_detail'].isna().all() else ''
        is_unrestricted = is_unrestricted_market(market_detail)
        
        # --- ğŸŸ¢ ç¬¬ä¸€æ­¥ï¼šè³‡æ–™æ¸…æ´— ---
        group['daily_change'] = group['close'].pct_change()
        
        # å¹³æ»‘ç•°å¸¸å€¼ (æœ‰æ¼²è·Œå¹…é™åˆ¶çš„å¸‚å ´ï¼Œ>60%è¦–ç‚ºç•°å¸¸)
        if not is_unrestricted:
            group.loc[abs(group['daily_change']) > 0.6, 'close'] = np.nan
            group['close'] = group['close'].ffill()
        
        # åŸºç¤æ¬„ä½
        group['prev_close'] = group['close'].shift(1)
        group['avg_vol_20'] = group['volume'].rolling(window=20).mean()
        group['year'] = group['date'].dt.year
        
        # --- ğŸ”´ ç¬¬äºŒæ­¥ï¼šæ¼²åœèˆ‡é•·ç´…å€é–“æ¨™è¨˜ (LU_Type & Brackets) ---
        # æ¼²å¹…ç™¾åˆ†æ¯”
        change_pct = group['daily_change'] * 100
        
        # åˆ¤å®šæ˜¯å¦ç‚ºã€Œå—é™å¸‚å ´æ¼²åœã€
        group['is_limit_up'] = 0
        if not is_unrestricted:
            # ä¸Šå¸‚æ«ƒ 10% åˆ¤å®š (è€ƒæ…®å››æ¨äº”å…¥)
            limit_price = group['prev_close'] * 1.1
            limit_price = round(limit_price, 2)
            group['is_limit_up'] = (group['close'] >= limit_price * 0.999).astype(int)
        
        # --- ğŸŸ¡ æ–°å¢ï¼šè©³ç´°æ¼²å¹…å€é–“åˆ†é¡ ---
        def label_detailed_strength(row, is_unrestricted):
            """ç‚ºç„¡æ¼²è·Œå¹…é™åˆ¶å¸‚å ´å‰µå»ºè©³ç´°å€é–“åˆ†é¡"""
            chg = row['daily_change'] * 100
            
            if pd.isna(chg):
                return "NEGATIVE"
            
            if is_unrestricted:
                # ç„¡æ¼²è·Œå¹…é™åˆ¶å¸‚å ´ï¼šæ¯10%ä¸€å€‹å€é–“ï¼Œç›´åˆ°100%ä»¥ä¸Š
                if chg >= 100:
                    return "RANK_100UP"
                elif chg >= 90:
                    return "RANK_90_100"
                elif chg >= 80:
                    return "RANK_80_90"
                elif chg >= 70:
                    return "RANK_70_80"
                elif chg >= 60:
                    return "RANK_60_70"
                elif chg >= 50:
                    return "RANK_50_60"
                elif chg >= 40:
                    return "RANK_40_50"
                elif chg >= 30:
                    return "RANK_30_40"
                elif chg >= 20:
                    return "RANK_20_30"
                elif chg >= 10:
                    return "RANK_10_20"
                elif chg > 0:
                    return "POSITIVE"
            else:
                # æœ‰æ¼²è·Œå¹…é™åˆ¶å¸‚å ´ï¼šç°¡åŒ–åˆ†é¡
                if chg >= 10:
                    return "RANK_10UP"
                elif chg > 0:
                    return "POSITIVE"
            
            return "NEGATIVE"
        
        # æ‡‰ç”¨è©³ç´°åˆ†é¡
        group['strength_rank'] = group.apply(
            lambda row: label_detailed_strength(row, is_unrestricted), 
            axis=1
        )
        
        # --- ğŸŸ  æ–°å¢ï¼šæ¼²å¹…å€é–“æ•¸å€¼æ¨™è¨˜ï¼ˆç”¨æ–¼çµ±è¨ˆï¼‰---
        def get_strength_value(row, is_unrestricted):
            """è¿”å›æ¼²å¹…å€é–“çš„æ•¸å€¼è¡¨ç¤º"""
            chg = row['daily_change'] * 100
            
            if pd.isna(chg) or chg <= 0:
                return 0
            
            if is_unrestricted:
                # ç„¡æ¼²è·Œå¹…é™åˆ¶ï¼šè¿”å›å€é–“ä¸‹é™
                if chg >= 100:
                    return 100
                elif chg >= 90:
                    return 90
                elif chg >= 80:
                    return 80
                elif chg >= 70:
                    return 70
                elif chg >= 60:
                    return 60
                elif chg >= 50:
                    return 50
                elif chg >= 40:
                    return 40
                elif chg >= 30:
                    return 30
                elif chg >= 20:
                    return 20
                elif chg >= 10:
                    return 10
                else:
                    return 1
            else:
                # æœ‰æ¼²è·Œå¹…é™åˆ¶ï¼šç°¡å–®åˆ†é¡
                if chg >= 10:
                    return 10
                else:
                    return 1
        
        group['strength_value'] = group.apply(
            lambda row: get_strength_value(row, is_unrestricted), 
            axis=1
        )
        
        # --- ğŸŸ¤ æ–°å¢ï¼šèˆˆæ«ƒè‚¡ç¥¨çµ±è¨ˆç‰¹å¾µ ---
        if is_unrestricted:
            # è¨ˆç®—æ¯å€‹å€é–“çš„å‡ºç¾æ¬¡æ•¸
            strength_counts = group['strength_rank'].value_counts().to_dict()
            
            # å‰µå»ºç‰¹å¾µï¼šéå»20å¤©å…§å„å¼·åº¦å€é–“çš„å‡ºç¾æ¬¡æ•¸
            for rank in ['RANK_10_20', 'RANK_20_30', 'RANK_30_40', 'RANK_40_50', 
                        'RANK_50_60', 'RANK_60_70', 'RANK_70_80', 'RANK_80_90', 
                        'RANK_90_100', 'RANK_100UP']:
                col_name = f'count_{rank.lower()}'
                group[col_name] = (group['strength_rank'] == rank).rolling(window=20, min_periods=1).sum()
        
        # æ¼²åœé¡å‹ (LU_Type4) - åƒ…é™æœ‰æ¼²è·Œå¹…é™åˆ¶çš„å¸‚å ´
        group['lu_type'] = None
        if not is_unrestricted:
            conditions = [
                (group['is_limit_up'] == 1) & (group['open'] == group['close']) & (group['high'] == group['low']),
                (group['is_limit_up'] == 1) & (group['open'] > group['prev_close'] * 1.05),
                (group['is_limit_up'] == 1) & (group['volume'] > group['avg_vol_20'] * 2),
                (group['is_limit_up'] == 1)
            ]
            choices = ['NO_VOLUME_LOCK', 'GAP_UP', 'HIGH_VOLUME_LOCK', 'FLOATING']
            group['lu_type'] = np.select(conditions, choices, default=None)

        # é€£æ¿æ¬¡æ•¸
        if not is_unrestricted:
            streak = group['is_limit_up'].groupby((group['is_limit_up'] != group['is_limit_up'].shift()).cumsum()).cumsum()
            group['consecutive_limits'] = np.where(group['is_limit_up'] == 1, streak, 0)
        else:
            group['consecutive_limits'] = 0

        # --- ğŸŸ£ ç¬¬ä¸‰æ­¥ï¼šå¹´åº¦å·”å³°è²¢ç»åº¦ (ä»¥æœ€é«˜åƒ¹ Peak High è¨ˆç®—) ---
        def calc_peak_contribution(df_year):
            if df_year.empty:
                df_year['peak_date'] = None
                df_year['peak_high_ret'] = np.nan
                df_year['strong_day_contribution'] = np.nan
                return df_year
            
            # ç¢ºä¿æœ‰æœ‰æ•ˆçš„é«˜åƒ¹æ•¸æ“š
            valid_high = df_year['high'].dropna()
            if valid_high.empty:
                df_year['peak_date'] = None
                df_year['peak_high_ret'] = np.nan
                df_year['strong_day_contribution'] = np.nan
                return df_year
            
            # æ‰¾åˆ°æœ€é«˜åƒ¹çš„ç´¢å¼•
            peak_idx = valid_high.idxmax()
            if pd.isna(peak_idx):
                df_year['peak_date'] = None
                df_year['peak_high_ret'] = np.nan
                df_year['strong_day_contribution'] = np.nan
                return df_year
            
            # ç²å–å³°å€¼æ—¥æœŸå’Œåƒ¹æ ¼
            peak_date = df_year.loc[peak_idx, 'date'] if peak_idx in df_year.index else None
            peak_price = df_year.loc[peak_idx, 'high'] if peak_idx in df_year.index else np.nan
            
            # ç²å–å¹´åº¦é–‹ç›¤åƒ¹
            if not df_year.empty:
                year_open = df_year.iloc[0]['open']
            else:
                year_open = np.nan
            
            # è¨ˆç®—å¹´åº¦ç¸½å·”å³°å ±é…¬ (å°æ•¸)
            if pd.notna(peak_price) and pd.notna(year_open) and year_open > 0:
                total_peak_log = np.log(peak_price / year_open)
            else:
                total_peak_log = 0
            
            mask_before = df_year['date'] <= peak_date if peak_date else pd.Series(False, index=df_year.index)
            
            # è¨ˆç®—æ‰€æœ‰ã€Œæ¼²å¹… > 10%ã€æ—¥å­çš„ç¸½è²¢ç»
            daily_logs = np.log(df_year['close'] / df_year['prev_close'])
            
            # èª¿æ•´é–¾å€¼ï¼šæœ‰æ¼²è·Œå¹…é™åˆ¶ç”¨10%ï¼Œç„¡é™åˆ¶ç”¨20%
            threshold = 0.10 if not is_unrestricted else 0.20
            strong_day_mask = (df_year['daily_change'] >= threshold) & mask_before
            
            if strong_day_mask.any() and total_peak_log > 0:
                strong_contribution = daily_logs[strong_day_mask].sum()
                strong_day_contribution = (strong_contribution / total_peak_log * 100)
            else:
                strong_day_contribution = 0
            
            df_year['peak_date'] = peak_date
            df_year['peak_high_ret'] = ((peak_price - year_open) / year_open * 100) if pd.notna(peak_price) and pd.notna(year_open) and year_open > 0 else np.nan
            df_year['strong_day_contribution'] = strong_day_contribution
            
            return df_year

        # ä¿å­˜ year æ¬„ä½ï¼Œç„¶å¾Œé€²è¡Œåˆ†çµ„è¨ˆç®—
        year_values = group['year'].copy()
        
        # é€²è¡Œåˆ†çµ„è¨ˆç®—
        try:
            group = group.groupby('year', group_keys=False).apply(calc_peak_contribution, include_groups=False)
        except TypeError:
            group = group.groupby('year', group_keys=False).apply(calc_peak_contribution)
        
        # ç¢ºä¿ year æ¬„ä½å­˜åœ¨
        if 'year' not in group.columns:
            group['year'] = year_values

        # --- ğŸ”µ ç¬¬å››æ­¥ï¼šåŸæœ‰æŠ€è¡“æŒ‡æ¨™ ---
        # MA
        group['ma20'] = group['close'].rolling(window=20).mean()
        group['ma60'] = group['close'].rolling(window=60).mean()
        
        # MACD
        ema12 = group['close'].ewm(span=12, adjust=False).mean()
        ema26 = group['close'].ewm(span=26, adjust=False).mean()
        group['macd'] = ema12 - ema26
        group['macds'] = group['macd'].ewm(span=9, adjust=False).mean()
        group['macdh'] = group['macd'] - group['macds']
        
        # æ³¢å‹•ç‡æŒ‡æ¨™
        group['volatility_20'] = group['daily_change'].rolling(window=20).std() * np.sqrt(252)
        
        # RSI
        delta = group['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        group['rsi'] = 100 - (100 / (1 + rs))
        
        # æˆäº¤é‡ç›¸é—œæŒ‡æ¨™
        group['volume_ratio'] = group['volume'] / group['avg_vol_20']
        
        # åƒ¹æ ¼ä½ç½®æŒ‡æ¨™
        rolling_20_high = group['high'].rolling(window=20).max()
        rolling_20_low = group['low'].rolling(window=20).min()
        group['price_position_20'] = (group['close'] - rolling_20_low) / (rolling_20_high - rolling_20_low)
        
        # YTD Ret (å¯¦æ¸¬æ”¶ç›¤)
        year_start_prices = group.groupby('year')['close'].first()
        year_to_start_price = year_start_prices.to_dict()
        group['year_start_price'] = group['year'].map(year_to_start_price)
        group['ytd_ret'] = ((group['close'] - group['year_start_price']) / group['year_start_price'] * 100).round(2)

        processed_list.append(group)
    
    # 3. æª¢æŸ¥æ˜¯å¦æœ‰è™•ç†å¾Œçš„æ•¸æ“š
    if not processed_list:
        print("âŒ æ²’æœ‰è™•ç†å¾Œçš„æ•¸æ“š")
        conn.close()
        return
    
    # 4. å¯«å›ä¸¦å„ªåŒ–
    df_final = pd.concat(processed_list)
    
    # åˆªé™¤èˆŠè¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    conn.execute("DROP TABLE IF EXISTS stock_analysis")
    
    # å‰µå»ºæ–°è¡¨
    df_final.to_sql('stock_analysis', conn, if_exists='replace', index=False)
    
    # å‰µå»ºç´¢å¼•
    conn.execute("CREATE INDEX IF NOT EXISTS idx_symbol_date ON stock_analysis (symbol, date)")
    conn.execute("CREATE INDEX IF NOT EXISTS idx_strength_rank ON stock_analysis (strength_rank)")
    conn.execute("CREATE INDEX IF NOT EXISTS idx_market ON stock_analysis (market_detail)")
    
    # 5. è¨ˆç®—çµ±è¨ˆä¿¡æ¯
    total_symbols = df_final['symbol'].nunique()
    date_range = f"{df_final['date'].min()} åˆ° {df_final['date'].max()}"
    
    # çµ±è¨ˆèˆˆæ«ƒè‚¡ç¥¨çš„å„å€é–“æ¼²å¹…æ•¸é‡
    emerging_stocks = df_final[df_final['market_detail'] == 'emerging']
    
    if not emerging_stocks.empty:
        print("\nğŸ“Š èˆˆæ«ƒè‚¡ç¥¨æ¼²å¹…å€é–“çµ±è¨ˆï¼š")
        strength_distribution = emerging_stocks['strength_rank'].value_counts().sort_index()
        
        for rank, count in strength_distribution.items():
            if rank.startswith('RANK_'):
                # æå–å€é–“
                if rank == 'RANK_100UP':
                    print(f"  {rank}: {count:,} ç­† (100%ä»¥ä¸Š)")
                elif '_' in rank:
                    parts = rank.split('_')
                    if len(parts) >= 3:
                        lower = parts[1]
                        upper = parts[2] if parts[2] != 'UP' else 'âˆ'
                        print(f"  {rank}: {count:,} ç­† ({lower}% ~ {upper}%)")
                else:
                    print(f"  {rank}: {count:,} ç­†")
        
        # è¨ˆç®—å¹³å‡æ¯æ—¥æ¼²å¹…å¤§æ–¼10%çš„æ•¸é‡
        strong_days = (emerging_stocks['daily_change'] > 0.10).sum()
        total_days = len(emerging_stocks)
        strong_percentage = (strong_days / total_days * 100) if total_days > 0 else 0
        print(f"  ğŸ“ˆ æ¼²å¹…å¤§æ–¼10%çš„å¤©æ•¸: {strong_days:,} / {total_days:,} ({strong_percentage:.1f}%)")
    
    conn.close()
    
    print(f"""
âœ… ç‰¹å¾µå·¥ç¨‹å®Œæˆï¼
ğŸ“Š è™•ç†çµ±è¨ˆï¼š
   - è™•ç†è‚¡ç¥¨æ•¸é‡: {total_symbols}
   - æ•¸æ“šæœŸé–“: {date_range}
   - ç¸½æ•¸æ“šè¡Œæ•¸: {len(df_final):,}
   - æ–°å¢ç‰¹å¾µ: è©³ç´°æ¼²å¹…å€é–“ã€æ¼²åœæ¨™è¨˜ã€å¼·åº¦åˆ†ç´šã€å¹´åº¦å·”å³°è²¢ç»åº¦ã€æŠ€è¡“æŒ‡æ¨™ç­‰
   - ç‰¹åˆ¥åŠŸèƒ½: èˆˆæ«ƒè‚¡ç¥¨æ¯10%æ¼²å¹…å€é–“çµ±è¨ˆ
    """)

if __name__ == "__main__":
    process_market_data("tw_stock_warehouse.db")
