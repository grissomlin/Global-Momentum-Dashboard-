# -*- coding: utf-8 -*-
import sqlite3
import pandas as pd
import numpy as np
from datetime import datetime
import warnings

# å¿½ç•¥ç‰¹å®šè­¦å‘Š
warnings.filterwarnings('ignore', category=FutureWarning)

class MarketConfig:
    """å¸‚å ´é…ç½®é¡åˆ¥ï¼Œçµ±ä¸€ç®¡ç†ä¸åŒå¸‚å ´çš„è¦å‰‡"""
    
    # å¸‚å ´åˆ†é¡å®šç¾©
    MARKET_RULES = {
        # å°ç£å¸‚å ´
        'TW_LISTED': {  # ä¸Šå¸‚
            'limit_up_pct': 0.10,
            'threshold': 0.10,  # å¼·å‹¢æ—¥é–¾å€¼
            'strength_intervals': [(10, 'RANK_10UP')],  # åªç”¨ä¸€å€‹10%ä»¥ä¸Šçš„å€é–“
            'max_strength': 10
        },
        'TW_OTC': {  # ä¸Šæ«ƒ
            'limit_up_pct': 0.10,
            'threshold': 0.10,
            'strength_intervals': [(10, 'RANK_10UP')],
            'max_strength': 10
        },
        'TW_EMERGING': {  # èˆˆæ«ƒ
            'limit_up_pct': None,  # ç„¡æ¼²è·Œå¹…é™åˆ¶
            'threshold': 0.20,
            'strength_intervals': [
                (10, 'RANK_10_20'), (20, 'RANK_20_30'), (30, 'RANK_30_40'),
                (40, 'RANK_40_50'), (50, 'RANK_50_60'), (60, 'RANK_60_70'),
                (70, 'RANK_70_80'), (80, 'RANK_80_90'), (90, 'RANK_90_100'),
                (100, 'RANK_100UP')
            ],
            'max_strength': 100
        },
        # éŸ“åœ‹å¸‚å ´
        'KR_KOSPI': {
            'limit_up_pct': 0.30,
            'threshold': 0.30,  # éŸ“åœ‹å¼·å‹¢æ—¥é–¾å€¼ç”¨30%
            'strength_intervals': [
                (10, 'RANK_10_20'), (20, 'RANK_20_30'), (30, 'RANK_30UP')
            ],
            'max_strength': 30
        },
        'KR_KOSDAQ': {
            'limit_up_pct': 0.30,
            'threshold': 0.30,
            'strength_intervals': [
                (10, 'RANK_10_20'), (20, 'RANK_20_30'), (30, 'RANK_30UP')
            ],
            'max_strength': 30
        }
    }
    
    @classmethod
    def get_market_config(cls, market, market_detail):
        """æ ¹æ“šå¸‚å ´å’Œå¸‚å ´ç´°åˆ†é¡ç²å–é…ç½®"""
        # å°ç£å¸‚å ´åˆ¤æ–·
        if market == 'TW':
            if market_detail == 'emerging':
                return cls.MARKET_RULES['TW_EMERGING']
            elif market_detail in ['listed', 'tse']:
                return cls.MARKET_RULES['TW_LISTED']
            elif market_detail in ['otc', 'gtsm']:
                return cls.MARKET_RULES['TW_OTC']
        
        # éŸ“åœ‹å¸‚å ´åˆ¤æ–·ï¼ˆå¾ä¸‹è¼‰å™¨çš„è³‡æ–™åˆ¤æ–·ï¼‰
        elif market == 'KR' or 'KOSPI' in str(market) or 'KOSDAQ' in str(market):
            if 'KOSPI' in str(market_detail) or 'KOSPI' in str(market):
                return cls.MARKET_RULES['KR_KOSPI']
            elif 'KOSDAQ' in str(market_detail) or 'KOSDAQ' in str(market):
                return cls.MARKET_RULES['KR_KOSDAQ']
            else:
                return cls.MARKET_RULES['KR_KOSPI']  # é è¨­ç‚ºKOSPI
        
        # é è¨­ç‚ºå°ç£ä¸Šå¸‚æ«ƒè¦å‰‡ï¼ˆå‘ä¸‹å…¼å®¹ï¼‰
        return cls.MARKET_RULES['TW_LISTED']

def process_market_data(db_path):
    conn = sqlite3.connect(db_path)
    
    # 1. è®€å–æ•¸æ“šä¸¦é—œè¯ stock_info å–å¾—å¸‚å ´èˆ‡ç”¢æ¥­åˆ¥
    query = """
    SELECT p.*, i.market, i.sector, i.market_detail
    FROM stock_prices p
    LEFT JOIN stock_info i ON p.symbol = i.symbol
    """
    df = pd.read_sql(query, conn)
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values(['symbol', 'date'])

    # æª¢æŸ¥æ˜¯å¦æœ‰æ•¸æ“š
    if df.empty:
        print("âŒ æ²’æœ‰æ‰¾åˆ°è‚¡ç¥¨æ•¸æ“š")
        conn.close()
        return

    processed_list = []
    
    # 2. åˆ†çµ„è¨ˆç®—
    for symbol, group in df.groupby('symbol'):
        group = group.copy().sort_values('date')
        
        # è·³éæ•¸æ“šå¤ªå°‘çš„è‚¡ç¥¨
        if len(group) < 40: 
            continue
        
        # ç²å–å¸‚å ´ä¿¡æ¯
        market = group['market'].iloc[0] if not group['market'].isna().all() else ''
        market_detail = group['market_detail'].iloc[0] if not group['market_detail'].isna().all() else ''
        
        # ç²å–å¸‚å ´é…ç½®
        config = MarketConfig.get_market_config(market, market_detail)
        limit_up_pct = config['limit_up_pct']
        is_unrestricted = (limit_up_pct is None)
        threshold = config['threshold']  # å¼·å‹¢æ—¥é–¾å€¼
        
        print(f"è™•ç† {symbol}: å¸‚å ´={market}, ç´°é¡={market_detail}, æ¼²åœ={limit_up_pct}, å¼·å‹¢é–¾å€¼={threshold}")
        
        # --- ğŸŸ¢ ç¬¬ä¸€æ­¥ï¼šè³‡æ–™æ¸…æ´— ---
        group['daily_change'] = group['close'].pct_change()
        
        # å¹³æ»‘ç•°å¸¸å€¼ (æœ‰æ¼²è·Œå¹…é™åˆ¶çš„å¸‚å ´)
        if not is_unrestricted and limit_up_pct is not None:
            # å°‡è¶…éæ¼²åœå¹…åº¦çš„è¦–ç‚ºç•°å¸¸
            max_allowed_change = limit_up_pct * 1.5  # å…è¨±ä¸€äº›èª¤å·®
            group.loc[abs(group['daily_change']) > max_allowed_change, 'close'] = np.nan
            group['close'] = group['close'].ffill()
        
        # åŸºç¤æ¬„ä½
        group['prev_close'] = group['close'].shift(1)
        group['avg_vol_20'] = group['volume'].rolling(window=20).mean()
        group['year'] = group['date'].dt.year
        
        # --- ğŸ”´ ç¬¬äºŒæ­¥ï¼šæ¼²åœèˆ‡é•·ç´…å€é–“æ¨™è¨˜ ---
        # æ¼²å¹…ç™¾åˆ†æ¯”
        change_pct = group['daily_change'] * 100
        
        # åˆ¤å®šæ˜¯å¦ç‚ºã€Œæ¼²åœã€
        group['is_limit_up'] = 0
        if limit_up_pct is not None:
            # æ ¹æ“šå¸‚å ´é…ç½®çš„æ¼²åœå¹…åº¦è¨ˆç®—
            limit_price = group['prev_close'] * (1 + limit_up_pct)
            limit_price = round(limit_price, 2)
            group['is_limit_up'] = (group['close'] >= limit_price * 0.999).astype(int)
        
        # --- ğŸŸ¡ æ–°å¢ï¼šè©³ç´°æ¼²å¹…å€é–“åˆ†é¡ï¼ˆçµ±ä¸€æ–¹æ³•ï¼‰---
        def label_detailed_strength(row):
            """ç‚ºæ‰€æœ‰å¸‚å ´å‰µå»ºè©³ç´°å€é–“åˆ†é¡"""
            chg = row['daily_change'] * 100
            
            if pd.isna(chg) or chg <= 0:
                return "NEGATIVE"
            
            # ä½¿ç”¨å¸‚å ´é…ç½®çš„å€é–“
            for min_val, rank_label in config['strength_intervals']:
                if chg >= min_val:
                    # æ‰¾åˆ°é©åˆçš„å€é–“
                    if rank_label == 'RANK_10UP' or rank_label == 'RANK_30UP':
                        # é€™äº›æ˜¯ã€Œä»¥ä¸Šã€çš„å€é–“
                        return rank_label
                    else:
                        # æª¢æŸ¥æ˜¯å¦åœ¨å€é–“å…§
                        next_min = next((m for m, _ in config['strength_intervals'] if m > min_val), None)
                        if next_min is None or chg < next_min:
                            return rank_label
            
            # å¦‚æœå°æ–¼æœ€å°å€é–“ä½†æ˜¯æ­£å€¼
            return "POSITIVE"
        
        # æ‡‰ç”¨è©³ç´°åˆ†é¡
        group['strength_rank'] = group.apply(
            lambda row: label_detailed_strength(row), 
            axis=1
        )
        
        # --- ğŸŸ  æ–°å¢ï¼šæ¼²å¹…å€é–“æ•¸å€¼æ¨™è¨˜ï¼ˆç”¨æ–¼çµ±è¨ˆï¼‰---
        def get_strength_value(row):
            """è¿”å›æ¼²å¹…å€é–“çš„æ•¸å€¼è¡¨ç¤º"""
            chg = row['daily_change'] * 100
            
            if pd.isna(chg) or chg <= 0:
                return 0
            
            # ä½¿ç”¨å¸‚å ´é…ç½®çš„å€é–“
            for min_val, rank_label in config['strength_intervals']:
                if chg >= min_val:
                    # å¦‚æœæ˜¯ã€Œä»¥ä¸Šã€çš„å€é–“ï¼Œè¿”å›è©²å€¼
                    if rank_label in ['RANK_10UP', 'RANK_30UP']:
                        return min_val
                    # æª¢æŸ¥æ˜¯å¦åœ¨å€é–“å…§
                    next_min = next((m for m, _ in config['strength_intervals'] if m > min_val), None)
                    if next_min is None or chg < next_min:
                        return min_val
            
            # å°æ–¼æœ€å°å€é–“ä½†æ˜¯æ­£å€¼
            return 1
        
        group['strength_value'] = group.apply(
            lambda row: get_strength_value(row), 
            axis=1
        )
        
        # --- ğŸŸ¤ æ–°å¢ï¼šç‰¹æ®Šå¸‚å ´çµ±è¨ˆç‰¹å¾µ ---
        if is_unrestricted or limit_up_pct == 0.30:
            # å°æ–¼ç„¡æ¼²è·Œå¹…é™åˆ¶æˆ–éŸ“åœ‹å¸‚å ´ï¼Œè¨ˆç®—å„å€é–“å‡ºç¾æ¬¡æ•¸
            for min_val, rank_label in config['strength_intervals']:
                if rank_label not in ['RANK_10UP', 'RANK_30UP']:  # æ’é™¤ã€Œä»¥ä¸Šã€çš„å€é–“
                    col_name = f'count_{rank_label.lower()}'
                    group[col_name] = (group['strength_rank'] == rank_label).rolling(window=20, min_periods=1).sum()
        
        # æ¼²åœé¡å‹ (LU_Type4) - åƒ…é™æœ‰æ¼²è·Œå¹…é™åˆ¶çš„å¸‚å ´
        group['lu_type'] = None
        if limit_up_pct is not None:
            conditions = [
                (group['is_limit_up'] == 1) & (group['open'] == group['close']) & (group['high'] == group['low']),
                (group['is_limit_up'] == 1) & (group['open'] > group['prev_close'] * (1 + limit_up_pct * 0.5)),
                (group['is_limit_up'] == 1) & (group['volume'] > group['avg_vol_20'] * 2),
                (group['is_limit_up'] == 1)
            ]
            choices = ['NO_VOLUME_LOCK', 'GAP_UP', 'HIGH_VOLUME_LOCK', 'FLOATING']
            group['lu_type'] = np.select(conditions, choices, default=None)

        # é€£æ¿æ¬¡æ•¸
        if limit_up_pct is not None:
            streak = group['is_limit_up'].groupby((group['is_limit_up'] != group['is_limit_up'].shift()).cumsum()).cumsum()
            group['consecutive_limits'] = np.where(group['is_limit_up'] == 1, streak, 0)
        else:
            group['consecutive_limits'] = 0

        # --- ğŸŸ£ ç¬¬ä¸‰æ­¥ï¼šå¹´åº¦å·”å³°è²¢ç»åº¦ ---
        def calc_peak_contribution(df_year):
            if df_year.empty:
                df_year['peak_date'] = None
                df_year['peak_high_ret'] = np.nan
                df_year['strong_day_contribution'] = np.nan
                return df_year
            
            # ç¢ºä¿æœ‰æœ‰æ•ˆçš„é«˜åƒ¹æ•¸æ“š
            valid_high = df_year['high'].dropna()
            if valid_high.empty:
                df_year['peak_date'] = None
                df_year['peak_high_ret'] = np.nan
                df_year['strong_day_contribution'] = np.nan
                return df_year
            
            # æ‰¾åˆ°æœ€é«˜åƒ¹çš„ç´¢å¼•
            peak_idx = valid_high.idxmax()
            if pd.isna(peak_idx):
                df_year['peak_date'] = None
                df_year['peak_high_ret'] = np.nan
                df_year['strong_day_contribution'] = np.nan
                return df_year
            
            # ç²å–å³°å€¼æ—¥æœŸå’Œåƒ¹æ ¼
            peak_date = df_year.loc[peak_idx, 'date'] if peak_idx in df_year.index else None
            peak_price = df_year.loc[peak_idx, 'high'] if peak_idx in df_year.index else np.nan
            
            # ç²å–å¹´åº¦é–‹ç›¤åƒ¹
            if not df_year.empty:
                year_open = df_year.iloc[0]['open']
            else:
                year_open = np.nan
            
            # è¨ˆç®—å¹´åº¦ç¸½å·”å³°å ±é…¬ (å°æ•¸)
            if pd.notna(peak_price) and pd.notna(year_open) and year_open > 0:
                total_peak_log = np.log(peak_price / year_open)
            else:
                total_peak_log = 0
            
            mask_before = df_year['date'] <= peak_date if peak_date else pd.Series(False, index=df_year.index)
            
            # è¨ˆç®—æ‰€æœ‰ã€Œæ¼²å¹… > thresholdã€æ—¥å­çš„ç¸½è²¢ç»
            daily_logs = np.log(df_year['close'] / df_year['prev_close'])
            
            # ä½¿ç”¨å¸‚å ´é…ç½®çš„threshold
            strong_day_mask = (df_year['daily_change'] >= threshold) & mask_before
            
            if strong_day_mask.any() and total_peak_log > 0:
                strong_contribution = daily_logs[strong_day_mask].sum()
                strong_day_contribution = (strong_contribution / total_peak_log * 100)
            else:
                strong_day_contribution = 0
            
            df_year['peak_date'] = peak_date
            df_year['peak_high_ret'] = ((peak_price - year_open) / year_open * 100) if pd.notna(peak_price) and pd.notna(year_open) and year_open > 0 else np.nan
            df_year['strong_day_contribution'] = strong_day_contribution
            
            return df_year

        # ä¿å­˜ year æ¬„ä½ï¼Œç„¶å¾Œé€²è¡Œåˆ†çµ„è¨ˆç®—
        year_values = group['year'].copy()
        
        # é€²è¡Œåˆ†çµ„è¨ˆç®—
        try:
            group = group.groupby('year', group_keys=False).apply(calc_peak_contribution, include_groups=False)
        except TypeError:
            group = group.groupby('year', group_keys=False).apply(calc_peak_contribution)
        
        # ç¢ºä¿ year æ¬„ä½å­˜åœ¨
        if 'year' not in group.columns:
            group['year'] = year_values

        # --- ğŸ”µ ç¬¬å››æ­¥ï¼šæŠ€è¡“æŒ‡æ¨™ ---
        # MA
        group['ma20'] = group['close'].rolling(window=20).mean()
        group['ma60'] = group['close'].rolling(window=60).mean()
        
        # MACD
        ema12 = group['close'].ewm(span=12, adjust=False).mean()
        ema26 = group['close'].ewm(span=26, adjust=False).mean()
        group['macd'] = ema12 - ema26
        group['macds'] = group['macd'].ewm(span=9, adjust=False).mean()
        group['macdh'] = group['macd'] - group['macds']
        
        # æ³¢å‹•ç‡æŒ‡æ¨™
        group['volatility_20'] = group['daily_change'].rolling(window=20).std() * np.sqrt(252)
        
        # RSI
        delta = group['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        group['rsi'] = 100 - (100 / (1 + rs))
        
        # æˆäº¤é‡ç›¸é—œæŒ‡æ¨™
        group['volume_ratio'] = group['volume'] / group['avg_vol_20']
        
        # åƒ¹æ ¼ä½ç½®æŒ‡æ¨™
        rolling_20_high = group['high'].rolling(window=20).max()
        rolling_20_low = group['low'].rolling(window=20).min()
        group['price_position_20'] = (group['close'] - rolling_20_low) / (rolling_20_high - rolling_20_low)
        
        # YTD Ret (å¯¦æ¸¬æ”¶ç›¤)
        year_start_prices = group.groupby('year')['close'].first()
        year_to_start_price = year_start_prices.to_dict()
        group['year_start_price'] = group['year'].map(year_to_start_price)
        group['ytd_ret'] = ((group['close'] - group['year_start_price']) / group['year_start_price'] * 100).round(2)

        processed_list.append(group)
    
    # 3. æª¢æŸ¥æ˜¯å¦æœ‰è™•ç†å¾Œçš„æ•¸æ“š
    if not processed_list:
        print("âŒ æ²’æœ‰è™•ç†å¾Œçš„æ•¸æ“š")
        conn.close()
        return
    
    # 4. å¯«å›ä¸¦å„ªåŒ–
    df_final = pd.concat(processed_list)
    
    # åˆªé™¤èˆŠè¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    conn.execute("DROP TABLE IF EXISTS stock_analysis")
    
    # å‰µå»ºæ–°è¡¨
    df_final.to_sql('stock_analysis', conn, if_exists='replace', index=False)
    
    # å‰µå»ºç´¢å¼•
    conn.execute("CREATE INDEX IF NOT EXISTS idx_symbol_date ON stock_analysis (symbol, date)")
    conn.execute("CREATE INDEX IF NOT EXISTS idx_strength_rank ON stock_analysis (strength_rank)")
    conn.execute("CREATE INDEX IF NOT EXISTS idx_market ON stock_analysis (market)")
    conn.execute("CREATE INDEX IF NOT EXISTS idx_market_detail ON stock_analysis (market_detail)")
    
    # 5. è¨ˆç®—çµ±è¨ˆä¿¡æ¯
    total_symbols = df_final['symbol'].nunique()
    date_range = f"{df_final['date'].min()} åˆ° {df_final['date'].max()}"
    
    # çµ±è¨ˆä¸åŒå¸‚å ´çš„æ¼²å¹…åˆ†ä½ˆ
    print("\nğŸ“Š å…¨çƒå¸‚å ´æ¼²å¹…å€é–“çµ±è¨ˆï¼š")
    
    for market in df_final['market'].unique():
        if pd.isna(market):
            continue
            
        market_data = df_final[df_final['market'] == market]
        if market_data.empty:
            continue
            
        print(f"\nğŸ”¹ å¸‚å ´: {market}")
        strength_distribution = market_data['strength_rank'].value_counts().sort_index()
        
        for rank, count in strength_distribution.items():
            if rank != "NEGATIVE" and rank != "POSITIVE":
                print(f"  {rank}: {count:,} ç­†")
        
        # è¨ˆç®—å„å¸‚å ´çš„å¼·å‹¢æ—¥æ¯”ä¾‹
        if market in ['KR', 'KOSPI', 'KOSDAQ']:
            strong_threshold = 0.30  # éŸ“åœ‹30%
        elif market == 'TW':
            # åˆ¤æ–·æ˜¯å¦ç‚ºèˆˆæ«ƒ
            emerging_data = market_data[market_data['market_detail'] == 'emerging']
            if not emerging_data.empty:
                strong_threshold = 0.20  # å°ç£èˆˆæ«ƒ20%
            else:
                strong_threshold = 0.10  # å°ç£ä¸Šå¸‚æ«ƒ10%
        else:
            strong_threshold = 0.10  # é è¨­10%
        
        strong_days = (market_data['daily_change'] > strong_threshold).sum()
        total_days = len(market_data)
        strong_percentage = (strong_days / total_days * 100) if total_days > 0 else 0
        print(f"  ğŸ“ˆ æ¼²å¹…å¤§æ–¼{strong_threshold*100:.0f}%çš„å¤©æ•¸: {strong_days:,} / {total_days:,} ({strong_percentage:.1f}%)")
        
        # ç‰¹åˆ¥é¡¯ç¤ºéŸ“åœ‹å¸‚å ´çš„çµ±è¨ˆ
        if market in ['KR', 'KOSPI', 'KOSDAQ']:
            kr_10_20 = ((market_data['daily_change'] >= 0.10) & (market_data['daily_change'] < 0.20)).sum()
            kr_20_30 = ((market_data['daily_change'] >= 0.20) & (market_data['daily_change'] < 0.30)).sum()
            kr_30_up = (market_data['daily_change'] >= 0.30).sum()
            print(f"  ğŸ‡°ğŸ‡· éŸ“åœ‹å°ˆå±¬çµ±è¨ˆ:")
            print(f"     10-20%: {kr_10_20:,} ç­†")
            print(f"     20-30%: {kr_20_30:,} ç­†")
            print(f"     30%ä»¥ä¸Š: {kr_30_up:,} ç­†")
    
    conn.close()
    
    print(f"""
âœ… å…¨çƒå¸‚å ´ç‰¹å¾µå·¥ç¨‹å®Œæˆï¼
ğŸ“Š è™•ç†çµ±è¨ˆï¼š
   - è™•ç†è‚¡ç¥¨æ•¸é‡: {total_symbols}
   - æ•¸æ“šæœŸé–“: {date_range}
   - ç¸½æ•¸æ“šè¡Œæ•¸: {len(df_final):,}
   - æ–°å¢ç‰¹å¾µ: è©³ç´°æ¼²å¹…å€é–“ã€æ¼²åœæ¨™è¨˜ã€å¼·åº¦åˆ†ç´šã€å¹´åº¦å·”å³°è²¢ç»åº¦ã€æŠ€è¡“æŒ‡æ¨™ç­‰
   - æ”¯æ´å¸‚å ´: å°ç£ä¸Šå¸‚/ä¸Šæ«ƒ/èˆˆæ«ƒã€éŸ“åœ‹KOSPI/KOSDAQ
   - ç‰¹åˆ¥åŠŸèƒ½: è·¨å¸‚å ´çµ±ä¸€æ¼²å¹…å€é–“åˆ†æ
    """)

if __name__ == "__main__":
    # å¯ä»¥æ ¹æ“šéœ€è¦é¸æ“‡è™•ç†å“ªå€‹è³‡æ–™åº«
    # process_market_data("tw_stock_warehouse.db")  # å°ç£
    process_market_data("kr_stock_warehouse.db")  # éŸ“åœ‹
    # æœªä¾†å¯ä»¥æ“´å±•: process_market_data("us_stock_warehouse.db")  # ç¾åœ‹
